[
["index.html", "Computational Tools for Reproducible Science Overview 0.1 Software Requirements and Installation Instructions", " Computational Tools for Reproducible Science Simona Picardi1 2021-01-15 Overview Figure 0.1: Artwork by Allison Horst This digital book contains the material for the Graduate Special Topics course WILD 6900: Computational Tools for Reproducible Science. The aim of the course is to provide students with practical skills to manage and process their data throughout their life cycle, from the moment they are entered into a computer to the moment they are used in a publication, document, presentation, etc. The content is organized in the following Chapters: Chapter 1, Project Organization Chapter 2, Version Control with Git Chapter 3, Collaborative Science with GitHub Chapter 4, Best Practices in the Use of Spreadsheets Chapter 5, Relational Databases Chapter 6, Basics of SQL Language Chapter 7, Linking Databases and R with RSQLite Chapter 8, Dynamic Documents with RMarkdown Chapter 9, Automatically Generated Websites with GitHub Pages Chapter 10, Introduction to R Chapter 11, Troubleshooting in R Chapter 12, Working Environments in R Chapter 13, Data Wrangling with tidyverse Chapter 14, Data Visualization with ggplot2 Chapter 15, Dates and Times in R Chapter 16, Introduction to Geospatial Data in R Chapter 17, Problem Decomposition 0.1 Software Requirements and Installation Instructions Required software is listed below along with installation instructions for different operating systems. 0.1.1 Git Git is a distributed version control system. It is free and open source. To install Git, follow instructions for your operating system below. Also, make sure you create a GitHub account on https://github.com/. 0.1.1.1 Windows Download from the Git website: go to https://git-scm.com/download/win and the download will start automatically. 0.1.1.2 Mac OS On Mavericks (10.9) or above, when you try to run a Git command from the Terminal for the first time, the installation will start automatically if you don’t already have Git installed. Type the following in the terminal: $ git --version And follow the instructions on the installation wizard. 0.1.1.3 Linux In the command line: $ sudo apt install git-all 0.1.2 Spreadsheet Editor Most people will already have Excel installed on their computer. However, any spreadsheet editor will work for the purpose of this course. If you don’t have access to an Office License, LibreOffice or OpenOffice are free, perfectly viable alternatives to Excel. Download the installer for your operating system: LibreOffice: https://www.libreoffice.org/download/download/ OpenOffice: https://www.openoffice.org/download/ 0.1.3 SQLite SQLite is a lightweight relational database management system. To install it, follow these steps: Go to https://www.sqlite.org/download.html and find your operating system in the list. You are looking for a category called “Precompiled Binaries”. For example, if you are on Windows, look for “Precompiled Binaries for Windows”. From this list, chose the file whose name starts with “sqlite-tools”. The description will read something like, “A bundle of command-line tools for managing SQLite database files, including the command-line shell program, the sqldiff.exe program, and the sqlite3_analyzer.exe program” In your file explorer, create a new folder called “sqlite” (e.g., on Windows, C:) Extract the .zip file you downloaded into this new folder. Download SQLiteStudio (this is a GUI, or Graphical User Interface, that we are going to use to run our SQL commands) here: https://github.com/pawelsalawa/sqlitestudio/releases. Download the file whose name starts with “Install” and choose the .exe extension if you’re working on Windows, .dmg if you’re on Mac OS, and the one without extension if you’re on Linux. If these instructions weren’t clear, you can find more details (with screenshots) at this link: https://www.sqlitetutorial.net/download-install-sqlite/ 0.1.4 R R is a free software environment for statistical computing and graphics. Note that installing or updating R is a separate, independent process from installing or updating RStudio! If you already have R installed, make sure you have the latest available version. Follow installation or update instructions for your operating system below. 0.1.4.1 Windows Download the latest version of R at https://cran.r-project.org/bin/windows/base/ 0.1.4.2 Mac OS Download the latest version of R at https://cran.r-project.org/bin/macosx/ 0.1.4.3 Linux These instructions are for Ubuntu 18.04. If you are running a different version of Debian/Ubuntu, there are some small adjustments to make (see below). In the command line, add the GPG Key: $ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9 Add the R repository (here is where you have to replace the appropriate release name if you’re working with a different version of Ubuntu; you can find the complete list here: https://cloud.r-project.org/bin/linux/ubuntu/): sudo add-apt-repository &#39;deb https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/&#39; Update package lists: $ sudo apt update Install R: $ sudo apt install r-base 0.1.5 RStudio RStudio is a free Integrated Development Environment (IDE) for R. Note that installing or updating RStudio is a separate, independent process from installing or updating R! If you already have RStudio installed, make sure you have the latest available version. Otherwise, go ahead and download it from here: https://rstudio.com/products/rstudio/download/#download (choose the appropriate version for your operating system.) 0.1.6 Required R Packages Throughout the course, we will be using the following R packages: RSQLite, rmarkdown, bookdown, renv, tidyverse, lubridate, raster, and sf. All these packages are on CRAN and can be installed (along with their dependencies) by running the following code in R: install.packages(c(&quot;RSQLite&quot;, &quot;rmarkdown&quot;, &quot;bookdown&quot;, &quot;renv&quot;, &quot;tidyverse&quot;, &quot;lubridate&quot;, &quot;raster&quot;, &quot;sf&quot;), dependencies = TRUE) Utah State University, simona.picardi@usu.edu↩︎ "],
["project-organization.html", "Chapter 1 Project Organization 1.1 Directory structure 1.2 Golden rules 1.3 Be flexible 1.4 Documentation 1.5 Naming files 1.6 RStudio Projects 1.7 Relative and absolute paths", " Chapter 1 Project Organization 1.1 Directory structure When starting a new project, it is worthwhile to spend some time thinking about how to best organize its content. This means asking questions such as: What are my project inputs? What types of outputs do I expect to come out of this project? How does this project relate to other projects I am working on? Answering these questions can help us decide on a directory structure to house our project files. For example, say that we are working on a research project that entails data cleaning, analysis, and writing of a manuscript. One way to go about it is to have a root project directory that contains subfolders for data, analysis code, results, and the manuscript file/s. We can call this a “project-based directory layout.” Alternatively, if we have multiple projects underway, we can split our files by activity rather than by projects and have a “data” folder, an “analyses” folder, a “manuscripts” folder, etc., all with a subfolder for each project. We can call this an “activity-based directory layout.” Figure 1.1: Project-based directory organization Figure 1.2: Activity-based directory organization How you define a project is largely up to you. It could be all the work you do on a given dataset, or all the work you do for a thesis or dissertation, or each manuscript could be its own project even if it uses the same dataset as a different project. With so many options, how do we choose? Ultimately, the way you structure your project directories will have a big impact on the efficiency and reproducibility of your work, so there are some criteria to keep in mind. 1.1.1 Overlap The first thing to consider is the overlap in data and code files between a project and other past/current projects. If two projects don’t share any data, it’s probably best to manage them separately. If two projects share a large amount of data, it might make more sense to manage them together as one. If you are writing functions to use across several different projects, they should probably be in their own project. 1.1.2 Minimizing duplication The reason why it’s important to account for overlap is because you want to minimize duplication as much as you can. Duplication of both data and code files is dangerous because it’s easy to lose track of modifications you have made to a file saved in one place but not in the other place. As you keep making changes, the two files will have the same name but different content, which generates confusion. Duplication is also inefficient because it occupies precious space on your computer. 1.1.3 Self-containedness A fundamental quality of reproducible projects is that they are self-contained, meaning that ideally you could zip up the entire project directory and send it to a friend and they should be able to run your code and reproduce your results without changing anything. This means everything the project needs to work, from A to Z – data, functions, code – is contained in its root directory. 1.1.4 Tradeoffs The self-containedness criterion is sometimes in contradiction with minimizing duplication: if two projects share one or more data files, you can either violate the duplication criterion by making sure each project contains all the necessary data for the sake of self-containedness; or you can choose to sacrifice self-containedness to avoid file duplication and save space on your computer. The answer will depend on whether you anticipate the project to be widely shared or mostly for your personal use, how large the shared data files are, etc. The bottom line is that there is no one-size-fits-all solution for project organization. Most importantly, the structure you choose needs to be functional for your needs. Putting thought into it is a great place to start. 1.2 Golden rules Whichever directory structure you choose for a project, there are some universal rules to keep in mind for how to organize files within it. First and foremost, raw data should never be changed. Save it into a “data” folder and treat it as immutable. You can even set it as read-only to make sure there is no room for accidents. The processed, clean version of your data will go into a dedicated “processed_data” folder. Anything that can be generated from code goes into its own folder. This includes basically everything but the raw data and the code itself. You can have an “output” folder, or separate folders for output files and figures (e.g., “output” and “figures”.) If there are text documents, put them in their own folder (e.g., “docs”) Code also has its own folder. If you write a lot of functions, it can be helpful to have a “funs” folder to store those and a “src” (for ‘source’) folder to save processing/analysis code. If processing/analysis scripts are meant to be used in a certain order, you can number them (more on this in a minute.) Sometimes the pipeline is not linear but branched, so numbering may not always make sense. Function scripts should not be numbered. Modularize your code: instead of having a giant script to run your entire analysis from data cleaning to final figures, break up your workflow into several short, single-purpose scripts with well-defined inputs and outputs. 1.3 Be flexible It can be challenging to anticipate the structure of a project that is just about to start (especially the first time you start thinking through optimal directory structures.) It helps to be flexible and allow some room for adjustments. For example, you can start with a basic directory structure where you have a “data” folder, a “code” folder, and an “output” folder, and then you may decide to split the “code” folder into “src” and “funs”, or to further split the “output” folder into “output” and “figures”, etc. Sometimes these changes can break your code and become frustrating, but these problems are easy to fix. Similarly, it can be challenging to have the long-term vision to know where it’s best to break a script and start a new one. It’s easy to tunnel vision into an analysis and keep adding lines and lines of code without thinking about break points that make sense. One good way to deal with this is to reserve some time at the end of your coding session to look at your script and notice if there are any intermediate products that you can save and use as input of the next step of the workflow. Then you can make the necessary adjustments in terms of code compartmentalization, paths to input and output files, etc. In the words of Wilson et al. (2017, see references below), “consistency and predictability are more important than hairsplitting” when organizing the directory structure for your projects. Besides a few universal rules, designing the optimal structure often requires consideration of project specifics. Ultimately, the goal is to improve efficiency – by allowing you to find your files easily, only run the minimal amount of code you need for a task, making it easy for collaborators and future you to wrap your head around the project content – and reproducibility. 1.4 Documentation One very important aspect of reproducibility is good documentation. Each of your projects should always be accompanied by a README file. The README should contain all the information an outsider would need to understand what the project is all about, what are the inputs and outputs, where to find files within the project directory, etc. The README is simply a text file, there’s nothing special to it – you can just create it in your Notepad or other text editor. Writing down everything about a project in a README can be tedious, but it pays off ten-fold. It’s good to get in the habit of starting a project by creating a README file right after the directory structure is created. Record who the author/s is/are, the date the project was started, and a description of what the project is for. Then, any time a new file is added, specify what it is and where you got it from. For example, “File X.csv was sent by Mary White in an email on 2/1/2019 to my.address @ gmail.com”, etc. Be meticulous: what seems obvious today can become a puzzle to solve in a few months. 1.5 Naming files There is a science to choosing good file names, too. Here is a list of file names that are not good, for a variety of different reasons: data.csv data_cleaned_March-22-2012.csv analysis code.R Green Frogs Manuscript_Final_edits.docx final.docx Why are those names bad, and what makes a good file name? Good file names are computer-readable, human-readable, and work well with default ordering. Let’s break these three criteria down one by one. 1.5.1 Computer-readable file names What makes a file name computer-readable? First, computer readable files contain no spaces, no punctuation, and no special characters. They are case-consistent, which means that you always stick to the same case pattern, whether that be full lowercase, camel case (ThisIsWhatIMeanByCamelCase), or whatever else. Finally, good file names make deliberate use of text delimiters. Wise use of delimiters makes it easy to look for patterns when you are searching for a specific file. Usually, it’s recommended that you use an underscore (_) to delimit metadata units and a dash (-) to delimit words within a metadata unit. For example, here is a good, computer-readable file name: 2018-04-26_reproducible-science_slides_lesson-01.pptx 1.5.2 Human-readable file names The example file name above is not only computer-readable, it’s also human-readable. This means that a human can read the file name and have a pretty good idea of what’s in that file. Good file names are informative! You shouldn’t be afraid to use long names if that’s what it takes to make them descriptive. 1.5.3 File names that work well with default ordering If you sort your files alphabetically in a folder, you want them to be ordered in a way that makes sense. Whether you sort your files by date or by a sequential number, the number always goes first. For dates, use the YMD format, or your files created in April of 1984 and 2020 will be closer than the ones created in March and April 2020. If you are using sequential numbering, add a sensible amount of zeros in front based on how many files of that category you expect to have in the future. If you expect to have more than 10 but not more than 99 files, you can add a single leading zero (e.g., “data_analysis_01.R” instead of “data_analysis_1.R”), whereas if you expect to have between 100 and 999 you can add two (e.g., “Photo_001.jpeg” instead of “Photo_1.jpeg” or “Photo_01.jpeg”.) 1.6 RStudio Projects RStudio Projects are a great tool to help you stay organized. The concept behind RStudio Projects is that each Project is a self-contained unit where inputs, outputs, and code are all in one place. Sounds familiar? RStudio Projects work seamlessly with the directory organization framework we have been talking about. It’s a good idea to make sure each of the projects (with a lowercase p) you work on has its own associated RStudio Project (with a capital P). Figure 1.3: How to create a new RStudio Project You may be familiar with the concept of a working directory in R. The working directory is the place where, unless otherwise specified, all of your outputs are saved. All relative paths are also interpreted relative to the working directory (more on relative paths in a minute.) The cool thing about an RStudio Project is that it automatically makes sure that your project directory is set as the working directory. All the clunkiness of having to set, change, or double check which directory you’re working in is forgotten: all you do is open up your Project and then the paths you use to load or save data are already, by default, relative to your project directory. 1.7 Relative and absolute paths Paths define the location of files within the file system. There are two ways to point to a file from within a command prompt such as R. The first is to use what is called an absolute path: this describes the full sequence of folders a file is contained in, starting from the root directory of a computer. When you right click on any file on your computer, you can look up its absolute path in the Properties. This is an example of an absolute path: C:/Users/MJS/Documents/PhD/Planning/schedule_2021.csv Relative paths describe the position of a file with respect to a reference directory. In R, that reference directory is your working directory. When you type a relative path to open a file in R, R appends that path to the path of the working directory to get the full absolute path, which it then uses to open the file. For example, if our working directory was “Documents”, this would be the relative path to reach the same file as above: PhD/Planning/schedule_2021.csv If our working directory was “Planning”, this would be the relative path to the same file: schedule_2021.csv To work across subfolders of our working directory, we can just use relative paths to navigate and locate files. But relative paths also work to navigate across folders that are outside of the working directory, if need be. Using “../” in front of a folder name navigates to the parent of that folder (“parent” means the folder where that is contained.) Let’s consider the following directory structure: Figure 1.4: Example directory structure We can navigate to a file into “PhD/Research” from “Planning” like so: ../Research/GreenFrogs/data-cleaning.RProj The “../” means “the parent directory of the working directory”, which is “PhD”. We can also stack these to navigate further up the directory tree: ../../../../DAJ The path above navigates all the way up to “Users” and into a different user’s directory. 1.7.1 Path separators Something to be mindful of is that the separator between folder names in a path is different on different operating systems. On Windows, it is a backslash (“\"), while on Mac/Linux, it is a slash (”/“). However, R uses the Mac/Linux convention, so always use”/\" when typing paths in R. 1.7.2 References Wilson G, Bryan J, Cranston K, Kitzes J, Nederbragt L, Teal TK (2017) Good enough practices in scientific computing. PLoS Comput Biol 13(6): e1005510. https://doi.org/10.1371/journal.pcbi.1005510 https://speakerdeck.com/jennybc/how-to-name-files https://r4ds.had.co.nz/workflow-projects.html "],
["version-control-git.html", "Chapter 2 Version Control with Git 2.1 Command line basics 2.2 Configuring Git 2.3 Getting help 2.4 Creating a repository 2.5 Tracking files 2.6 Ignoring files 2.7 The 3 states 2.8 Un-staging files 2.9 Recovering a previous version of a file 2.10 Removing Git 2.11 Git everyday 2.12 References", " Chapter 2 Version Control with Git Git is a version control system. It tracks all the changes you make to your files and allows you to go back to previous versions as far back in time as you need. Git is useful for a variety of reasons. Most of us are familiar with folders that look like this: Messy folder Saving multiple versions of files like this is problematic because, first, it uses space inefficiently (even if files are small, multiple versions add up and end up wasting a lot of room on our computers); second, and perhaps most importantly, it creates confusion and makes our workflow prone to errors. Instead of manually saving edits to a file in a separate copy “just in case”, and instead of having to keep track of which is the most recent version, we can put our files under version control and let Git keep track of the changes we make. Git will record a history of changes to each file without duplicating it, and we’ll be able to revert to any previous version in the history of that file. Version control allows us to be clean and tidy in our file organization, optimizing use of space without ever fearing to lose any of our work. Once a file is tracked by Git, it is virtually impossible to do anything irreversible to it. I haven’t mentioned anything yet about the benefits of version control for collaborative work. This is because at its core, Git works locally on your computer. We often tend to think of version control as the way to handle multiple users working on the same file simultaneously, but Git is first and foremost a tool for your own file organization. Git is installed and runs on your machine, not on a network. It is the integration with an external server, be it private or public (GitHub and GitLab, for example, are public server providers), that makes Git a tool for multiple-user applications. This chapter focuses on the local functionalities of Git, while we’ll dive into its benefits for collaborative projects in the next Chapter. 2.1 Command line basics You can use Git from the command line in the computer’s terminal. The command line can be intimidating if you haven’t used it before, but using Git only requires basic familiarity with it. Commands are slightly different between operating systems, so I’ll assume Windows is the most commonly used and specify the Mac/Linux alternative when applicable. When you open up the terminal (or command prompt) on your computer, you’ll see a symbol, on many computers it is a “$” or “&gt;”, followed by a blinking cursor. That symbol is called the prompt, and it means the terminal is waiting for your input. If you copy-paste any code from this chapter into your terminal, make sure you only copy the part after the prompt. Also, if Ctrl+V does not work in the terminal, you can right-click to paste. When you open the terminal, you should automatically be located in the root directory of your file system (or your home directory, if you have a computer with multiple users). The name of the folder you’re in appears right before the prompt. For example, this is what my prompt looks like: C:\\Users\\Simona&gt; If you are not in your root directory when you first open up the terminal, you can use the following command to navigate to it: &gt; cd \\ This command stands for “change directory”. The “\" symbol indicates the root directory. On Mac/Linux, you can navigate to the root directory by simply typing”cd\" or: &gt; cd ~ If you want to go to a specific directory other than the root, you can type its path (relative to the folder you’re currently in) after “cd”. To go from Usersto Users: &gt; cd Documents If you want to go back to the parent of the current directory (the folder that contains it), you can use: &gt; cd .. To go back to Users from Documents: &gt; cd ..\\.. To go back to Documents from Users: &gt; cd Simona\\Documents 2.2 Configuring Git Once Git is installed on our computer, we need to do a few one-time steps to configure it. Let’s set up our name and our email address by typing the following in the terminal: &gt; git config --global user.name &quot;First Last&quot; &gt; git config --global user.email &quot;first.last@example.com&quot; This will be important when we start using GitHub. If you want to change these options in the future you always can, and if you want to use different options than the global ones within a specific project you can run the commands above removing “–global” while in the project directory (not the root!). There are more configuration options you can personalize, but we won’t get into that in this chapter. If you want to check what configuration options you have active, you can use: &gt; git config --list 2.3 Getting help If you need help while using Git, you can use any of the following commands to get the manual page for any of the Git verbs: &gt; git help &lt;verb&gt; &gt; git &lt;verb&gt; --help &gt; man git-&lt;verb&gt; 2.4 Creating a repository Once Git is set up and configured, we are ready to create our first repository. A repository is a directory that is under version control. Let’s use the example directory structure from Figure 1.4. First, we navigate to the folder where we want to initialize our repository. In our example’s case, that is: &gt; cd Documents\\PhD\\Research\\GreenFrogs Now we will enable Git to start tracking everything inside this folder: &gt; git init This command initializes Git. It may appear like nothing changed, but if you allow the option to show hidden files in your file explorer you will notice there is a new subfolder called .git. That folder is where Git will store all of its version control information. You don’t have to worry about the content of that folder and you can keep using your files normally like you always would. 2.5 Tracking files Creating a repository enables Git to start tracking files within it, but that does not happen automatically. We have to tell Git which files we want to track. We can check what Git is tracking so far by using: &gt; git status At the bottom, we’ll see a list of untracked files. We need to switch on tracking on those. To begin tracking a new file, we use the verb ‘add’. For example, to track a file named “green_frog_diet_data_cleaning.R” we would type: &gt; git add green_frog_diet_data_cleaning.R This works well if we want to add a specific file. If we want to start tracking the whole content of the folder, we can do: &gt; git add --all But be careful when using this command: Git is optimized to work with plain text files (for example .txt or R scripts), and it doesn’t really understand binary files (which is how Word files are stored, for example). Also, some files typically do not need to be version controlled, such as images; in fact, because they are large files, version controlling images can end up clogging your workflow. Make sure you are always aware of what exactly you’re adding when you use ‘git add –all’. When in doubt, add files one by one. There are also ways to make this process a little more distraction-proof: in the next step, we’ll see how to make sure we only track the files we want. 2.6 Ignoring files We can set up some rules to exclude from version control files that it would be superfluous or detrimental to track. Writing these down as rules can save us some time and headaches versus having to decide manually every time. We can exclude files from version control within a repository by using .gitignore. This is simply a text file that lists all the rules for files that, by default, we do not want to track. Rules can be based on the file type or patterns in the file name. Generally, there are a few criteria you can consider when deciding what to exclude from version control: File encoding (plain-text vs. binary): Git cannot track changes within binary files, so, even though you can store these files under version control, you won’t be able to use Git to compare different version, so there’s really no point in tracking these; Code-generated: anything that can be reproduced by running code does not need to be version-controlled; Size: files that are too big will slow down the functioning of Git. As a benchmark, you can keep in mind the maximum size limit enforced by GitHub, which is 100 MB – but if you follow the two criteria above, you will rarely end up with this problem because 100 MB’s worth of plain-text files is a whole lot of plain text. You can create a text file called “.gitignore” in our repository by using your default text editor (Notepad for Windows, TextEdit for MacOS, etc). The name must be exactly “.gitignore” for Git to recognize it. The file must have no extension (i.e., .txt) so go ahead and delete that (don’t worry about any warnings). Once .gitignore is created, we can start adding rules. Nothing prevents us from listing files in .gitignore one by one, but this approach is not efficient: stacked_barplot_diet_composition.jpg &lt;&gt; predicted_population_trends.jpg &lt;&gt; individual_movement_tracks.jpg &lt;&gt; capture_locations.jpg &lt;&gt; green_frog_diet_manuscript.docx &lt;&gt; green_frog_movement_manuscript.docx &lt;&gt; green_frog_demography_manuscript.docx Instead, we can use pattern matching to kill many birds with one stone. What all these files have in common is they are all either .jpg’s or .docx’s. We can use the wildcard ’*’ to signify “any character” before the file extension: .jpg &lt;&gt; .docx This will exclude any .png or .docx file from being tracked by Git in this repository. Since the images are conveniently located all together in one folder, we can also just do this: figures/ We should also add the following rules to ignore the user-specific R project files: *.Rhistory /.Rproj.user/ We can add as many rules as we like, then save the .gitignore text file when we’re done. Now, if we didn’t forget to include anything that needed to be ignored, we can safely add all our files in one go: &gt; git add --all 2.7 The 3 states Once files are tracked by Git, they can be in one of three states: modified, staged, or committed. A modified file includes edits that have not been recorded in Git yet; when we stage a modified file, we mark it as ready to be committed; when we commit that staged file, the current version gets stored in the history of that file. Git works with snapshots called “commits”, which are records of what the repository looked like at a certain point in time. By committing a file, we freeze that version of the file forever in its history and we will be able to go back to it. Then, if we edit the file again, we’ll have to tell Git when we’re ready to make a new commit by moving that file to the staging area. Note that the same command ‘git add’ is used both to start tracking a previously untracked file and to add a modified file to the staging area. Now we are ready to do our first commit. We use the following command: &gt; git commit -m &quot;First commit&quot; Each commit should be accompanied by a message, added with the flag -m. The message should describe the changes made to the file/s since the previous commit. It is a good habit to write detailed commit messages, so that when we need to go back and recover a previous version of a file, we can read the history of commits and easily find the version we are looking for. 2.8 Un-staging files It happens to the best of us. We forgot to add a certain rule to .gitignore and when we go ahead and get ready to commit our files we realized we just staged a file we didn’t want to stage. No worries, there is a way to fix that. The following command un-stages files and saves us from having to commit them: &gt; git rm --cached filename You can use pattern matching here as well, but you’ll need to put a backslash in front of the wildcard: &gt; git rm --cached \\*.jpg 2.9 Recovering a previous version of a file Git works like a time machine, allowing us to recover any previous version of a tracked file. It does so by saving snapshots of what the file looked like at each commit. So, each commit represent a point in time that we can access to retrieve the version that existed at that time. We can take a look at the commit history using: &gt; git log Here’s where current me will be grateful to past me for writing descriptive commit messages. If the commit messages do a good job of describing what changes I made to a file, it will be easy to recognize which commit is the one I want to go back to. The string of numbers and letters following the word ‘commit’ in the log is called the hash and it uniquely identifies each commit. We can revert to the version of a file from a specific commit by using the hash as follows: &gt; git checkout 9c5d9a3f52b7d43c1c0a06a94b11df5c3051ca27 -- filename.ext 2.10 Removing Git If for any reason you ever want to remove Git tracking from a repository (going back to a regular folder without version control) you can use the following command: &gt; rm -rf .git 2.11 Git everyday This chapter walked you through commands to configure git, initialize repositories, stage and un-stage files, commit changes, and revert to previous versions of a file. In practice, you may use some of these commands only once (e.g., to configure your email address when you first install Git) or when you start a new repository. In your everyday use of Git, the most important commands you need to remember are those to add and commit your changes. For everything else, feel free to refer back to this manual or other resources on the internet. 2.12 References The Carpentries lesson on Version Control with Git: http://swcarpentry.github.io/git-novice/ Pro Git book by Scott Chacon and Ben Straub: https://git-scm.com/book/en/v2 "],
["github.html", "Chapter 3 Collaborative Science with GitHub 3.1 Adding a remote to a local repository 3.2 Pushing to a remote repository 3.3 Cloning a repository 3.4 Synchronizing changes among collaborators 3.5 Resolving conflicts 3.6 Avoiding conflicts 3.7 Working with branches 3.8 Forking a repository 3.9 Pull requests 3.10 References", " Chapter 3 Collaborative Science with GitHub So far, we have gained a good understanding of how Git works locally on our computer. Now we are going to see how to work with remote repositories and use Git to collaborate with others. A remote repository is a copy of a repository that is stored elsewhere than your local copy, such as a web server or a private network server. In most cases, when collaborating, you’ll have a copy of a repository on your machine (the local repository) and a copy on a server that is accessible to others (the remote repository). The remote repository can be hosted on GitHub. There are two ways to set up your local and remote repositories to interact. One is to set up the local first and link it with a remote later. The second one is to create the remote first and “clone it” on your computer to get a local copy. If you’re starting a brand new repository you can go either way, but the first approach is what you would do if you wanted to link a repository that already exists on your local machine to a GitHub repository. 3.1 Adding a remote to a local repository Starting from an existing Git repository on your computer, you can link this to its GitHub counterpart by adding a remote URL. To set up a URL, go on the GitHub website, click on the ‘+’ sign in the top-right corner and select ‘New Repository’. img You can choose any name for your repository, but I find it intuitive to give it the same name as the folder where my local Git repository is. Since the remote repository will need to be connected to a local one, it needs to be completely empty: if there are conflicts in the content of the two repositories to begin with, Git won’t be able to link them. Therefore, do not add a README, a .gitignore file, or a license. img To connect the local and remote repositories, you can copy the URL of the remote repository and paste it in the following command in the terminal: &gt; git remote add origin https://github.com/picardis/myrepo.git ‘Origin’ is the conventional name given to a remote repository. You could use any other name, but since GitHub uses ‘origin’ as the default name when creating a repository from the website, using this convention will make things easier later. You’d need a very good reason to use a different name. To check that the remote was added correctly you can view the list of remotes associated with your local repository: &gt; git remote -v We’ll talk about branches later in this chapter, and we’ll see that a repository can have multiple branches. At a minimum, each repository includes one main branch, which is created by default when you create your repository. By default, this branch is called master. Starting in 2020, GitHub has started to switch to using main instead of master to remove unnecessary references to slavery. We like this change, because Black Lives Matter. So we’ll go ahead and rename the master branch to main: &gt; git branch -M main 3.2 Pushing to a remote repository Now it’s time to transfer an exact copy of the files in the local repository to the remote one. This action is called ‘pushing’. The first time you push, it’s a good idea to specify which branch Git should use as the default remote for the local main branch in the future. We do this by adding the flag ‘-u’ (for upstream), followed by the name of the remote and the name of the local branch that you want to link up: &gt; git push -u origin main This command is identical to the following: &gt; git push --set-upstream origin main You only have to set the upstream the first time you push a certain branch. After the upstream is set up, you will be able to just push changes to the remote repository by doing: &gt; git push You will be prompted to enter your GitHub password for the push to go through. Once you push, all the files you committed are transferred and your two repositories will mirror each other. To keep the remote repository synchronized with the local, any time you commit changes to tracked files you will also need to push them. That adds a new step to our workflow: add/stage, commit, push. 3.3 Cloning a repository The other way to get a local-remote repository pair set up is to create a GitHub repository first and clone it on your computer. In this case, it doesn’t matter whether the remote repository is empty or not, so you can add a README. Cloning a repository is also useful if you are collaborating on a project with someone on their repository. You and your collaborator/s can all have a copy of the same repository on each of your computers by cloning a shared remote repository, which will then be synchronized with changes made by anyone on the team. The person who created the repository will need to add the others as collaborators so that they’re able to clone it. To clone a repository, open the terminal and navigate to the folder where you want to download it. Then use the following command: $ git clone https://github.com/picardis/myrepo.git The repository will be copied to your computer into the folder you specified. 3.4 Synchronizing changes among collaborators The inverse of pushing is pulling, which transfers files and changes from the remote repository to the local one: $ git pull When you are working with collaborators on a shared GitHub repository, you will periodically need to pull from it to make sure your local copy is synchronized with changes somebody else might have made. You certainly need to pull before you push your own changes, because Git won’t allow you to push if the remote repository has changes that you don’t have on your local copy. If the two repositories are already up-to-date and you try to pull, nothing will happen because there are no changes on the remote repository that aren’t already in the local. If a collaborator makes a change that is in conflict with what we committed to our own local repository, when we try to pull we are going to encounter a merge conflict. Merge conflicts occur when two collaborators work on the same file at the same time. GitHub does not know how to automatically reconcile changes to the same file, and it will throw an error that we’ll need to resolve manually. 3.5 Resolving conflicts Having to deal with merge conflicts is eventually very likely when working on collaborative projects, but they can be handled and resolved without too much pain. If two collaborators edit the same file at the same time without pulling each other’s changes first, when one tries to push their changes to the remote they will get an error message that looks like this: To https://github.com/picardis/myrepo.git ! [rejected] master -&gt; master (fetch first) error: failed to push some refs to &#39;https://github.com/picardis/myrepo.git&#39; hint: Updates were rejected because the remote contains work that you do hint: not have locally. This is usually caused by another repository pushing hint: to the same ref. You may want to first integrate the remote changes hint: (e.g., &#39;git pull ...&#39;) before pushing again. hint: See the &#39;Note about fast-forwards&#39; in &#39;git push --help&#39; for details. Git is rejecting the push because it found some updates in the remote repository that have not been incorporated in the local copy. To solve this, the person who got the error will need to pull the most recent changes, merge them into their current copy, and then push the resulting file. After pulling, if we open the file where the conflict is, we’ll find that Git did not erase one person’s changes in favor of the other’s; instead, it marked the lines where conflicting changes occur. The beginning and end of the problematic chunk are highlighted, and the two versions are separated by ‘=’ signs. Now it is up to us to reconcile these changes however we consider appropriate. We could keep our own changes, keep the changes made by our collaborator, write something new to replace both, or delete the change entirely. Once the conflict is removed and the file is saved, we can proceed as usual by staging the file, committing it, and pushing it. Now, when any of the other collaborators pulls from the repository again, they will get the merged version of this file. In some cases, collaborators will make simultaneous changes to a file that are mutually exclusive – for example, one person will delete a line of code while another person will edit that same line. However, changes don’t need to be mutually exclusive for a merge conflict to happen: any time two users edit the same line of the same file at the same time (for example, two users may both add a new argument to the same function), Git is going to play it safe and call a merge conflict regardless of whether the changes contradict each other or not. Conflict resolution requires the user to verify whether the changes affect each other and if they can both stay or not. 3.6 Avoiding conflicts Merge conflicts need to be manually resolved by a person, which is time-consuming. More importantly, the person who resolves a merge conflicts is making a judgement call on what is the best way of fixing the situation. Having to introduce subjective judgement calls is perhaps the weakest spot of the entire collaborative version control workflow. Preventing conflicts from happening in the first place is better than having to fix them. There are a few things that can help prevent merge conflicts: Pull often: decreases probability that your working version is not up-to-date; Make small and frequent commits: decreases probability that your recent changes are not in other people’s working version; Organize your code in small modules: decreases probability of two users working on the same file; Working on branches or forks… more on this in the next sections. 3.7 Working with branches By default, a new repository contains a single branch: the main branch. However, we can create new branches within a repository. A branch is like a parallel universe where any changes we make on the files only exist on that branch and do not affect the main branch. Branches allow you to freely experiment with editing files and code without affecting the original project until you’re ready to merge them. The command to create a branch is: &gt; git branch my-branch To start working on the new branch, we switch to it with the following command: &gt; git checkout my-branch Or we could also create the branch and switch to it all in one: &gt; git checkout -b my-branch Where “b” stands for branch. To verify which branch we’re on, we can use ‘git log’ (we’ve used this same command before to look at the commit history): &gt; git log The word ‘HEAD’ in the output of git log is called a pointer; it tells us which branch we’re currently working on. On creation, a new branch shares the commit history of the main branch up until the moment the branch was created. After that, the two commit histories are allowed to diverge. Any changes we commit to a branch will be only effective on the that branch and not affect the others. This takes off all the pressure of making changes to your code that could potentially break your workflow downstream. Once you’ve had a chance to verify that the changes work the way you want them to, you can merge the branches back into one. To merge changes made in a branch into the main branch we use: &gt; git merge my-branch And then we can delete the ‘my-branch’ branch which is no longer needed: $ git branch -d my-branch If there are conflicting changes on the two branches we are trying to merge, Git will halt the process and issue a merge conflict similar to what we have seen before. 3.8 Forking a repository Forking a repository means creating a copy of an existing repository where you can make changes without affecting the original repository. You can technically fork your own repository, but forking is mostly used to get a copy of somebody else’s repository. For example, if you want to contribute to a project that was created by a person you don’t know, or if you want to build off of their code because it does something similar to what you need to do, you can fork their repository and work on it without their copy being affected. The cool thing about forking is that, if the owner makes changes to their repository, you can pull those changes to your fork so that your copy of the repository stays in sync with the original. Also, you can contribute your own changes by submitting them to the original repository through pull requests. This is the main difference between forking and cloning somebody else’s repository: by cloning, you won’t be able to update your copy to include new changes made in the original and you won’t be able to contribute back unless you’re added as a collaborator. Unlike all the other functionalities we have seen so far, which are Git commands, forking is a GitHub functionality. There is no built-in Git function to fork a repository from the command line. To fork a repository, go to the web page of that repository and click “Fork” in the top-right corner. This will create a copy of the repository on your GitHub account. img Now, if you also want a local copy of this repository on your computer, you can clone your fork. For example, if I forked octocat’s Spoon-Knife repository onto my GitHub account, I could then clone it onto my computer like so: &gt; git clone https://github.com/picardis/Spoon-Knife To keep my fork up-to-date with the original repository, I can configure it as follows: $ git remote add upstream https://github.com/octocat/Spoon-Knife.git Now I will be able to pull from the original repository and keep my local copy synchronized. I won’t be able to push because I do not have collaborator privileges on this repository. 3.9 Pull requests Pull requests are the way to ask that the edits you made in a fork (or a branch) get merged into the original repository (or main branch). To ask the owner of a repository to view and potentially integrate the changes you made in your own forked version, you submit a pull request. Similarly, to let your collaborators know about the edits you made and let them review them before they get merged, you submit a pull request. There is a key difference here: while as an external agent you have no other choice but submitting a pull request to merge a fork into a repository, as a collaborator you could simply merge your edits if you wanted to. If you are working on your own repository by yourself, there is no need to go through pull requests to merge a branch. But if you are collaborating with people, it is still good and courteous practice to use pull requests as a heads-up before you merge your changes, so that others on the project can review and approve them. The most straightforward way to submit a pull request is from the GitHub website. To start a pull request, you must have some changes committed to the repository or branch where you want to merge them. Then you can go to the repository page on GitHub and click on the ‘Pull requests’ tab, then click ‘New pull request’. Choose your target branch, enter a title and description, and then click ‘Send pull request’. Once the pull request is open, everyone can write comments on it, see all the commits it includes, and look at the changes it proposes within files. img Once everyone is happy with the proposed changes, you are ready to merge the pull request. If there are no merge conflicts, you will see a ‘Merge pull request’ button. 3.10 References GitHub Community Forum: https://github.community/ "],
["spreadsheets.html", "Chapter 4 Best Practices in the Use of Spreadsheets 4.1 What are spreadsheets good for? 4.2 Human-readable vs. computer-readable data 4.3 Tidy data 4.4 Problematic practices 4.5 Document, document, document! 4.6 References", " Chapter 4 Best Practices in the Use of Spreadsheets So you think you know everything about spreadsheets… think again! While probably all of us have used spreadsheets before, it’s easy to misuse them without even knowing you are doing it. This Chapter gives an overview of best practices and common mistakes to avoid. 4.1 What are spreadsheets good for? Spreadsheets are good tools for data entry. Even though you could technically run some data analyses within your spreadsheet program, that doesn’t mean you should! The main downside to doing data processing and analysis in a spreadsheet is that it entails a lot of pointing and clicking. This makes your analysis difficult to reproduce. If you need to re-run your analysis or re-process some data, you have to do it manually all over again. Also, if you go back to your completed analysis after a while (for example to write the methods of your paper) and you don’t remember what you did, there is no record of it left. This is why this course introduces spreadsheets exclusively as a tool for data entry. 4.2 Human-readable vs. computer-readable data Most of the problematic practices outlined in this Chapter can be summarized into a single concept: using spreadsheets to convey information in a way that is readable for humans but not for computers. While a human brain is capable of extracting information from context, such as spatial layout, colors, footnotes, etc., a computer is very literal and does not understand any of that. To make good use of spreadsheets, we need to put ourselves in the computer’s mind. All the computer understands from a spreadsheet is the information encoded in rows and columns. So, the number one rule to remember when using spreadsheets is to make your data “tidy”. 4.3 Tidy data Figure 4.1: Artwork by Allison Horst The fundamental definition of tidy data is quite simple: one variable per column and one observation per row. Variables are the things we are measuring (e.g., temperature, distance, height.) Observations are repeated measurements of a variable on different experimental units. Structuring your data following this rule will put you in a great position for processing and analyzing your data in an automated way. First, using a standard approach to formatting data, where the structure of a table reflects the meaning of its content (i.e., where a column always means a variable and a row always means an observation) removes any ambiguity for yourself and for the computer. Second, this specific approach works very well with programming languages, like R, that support vector calculations (i.e., calculations on entire columns or tables at a time, instead of single elements only.) 4.4 Problematic practices In practice, what are some common habits that contradict the principles of tidy data? Here are some examples. 4.4.1 Multiple variables in a single column Putting information for two separate variables into one column contradicts the “one column per variable” principle. A classic example of this is merging age class and sex into one – for example “adult female”, “juvenile male”, etc. If, for instance, later on we wanted to filter based on age only, we would have to first separate the information within the column and then apply a filter. It is much more straightforward to combine information than to split it, so the structure of our data should always follow a reductionist approach where each table unit (cell) contains a single data unit (value). img 4.4.2 Rows for variables, columns for observation While the choice of using rows for observations and columns for variables may seem arbitrary – after all, why can’t it be the other way around? – consider this: the most commonly used data structure in R, the data frame, is a collection of vectors stored as columns. A property of vectors is that they contain data of a single type (for instance, you can’t have both numbers and characters in the same vector, they either have to be all numbers or all characters). Now imagine a situation where a dataset includes weight measurements of individual green frogs captured in different ponds: for each frog, we’d have a weight value (a number) and the name of the pond where it was captured (a character string). If each frog gets a row, we get a column for weight (all numbers) and a column for pond (all characters). If each frog gets a column and weight and pond go in different rows, each column would contain a number and a character, which is not compatible with R. This is valid not only for R, but for other vector-based programming languages too. The tidy data format makes sure your data integrates well with your analysis software which means less work for you getting the data cleaned and ready. img 4.4.3 Multiple tables in a single spreadsheet Creating multiple tables in a single spreadsheet is problematic because, while a human can see the layout (empty cells to visually separate different tables, borders, etc.) and interpret the tables as separate, the computer doesn’t have eyes and won’t understand that these are separate. Two values on the same row will be interpreted as belonging to the same experimental unit. Having multiple tables within a single spreadsheet draws false associations between values in the data. Starting from this format will invariably require some manual steps to get the data into a format the computer will read. Not good for reproducibility! img 4.4.4 Multiple sheets This one may seem innocuous, but actually it can be problematic as well. For starters, you can’t load multiple sheets into R at the same time (by multiple sheets, I mean the tabs at the bottom). If you’re only using base R functions, you can’t even load a .xslx file (although you can using packages such as readxl), so you’re going to have to save your spreadsheets as .csv before importing. When saving as .csv, you’ll only be able to save one sheet at a time. If you’re not aware of this, you end up losing track of the data that was in the other sheets. Even if you are aware, it just makes it more work for you to save each of the sheets separately. Using multiple sheets becomes even more of a problem when you are saving the same type of information into separate sheets, like for example the same type of data collected during different surveys or years. This contradicts another principle of tidy data, which is each type of observational unit forms a table. There’s no reason to split a table into multiple ones if they all contain the same type of observational unit (e.g., morphometric measurements of frogs from different ponds). Instead, you can just add an extra column for the survey number or year. This way you avoid inadvertently introducing inconsistencies in format when entering data, and you save yourself the work of having to merge multiple sheets into one when you start processing and analyzing. img 4.4.5 Using formatting to convey information Anything that has to do with visual formatting is not computer-readable. This includes borders, merging cells, colors, etc. When you load the data into an analysis software, all the graphical features are lost and all that is left is… rows and columns. Resisting the temptation to merge cells, and instead repeating the value across all rows/columns that it applies to, is making your data computer-friendly. Resisting the urge to color-code your data, and instead adding an additional column to encode the information you want to convey with the different colors, is making your data computer-friendly. Columns are cheap and there’s no such thing as too many of them. img 4.4.6 Putting units in cells Ideally, each measurement of a variable should be recorded in the same units. In this case, you can add the unit to the column name. But even if a column includes measurements in different units, these units should never go after the values in the cells. Adding units will make your processing/analysis software read that column as a character rather than as a numeric variable. Instead, if you need to specify which unit each measurement was taken in, add a new column called “variable_unit” and report it there. Remember, columns are cheap! img 4.4.7 Using problematic column names Problematic column names are a lot like the problematic file names from Chapter 1. They are non-descriptive, they contain spaces or special characters – in short, they are human-readable but not computer-readable. Whether you separate words in column names using camel case or underscores, avoid using spaces. It’s a good idea to include units in the column names, e.g., “weight_g”, “distance_km”, etc. Also, just like for file names, be consistent in your capitalization pattern and choice of delimiters. img 4.4.8 Conflating zeros and missing values Conflating zero measurements with missing values by using a zero or a blank cell as interchangeable is a problem, because there’s a big difference between something you didn’t measure and something that you did measure and it was zero. Any blank cell will be interpreted as missing data by your processing/analysis software, so if something is zero it needs to be actually entered as a zero, not just left blank. Similarly, never use zero as your value for missing data. These are two separate meanings that need to be encoded with different values. 4.4.9 Using problematic null values Many common ways to encode missing values are problematic because processing/analysis software does not interpret them correctly. For example, “999” or “-999” is a common choice to signify missing values. However, computers are very literal, and those are numbers. You may end up accidentally including those numbers in your calculations without realizing because your software did not recognize them as missing values. Similarly, like we said, “0” is indistinguishable from a true zero and should never be used to signify “missing data”. Worded options, such as “Unknown”, “Missing”, or “No data” should be avoided because including a character value into a column that is otherwise numeric will cause the entire column to be read as character by R, and you won’t be able to do math on the numbers. Using the native missing value encoding from your most used programming language (e.g., NA for R, NULL for SQL, etc.) is a good option, although it can also be interpreted as text in some instances. The recommended way to go is to simply leave missing values blank. The downside to this is that, while you’re entering data, it can be tricky to remember which cells you left blank because the data is missing and which ones are blank because you haven’t filled them yet. Also, if you accidentally enter a space in an empty cell, it will look like it’s blank when it actually is not. 4.4.9.1 Inconsistent value formatting A very common problem arises when having to filter/tally/organize data based on a criterion that was recorded inconsistently in the data. I find this to be especially common for columns containing character-type variables. For example, if the person entering data used “F” or “Female” or “f” interchangeably in the “sex” column, it will be difficult later on to know how many female individuals are in the dataset. Similarly, if the column “observer” contains the name of the same person written in multiple different ways (e.g., “Mary Brown”, “Mary Jean Brown”, “M. Brown”, “MJ Brown”), these won’t be recognized as the same person unless these inconsistencies are fixed later on. 4.5 Document, document, document! If you follow all the guidelines outlined in this Chapter, chances are you will be able to automate all of your data processing without having to do anything manually, because the data will be in a computer-readable format to begin with. However, if you do end up having to do some manual processing, make sure you thoroughly document every step. Like we discussed in Chapter 1, never edit your raw data; save processed/cleaned versions as new files; and describe all the steps you took to get from the raw data to the clean data in your README file. 4.6 References https://datacarpentry.org/spreadsheet-ecology-lesson Wickham, Hadley. “Tidy data.” Journal of Statistical Software 59.10 (2014): 1-23. White, Ethan P., et al. “Nine simple ways to make it easier to (re) use your data.” Ideas in Ecology and Evolution 6.2 (2013). "],
["relational-databases.html", "Chapter 5 Relational Databases 5.1 What is a relational database? 5.2 Why bothering with relational databases? 5.3 Database components 5.4 Database design and architecture 5.5 Data types 5.6 A first look at our practice database", " Chapter 5 Relational Databases 5.1 What is a relational database? A relational database is a collection of interrelated tables. The relationships between tables represent actual relationships between data entities. The relationships between data entities always exist in real life, no matter our choice of data management system; but they are only made explicit to the computer when the data are stored in a relational database. For example, say that we collected data in the field for green frogs where, the first time an individual is captured, we record its sex, take some biometric measurements, and assign it an ID. Then, the animals are recaptured periodically to take new biometric measurements. We’d store our data in two spreadsheets, one that has a list of all the frogs we’ve ever captured with their ID and sex. The second spreadsheet has all the biometric measurements, and each frog ID may appear more than once. The two spreadsheets are related because they both contain information about the same individuals: the first one contains one-time information, and the second one contains repeated records for each individual. However, the computer does not know about this relationship, only we do. By using a relational database we translate real-world relationships between data entities into structural relationships between our data tables. 5.2 Why bothering with relational databases? You may ask, why should we care to enforce structural relationships between tables? Isn’t it enough to just know how things are related? Well, the first advantage of relational databases is that they force us to think critically about the real-life relationships between data entities, which we often take for granted and we might overlook. Many problems with data inconsistencies directly stem from not having a robust logical structure to our data organization. Enforcing a logical data structure goes hand in hand with quality control and assurance. By designing a mental map of what the different pieces of information look like and how they relate to one another, we can easily spot conditions that need to be verified in order for the data to make sense. If any of those conditions aren’t verified, something isn’t right. For example, imagine having a table of capture and mortality dates for the frogs in addition to biometric measurements. It is logically impossible for any of the biometrics measurements of an individual to be taken outside of the interval between first capture and death. If we store our data in spreadsheets, we may not even notice if there’s a record supposedly taken before an individual was captured or after it died. But if we make the relationship between the two tables explicit, the computer will recognize impossible situations like these for us. Another advantage of relational databases is that they allow for optimal data storage by avoiding redundancy of information across tables. There is no need to repeat the same data across multiple tables because the relationships between tables allow us to cross-link data across them. For example, there is no need to repeat the sex and capture date of an individual frog for each biometrics measurement we take of that individual. As long as we can relate the two tables based on the individual ID, we can always retrieve and combine information across them. This improves accuracy by avoiding duplication and it reduces the space our data occupies on our computer. There are several more advantages to using relational databases, including fast (like, extremely fast) processing over large amounts of data. If the database is stored on an external server, that also helps managing data across collaborators within a project by having a centralized repository that everybody can connect to and use, which means everyone always has the same and most up-to-date version of the data. It’s also possible to set up user profiles with different privileges, like read-and-write or read-only. Storing the database on an external server also means that data processing and computation don’t happen on your local computer and thus they don’t take up your memory, which is often limited. Finally, concepts of relational database management are key to understanding data manipulation in other languages. 5.3 Database components The core unit of a relational database is a table: a two-dimensional structure composed by rows (or records), and columns (or fields). Each row is an observation and each column is a variable (sounds familiar? We talked about tidy data in 4.3) Tables relate to one another through foreign keys. A foreign key is a variable that is shared between two tables. For instance, in the frogs example above, the individual ID is the variable relating each biometric measurement to the static features of each individual (sex, first capture date, mortality date.) Foreign keys are what makes relational databases “relational”. A table can have one or more foreign keys, each relating it to another table. In addition to foreign keys, each table in a relational database also has a primary key. A primary key is a unique identifier for each record in the table. Sometimes one variable lends itself well to being a primary key, for example the individual ID would be a suitable primary key for the table of static individual information, because each individual appears only once and thus the ID is a unique identifier of rows. However, the individual ID would not be a suitable primary key for the table of biometric measurements, because IDs are repeated and therefore not unique. When there isn’t a suitable variable to serve as a primary key, we can simply add a serial number that uniquely identifies each record. 5.4 Database design and architecture The structure of a database should reflect real-world structure in the data. The way we split data into tables and the relationships we enforce between them should mirror the real way data entities relate to one another. Designing a database has little to do with software and coding and everything to do with thinking about the real structure in our data and how can we best represent it using the building blocks of a database. In general, tables should we split based on the sampling unit of the data they contain. For example, data on individual frogs and data on the ponds where the frogs came from should be stored in separate tables. One table has the frog as its unit and one has the pond. These two tables could then be put in relation based on the pond each frog was caught in. Two tables may still deserve to be split even if they refer to the same real-world sampling unit. The example we made at the beginning where we have a table of individual ID and sex and a table of individual biometric measurements is a good illustration for this. In both of those tables, the sampling unit is an individual frog, but the first table contains static information that does not change through time, whereas the second table contains dynamic information, which translates into repeated measures for each individual. Instead of keeping these data together into a single table and repeating the static information at each of the repeated individual records, it is much more efficient to split the static and dynamic information. We can always put the two tables in relation based on the frog ID. A database should also be designed so that each column only contains atomic values, which means values that cannot be further divided. This means, for example, separating first and last name into two columns instead of a “full name” column (not talking about frogs here.) It also means lists of several items are not allowed within one cell. Whenever we find ourselves in a situation where we need to enter a list of items inside a single cell, it means that the structure of the current table is not optimized and we need to rethink it. For example, let’s say that we are collecting data on frog diet. Each diet sample may contain multiple food items, e.g., a fly, an ant, a beetle, a cricket. If our diet table uses the diet sample as a unit (one sample per row), we’ll end up with a list of multiple entries in the “food item” column, which would no longer be atomic. A good alternative would be to use the food item as the unit of the table instead. We can have one food item per row and repeat the ID of the diet sample for each item that was found in that sample. 5.5 Data types Data types define what kind of data is stored in each column of a table. Different database systems recognize different sets of data types, but the most fundamental are common to many. These include character strings, numerical values (and special cases of these, such as integers), boolean values (TRUE or FALSE), etc. Because each column in a table has a data type associated to it, it means that you can’t mix data types inside the same column. You can’t, for example, use both “5” (for 5-year-old) and “adult” in an “age” column. 5.6 A first look at our practice database In the next chapter, we are going to take a deep dive into SQL, the most used programming language for relational databases. We are going to learn how to write queries to retrieve data and how to build the database itself. The database we’ll practice with includes imaginary data on dragons. Let’s take a look at the content and structure: Figure 5.1: Diagram of the dragons database The database is composed of 9 tables. The dragons table includes individual information on the sample individuals. The captures table contains information on when and where each dragon was captured, and it’s linked to the capture sites table which stores the coordinates of each capture site. The morphometrics table contains body measurements and the diet table contains information on diet samples. Both of these are linked to the dragons table based on individual IDs. We also tracked some of these dragons, so we have a tags table which lists all the different GPS units we deployed within the project. The deployments table tells us which dragon was wearing each tag at any given time, and therefore it’s linked to both the dragons and the tags table through the dragon IDs and the tag IDs, respectively. A raw GPS data table contains telemetry data in its raw form, i.e., as it comes out of the tags, and it’s therefore linked to the tags table via the tag ID. Finally, a processed GPS data table associates the tracking data to the dragons. Primary keys are in italics and foreign keys are in bold. Connectors link tables with one another based on their foreign keys. "],
["sql.html", "Chapter 6 Basics of SQL Language 6.1 The SQL language 6.2 Writing SQL queries 6.3 Building a database", " Chapter 6 Basics of SQL Language 6.1 The SQL language The acronym SQL stands for Structured Query Language. It is the most used language worldwide for relational database management systems. Whenever you interact with a database in your daily life (for example, any time you browse an online shopping website, or any time you look up something on Google), you can bet that it was written in SQL. SQL is a language that is used and understood by different database management systems, such as Oracle, PostgreSQL, MySQL, or SQLite. While all these programs share many similarities, which one of these you’ll end up using depends on the specifics of what you need it for. For the purposes of this class, we’ll be using SQLite. SQLite provides all the core functionalities you’ll need to get familiar with databases while being lightweight in terms of setup (easy to install and to configure). At the end of this chapter, we’ll talk about why you may want to make a different choice in the future, but for now we’ll stick with SQLite. Each database management program uses a slightly different dialect of SQL. The language is the same, but there may be some slight differences in the syntax between different programs. I’ll point out throughout the chapter when we encounter syntax that is specific to the SQLite dialect. 6.2 Writing SQL queries The nice thing about SQL is that it sounds a lot like human language. An SQL statement, or query, always begins with a verb that describes the action we want to do. A semicolon at the end of the query lets SQL know that we are done talking. For example: SELECT dragon_id FROM dragons; ## dragon_id ## 1 D1 ## 2 D10 ## 3 D100 ## 4 D101 ## 5 D102 ## 6 D103 ## 7 D104 ## 8 D105 ## 9 D106 ## 10 D107 ## 11 D108 ## 12 D109 ## 13 D11 ## 14 D110 ## 15 D111 ## 16 D112 ## 17 D113 ## 18 D114 ## 19 D115 ## 20 D116 ## 21 D117 ## 22 D118 ## 23 D119 ## 24 D12 ## 25 D120 ## 26 D121 ## 27 D122 ## 28 D123 ## 29 D124 ## 30 D125 ## 31 D126 ## 32 D127 ## 33 D128 ## 34 D129 ## 35 D13 ## 36 D130 ## 37 D131 ## 38 D132 ## 39 D133 ## 40 D134 ## 41 D135 ## 42 D136 ## 43 D137 ## 44 D138 ## 45 D139 ## 46 D14 ## 47 D140 ## 48 D141 ## 49 D142 ## 50 D143 ## 51 D144 ## 52 D145 ## 53 D146 ## 54 D147 ## 55 D148 ## 56 D149 ## 57 D15 ## 58 D150 ## 59 D151 ## 60 D152 ## 61 D153 ## 62 D154 ## 63 D155 ## 64 D156 ## 65 D157 ## 66 D158 ## 67 D159 ## 68 D16 ## 69 D160 ## 70 D161 ## 71 D162 ## 72 D163 ## 73 D164 ## 74 D165 ## 75 D166 ## 76 D167 ## 77 D168 ## 78 D169 ## 79 D17 ## 80 D170 ## 81 D171 ## 82 D172 ## 83 D173 ## 84 D174 ## 85 D175 ## 86 D176 ## 87 D177 ## 88 D178 ## 89 D179 ## 90 D18 ## 91 D180 ## 92 D181 ## 93 D182 ## 94 D183 ## 95 D184 ## 96 D185 ## 97 D186 ## 98 D187 ## 99 D188 ## 100 D189 ## 101 D19 ## 102 D190 ## 103 D191 ## 104 D192 ## 105 D193 ## 106 D194 ## 107 D195 ## 108 D196 ## 109 D197 ## 110 D198 ## 111 D199 ## 112 D2 ## 113 D20 ## 114 D200 ## 115 D201 ## 116 D202 ## 117 D203 ## 118 D204 ## 119 D205 ## 120 D206 ## 121 D207 ## 122 D208 ## 123 D209 ## 124 D21 ## 125 D210 ## 126 D211 ## 127 D212 ## 128 D213 ## 129 D214 ## 130 D215 ## 131 D216 ## 132 D217 ## 133 D218 ## 134 D219 ## 135 D22 ## 136 D220 ## 137 D221 ## 138 D222 ## 139 D223 ## 140 D224 ## 141 D225 ## 142 D226 ## 143 D227 ## 144 D228 ## 145 D229 ## 146 D23 ## 147 D230 ## 148 D231 ## 149 D232 ## 150 D233 ## 151 D234 ## 152 D235 ## 153 D236 ## 154 D237 ## 155 D238 ## 156 D239 ## 157 D24 ## 158 D240 ## 159 D241 ## 160 D242 ## 161 D243 ## 162 D244 ## 163 D245 ## 164 D246 ## 165 D247 ## 166 D248 ## 167 D249 ## 168 D25 ## 169 D250 ## 170 D251 ## 171 D252 ## 172 D253 ## 173 D254 ## 174 D255 ## 175 D256 ## 176 D257 ## 177 D258 ## 178 D259 ## 179 D26 ## 180 D260 ## 181 D261 ## 182 D262 ## 183 D263 ## 184 D264 ## 185 D265 ## 186 D266 ## 187 D267 ## 188 D268 ## 189 D269 ## 190 D27 ## 191 D270 ## 192 D271 ## 193 D272 ## 194 D273 ## 195 D274 ## 196 D275 ## 197 D276 ## 198 D277 ## 199 D278 ## 200 D279 ## 201 D28 ## 202 D280 ## 203 D281 ## 204 D282 ## 205 D283 ## 206 D284 ## 207 D285 ## 208 D286 ## 209 D287 ## 210 D288 ## 211 D289 ## 212 D29 ## 213 D290 ## 214 D291 ## 215 D292 ## 216 D293 ## 217 D294 ## 218 D295 ## 219 D296 ## 220 D297 ## 221 D298 ## 222 D299 ## 223 D3 ## 224 D30 ## 225 D300 ## 226 D301 ## 227 D302 ## 228 D303 ## 229 D304 ## 230 D305 ## 231 D306 ## 232 D307 ## 233 D308 ## 234 D309 ## 235 D31 ## 236 D310 ## 237 D311 ## 238 D312 ## 239 D313 ## 240 D314 ## 241 D315 ## 242 D316 ## 243 D317 ## 244 D318 ## 245 D319 ## 246 D32 ## 247 D320 ## 248 D321 ## 249 D322 ## 250 D323 ## 251 D324 ## 252 D325 ## 253 D326 ## 254 D327 ## 255 D328 ## 256 D329 ## 257 D33 ## 258 D330 ## 259 D331 ## 260 D332 ## 261 D333 ## 262 D334 ## 263 D335 ## 264 D336 ## 265 D337 ## 266 D338 ## 267 D339 ## 268 D34 ## 269 D340 ## 270 D341 ## 271 D342 ## 272 D343 ## 273 D344 ## 274 D345 ## 275 D346 ## 276 D347 ## 277 D348 ## 278 D349 ## 279 D35 ## 280 D350 ## 281 D351 ## 282 D352 ## 283 D353 ## 284 D354 ## 285 D355 ## 286 D356 ## 287 D357 ## 288 D358 ## 289 D359 ## 290 D36 ## 291 D360 ## 292 D361 ## 293 D362 ## 294 D363 ## 295 D364 ## 296 D365 ## 297 D366 ## 298 D367 ## 299 D368 ## 300 D369 ## 301 D37 ## 302 D370 ## 303 D371 ## 304 D372 ## 305 D373 ## 306 D374 ## 307 D375 ## 308 D376 ## 309 D377 ## 310 D378 ## 311 D379 ## 312 D38 ## 313 D380 ## 314 D381 ## 315 D382 ## 316 D383 ## 317 D384 ## 318 D385 ## 319 D386 ## 320 D387 ## 321 D388 ## 322 D389 ## 323 D39 ## 324 D390 ## 325 D391 ## 326 D392 ## 327 D393 ## 328 D394 ## 329 D395 ## 330 D396 ## 331 D397 ## 332 D398 ## 333 D399 ## 334 D4 ## 335 D40 ## 336 D400 ## 337 D401 ## 338 D402 ## 339 D403 ## 340 D404 ## 341 D405 ## 342 D406 ## 343 D407 ## 344 D408 ## 345 D409 ## 346 D41 ## 347 D410 ## 348 D411 ## 349 D412 ## 350 D413 ## 351 D414 ## 352 D415 ## 353 D416 ## 354 D417 ## 355 D418 ## 356 D419 ## 357 D42 ## 358 D420 ## 359 D421 ## 360 D422 ## 361 D423 ## 362 D424 ## 363 D425 ## 364 D426 ## 365 D427 ## 366 D428 ## 367 D429 ## 368 D43 ## 369 D430 ## 370 D431 ## 371 D432 ## 372 D433 ## 373 D434 ## 374 D435 ## 375 D436 ## 376 D437 ## 377 D438 ## 378 D439 ## 379 D44 ## 380 D440 ## 381 D441 ## 382 D442 ## 383 D443 ## 384 D444 ## 385 D445 ## 386 D446 ## 387 D447 ## 388 D448 ## 389 D449 ## 390 D45 ## 391 D450 ## 392 D451 ## 393 D452 ## 394 D453 ## 395 D454 ## 396 D455 ## 397 D456 ## 398 D457 ## 399 D458 ## 400 D459 ## 401 D46 ## 402 D460 ## 403 D461 ## 404 D462 ## 405 D463 ## 406 D464 ## 407 D465 ## 408 D466 ## 409 D467 ## 410 D468 ## 411 D469 ## 412 D47 ## 413 D470 ## 414 D471 ## 415 D472 ## 416 D473 ## 417 D474 ## 418 D475 ## 419 D476 ## 420 D477 ## 421 D478 ## 422 D479 ## 423 D48 ## 424 D480 ## 425 D481 ## 426 D482 ## 427 D483 ## 428 D484 ## 429 D485 ## 430 D486 ## 431 D487 ## 432 D488 ## 433 D489 ## 434 D49 ## 435 D490 ## 436 D491 ## 437 D492 ## 438 D493 ## 439 D494 ## 440 D495 ## 441 D496 ## 442 D497 ## 443 D498 ## 444 D499 ## 445 D5 ## 446 D50 ## 447 D500 ## 448 D51 ## 449 D52 ## 450 D53 ## 451 D54 ## 452 D55 ## 453 D56 ## 454 D57 ## 455 D58 ## 456 D59 ## 457 D6 ## 458 D60 ## 459 D61 ## 460 D62 ## 461 D63 ## 462 D64 ## 463 D65 ## 464 D66 ## 465 D67 ## 466 D68 ## 467 D69 ## 468 D7 ## 469 D70 ## 470 D71 ## 471 D72 ## 472 D73 ## 473 D74 ## 474 D75 ## 475 D76 ## 476 D77 ## 477 D78 ## 478 D79 ## 479 D8 ## 480 D80 ## 481 D81 ## 482 D82 ## 483 D83 ## 484 D84 ## 485 D85 ## 486 D86 ## 487 D87 ## 488 D88 ## 489 D89 ## 490 D9 ## 491 D90 ## 492 D91 ## 493 D92 ## 494 D93 ## 495 D94 ## 496 D95 ## 497 D96 ## 498 D97 ## 499 D98 ## 500 D99 The verb SELECT is one we’ll be using over and over again. Any time you want to select data you also have to specify which table you want it from, so the SELECT clause is always followed by a FROM clause. In this case, we asked to see the column dragon_id from the dragons table. Sounds like English, right? If we want to see multiple columns, we can list them separated by commas: SELECT dragon_id, sex FROM dragons; ## dragon_id sex ## 1 D1 F ## 2 D2 &lt;NA&gt; ## 3 D3 F ## 4 D4 F ## 5 D5 &lt;NA&gt; ## 6 D6 F ## 7 D7 M ## 8 D8 &lt;NA&gt; ## 9 D9 F ## 10 D10 F ## 11 D11 F ## 12 D12 F ## 13 D13 &lt;NA&gt; ## 14 D14 &lt;NA&gt; ## 15 D15 &lt;NA&gt; ## 16 D16 F ## 17 D17 F ## 18 D18 F ## 19 D19 F ## 20 D20 M ## 21 D21 F ## 22 D22 &lt;NA&gt; ## 23 D23 M ## 24 D24 &lt;NA&gt; ## 25 D25 M ## 26 D26 &lt;NA&gt; ## 27 D27 F ## 28 D28 M ## 29 D29 F ## 30 D30 F ## 31 D31 &lt;NA&gt; ## 32 D32 M ## 33 D33 F ## 34 D34 F ## 35 D35 F ## 36 D36 &lt;NA&gt; ## 37 D37 F ## 38 D38 F ## 39 D39 &lt;NA&gt; ## 40 D40 &lt;NA&gt; ## 41 D41 &lt;NA&gt; ## 42 D42 M ## 43 D43 F ## 44 D44 M ## 45 D45 F ## 46 D46 M ## 47 D47 F ## 48 D48 M ## 49 D49 &lt;NA&gt; ## 50 D50 F ## 51 D51 F ## 52 D52 M ## 53 D53 &lt;NA&gt; ## 54 D54 F ## 55 D55 &lt;NA&gt; ## 56 D56 F ## 57 D57 F ## 58 D58 M ## 59 D59 F ## 60 D60 F ## 61 D61 M ## 62 D62 F ## 63 D63 F ## 64 D64 &lt;NA&gt; ## 65 D65 &lt;NA&gt; ## 66 D66 &lt;NA&gt; ## 67 D67 M ## 68 D68 M ## 69 D69 F ## 70 D70 F ## 71 D71 M ## 72 D72 &lt;NA&gt; ## 73 D73 F ## 74 D74 &lt;NA&gt; ## 75 D75 M ## 76 D76 M ## 77 D77 &lt;NA&gt; ## 78 D78 &lt;NA&gt; ## 79 D79 M ## 80 D80 F ## 81 D81 &lt;NA&gt; ## 82 D82 F ## 83 D83 &lt;NA&gt; ## 84 D84 M ## 85 D85 F ## 86 D86 F ## 87 D87 M ## 88 D88 M ## 89 D89 F ## 90 D90 M ## 91 D91 F ## 92 D92 M ## 93 D93 M ## 94 D94 M ## 95 D95 M ## 96 D96 F ## 97 D97 &lt;NA&gt; ## 98 D98 &lt;NA&gt; ## 99 D99 F ## 100 D100 &lt;NA&gt; ## 101 D101 &lt;NA&gt; ## 102 D102 F ## 103 D103 F ## 104 D104 F ## 105 D105 M ## 106 D106 &lt;NA&gt; ## 107 D107 &lt;NA&gt; ## 108 D108 F ## 109 D109 M ## 110 D110 F ## 111 D111 M ## 112 D112 F ## 113 D113 &lt;NA&gt; ## 114 D114 &lt;NA&gt; ## 115 D115 F ## 116 D116 F ## 117 D117 &lt;NA&gt; ## 118 D118 &lt;NA&gt; ## 119 D119 F ## 120 D120 F ## 121 D121 &lt;NA&gt; ## 122 D122 F ## 123 D123 &lt;NA&gt; ## 124 D124 M ## 125 D125 &lt;NA&gt; ## 126 D126 M ## 127 D127 M ## 128 D128 &lt;NA&gt; ## 129 D129 M ## 130 D130 &lt;NA&gt; ## 131 D131 &lt;NA&gt; ## 132 D132 F ## 133 D133 F ## 134 D134 F ## 135 D135 &lt;NA&gt; ## 136 D136 F ## 137 D137 F ## 138 D138 F ## 139 D139 F ## 140 D140 &lt;NA&gt; ## 141 D141 F ## 142 D142 M ## 143 D143 F ## 144 D144 M ## 145 D145 M ## 146 D146 M ## 147 D147 &lt;NA&gt; ## 148 D148 &lt;NA&gt; ## 149 D149 M ## 150 D150 F ## 151 D151 &lt;NA&gt; ## 152 D152 F ## 153 D153 M ## 154 D154 F ## 155 D155 F ## 156 D156 M ## 157 D157 F ## 158 D158 &lt;NA&gt; ## 159 D159 &lt;NA&gt; ## 160 D160 F ## 161 D161 F ## 162 D162 F ## 163 D163 &lt;NA&gt; ## 164 D164 &lt;NA&gt; ## 165 D165 M ## 166 D166 &lt;NA&gt; ## 167 D167 M ## 168 D168 F ## 169 D169 F ## 170 D170 &lt;NA&gt; ## 171 D171 M ## 172 D172 M ## 173 D173 F ## 174 D174 &lt;NA&gt; ## 175 D175 M ## 176 D176 F ## 177 D177 F ## 178 D178 F ## 179 D179 &lt;NA&gt; ## 180 D180 F ## 181 D181 F ## 182 D182 F ## 183 D183 F ## 184 D184 F ## 185 D185 M ## 186 D186 &lt;NA&gt; ## 187 D187 &lt;NA&gt; ## 188 D188 M ## 189 D189 F ## 190 D190 F ## 191 D191 M ## 192 D192 M ## 193 D193 M ## 194 D194 &lt;NA&gt; ## 195 D195 F ## 196 D196 F ## 197 D197 F ## 198 D198 M ## 199 D199 &lt;NA&gt; ## 200 D200 &lt;NA&gt; ## 201 D201 &lt;NA&gt; ## 202 D202 M ## 203 D203 &lt;NA&gt; ## 204 D204 M ## 205 D205 F ## 206 D206 F ## 207 D207 &lt;NA&gt; ## 208 D208 M ## 209 D209 &lt;NA&gt; ## 210 D210 M ## 211 D211 F ## 212 D212 F ## 213 D213 &lt;NA&gt; ## 214 D214 F ## 215 D215 F ## 216 D216 &lt;NA&gt; ## 217 D217 F ## 218 D218 F ## 219 D219 M ## 220 D220 F ## 221 D221 M ## 222 D222 M ## 223 D223 M ## 224 D224 &lt;NA&gt; ## 225 D225 M ## 226 D226 &lt;NA&gt; ## 227 D227 F ## 228 D228 F ## 229 D229 &lt;NA&gt; ## 230 D230 M ## 231 D231 M ## 232 D232 F ## 233 D233 F ## 234 D234 F ## 235 D235 &lt;NA&gt; ## 236 D236 F ## 237 D237 M ## 238 D238 F ## 239 D239 F ## 240 D240 F ## 241 D241 &lt;NA&gt; ## 242 D242 M ## 243 D243 &lt;NA&gt; ## 244 D244 F ## 245 D245 &lt;NA&gt; ## 246 D246 &lt;NA&gt; ## 247 D247 M ## 248 D248 M ## 249 D249 &lt;NA&gt; ## 250 D250 F ## 251 D251 &lt;NA&gt; ## 252 D252 &lt;NA&gt; ## 253 D253 F ## 254 D254 F ## 255 D255 &lt;NA&gt; ## 256 D256 &lt;NA&gt; ## 257 D257 &lt;NA&gt; ## 258 D258 &lt;NA&gt; ## 259 D259 F ## 260 D260 F ## 261 D261 &lt;NA&gt; ## 262 D262 M ## 263 D263 M ## 264 D264 F ## 265 D265 M ## 266 D266 &lt;NA&gt; ## 267 D267 &lt;NA&gt; ## 268 D268 F ## 269 D269 F ## 270 D270 &lt;NA&gt; ## 271 D271 F ## 272 D272 F ## 273 D273 &lt;NA&gt; ## 274 D274 F ## 275 D275 F ## 276 D276 M ## 277 D277 F ## 278 D278 F ## 279 D279 &lt;NA&gt; ## 280 D280 M ## 281 D281 F ## 282 D282 F ## 283 D283 F ## 284 D284 F ## 285 D285 &lt;NA&gt; ## 286 D286 F ## 287 D287 M ## 288 D288 M ## 289 D289 &lt;NA&gt; ## 290 D290 &lt;NA&gt; ## 291 D291 F ## 292 D292 &lt;NA&gt; ## 293 D293 F ## 294 D294 F ## 295 D295 M ## 296 D296 &lt;NA&gt; ## 297 D297 &lt;NA&gt; ## 298 D298 M ## 299 D299 F ## 300 D300 F ## 301 D301 F ## 302 D302 F ## 303 D303 &lt;NA&gt; ## 304 D304 F ## 305 D305 M ## 306 D306 &lt;NA&gt; ## 307 D307 &lt;NA&gt; ## 308 D308 F ## 309 D309 &lt;NA&gt; ## 310 D310 &lt;NA&gt; ## 311 D311 M ## 312 D312 M ## 313 D313 F ## 314 D314 M ## 315 D315 F ## 316 D316 M ## 317 D317 F ## 318 D318 &lt;NA&gt; ## 319 D319 &lt;NA&gt; ## 320 D320 &lt;NA&gt; ## 321 D321 M ## 322 D322 &lt;NA&gt; ## 323 D323 M ## 324 D324 &lt;NA&gt; ## 325 D325 F ## 326 D326 F ## 327 D327 M ## 328 D328 &lt;NA&gt; ## 329 D329 M ## 330 D330 F ## 331 D331 &lt;NA&gt; ## 332 D332 F ## 333 D333 &lt;NA&gt; ## 334 D334 &lt;NA&gt; ## 335 D335 F ## 336 D336 &lt;NA&gt; ## 337 D337 M ## 338 D338 &lt;NA&gt; ## 339 D339 &lt;NA&gt; ## 340 D340 &lt;NA&gt; ## 341 D341 F ## 342 D342 &lt;NA&gt; ## 343 D343 F ## 344 D344 &lt;NA&gt; ## 345 D345 M ## 346 D346 F ## 347 D347 F ## 348 D348 &lt;NA&gt; ## 349 D349 M ## 350 D350 M ## 351 D351 M ## 352 D352 M ## 353 D353 &lt;NA&gt; ## 354 D354 F ## 355 D355 &lt;NA&gt; ## 356 D356 F ## 357 D357 F ## 358 D358 &lt;NA&gt; ## 359 D359 F ## 360 D360 M ## 361 D361 M ## 362 D362 F ## 363 D363 &lt;NA&gt; ## 364 D364 &lt;NA&gt; ## 365 D365 M ## 366 D366 M ## 367 D367 M ## 368 D368 F ## 369 D369 M ## 370 D370 &lt;NA&gt; ## 371 D371 &lt;NA&gt; ## 372 D372 M ## 373 D373 F ## 374 D374 M ## 375 D375 M ## 376 D376 &lt;NA&gt; ## 377 D377 F ## 378 D378 M ## 379 D379 F ## 380 D380 &lt;NA&gt; ## 381 D381 M ## 382 D382 F ## 383 D383 F ## 384 D384 M ## 385 D385 F ## 386 D386 &lt;NA&gt; ## 387 D387 M ## 388 D388 F ## 389 D389 F ## 390 D390 F ## 391 D391 &lt;NA&gt; ## 392 D392 M ## 393 D393 M ## 394 D394 M ## 395 D395 &lt;NA&gt; ## 396 D396 F ## 397 D397 &lt;NA&gt; ## 398 D398 F ## 399 D399 F ## 400 D400 &lt;NA&gt; ## 401 D401 M ## 402 D402 F ## 403 D403 &lt;NA&gt; ## 404 D404 F ## 405 D405 M ## 406 D406 M ## 407 D407 M ## 408 D408 F ## 409 D409 &lt;NA&gt; ## 410 D410 F ## 411 D411 &lt;NA&gt; ## 412 D412 &lt;NA&gt; ## 413 D413 F ## 414 D414 F ## 415 D415 F ## 416 D416 F ## 417 D417 M ## 418 D418 M ## 419 D419 F ## 420 D420 &lt;NA&gt; ## 421 D421 &lt;NA&gt; ## 422 D422 F ## 423 D423 M ## 424 D424 F ## 425 D425 M ## 426 D426 F ## 427 D427 F ## 428 D428 &lt;NA&gt; ## 429 D429 &lt;NA&gt; ## 430 D430 F ## 431 D431 &lt;NA&gt; ## 432 D432 M ## 433 D433 M ## 434 D434 &lt;NA&gt; ## 435 D435 &lt;NA&gt; ## 436 D436 &lt;NA&gt; ## 437 D437 M ## 438 D438 &lt;NA&gt; ## 439 D439 F ## 440 D440 M ## 441 D441 F ## 442 D442 M ## 443 D443 F ## 444 D444 M ## 445 D445 M ## 446 D446 F ## 447 D447 &lt;NA&gt; ## 448 D448 F ## 449 D449 M ## 450 D450 F ## 451 D451 F ## 452 D452 F ## 453 D453 F ## 454 D454 M ## 455 D455 F ## 456 D456 F ## 457 D457 F ## 458 D458 F ## 459 D459 F ## 460 D460 F ## 461 D461 M ## 462 D462 &lt;NA&gt; ## 463 D463 M ## 464 D464 F ## 465 D465 M ## 466 D466 &lt;NA&gt; ## 467 D467 &lt;NA&gt; ## 468 D468 M ## 469 D469 F ## 470 D470 F ## 471 D471 F ## 472 D472 M ## 473 D473 M ## 474 D474 F ## 475 D475 M ## 476 D476 F ## 477 D477 M ## 478 D478 M ## 479 D479 F ## 480 D480 F ## 481 D481 F ## 482 D482 M ## 483 D483 &lt;NA&gt; ## 484 D484 M ## 485 D485 M ## 486 D486 &lt;NA&gt; ## 487 D487 F ## 488 D488 &lt;NA&gt; ## 489 D489 F ## 490 D490 F ## 491 D491 F ## 492 D492 F ## 493 D493 F ## 494 D494 F ## 495 D495 M ## 496 D496 F ## 497 D497 F ## 498 D498 F ## 499 D499 F ## 500 D500 F And if we want to see the whole table (not specific columns), we can use a wildcard: SELECT * FROM dragons; ## dragon_id sex age_class species ## 1 D1 F Subadult Hebridean Black ## 2 D2 &lt;NA&gt; Juvenile Romanian Longhorn ## 3 D3 F Adult Hebridean Black ## 4 D4 F Adult Peruvian Vipertooth ## 5 D5 &lt;NA&gt; Juvenile Ukrainian Ironbelly ## 6 D6 F Adult Norwegian Ridgeback ## 7 D7 M Adult Hebridean Black ## 8 D8 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 9 D9 F Adult Norwegian Ridgeback ## 10 D10 F Adult Common Welsh Green ## 11 D11 F Adult Peruvian Vipertooth ## 12 D12 F Adult Swedish Short-Snout ## 13 D13 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 14 D14 &lt;NA&gt; Juvenile Hebridean Black ## 15 D15 &lt;NA&gt; Juvenile Chinese Fireball ## 16 D16 F Adult Chinese Fireball ## 17 D17 F Adult Peruvian Vipertooth ## 18 D18 F Adult Norwegian Ridgeback ## 19 D19 F Adult Common Welsh Green ## 20 D20 M Subadult Chinese Fireball ## 21 D21 F Adult Ukrainian Ironbelly ## 22 D22 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 23 D23 M Adult Swedish Short-Snout ## 24 D24 &lt;NA&gt; Juvenile Common Welsh Green ## 25 D25 M Adult Peruvian Vipertooth ## 26 D26 &lt;NA&gt; Juvenile Common Welsh Green ## 27 D27 F Adult Norwegian Ridgeback ## 28 D28 M Adult Common Welsh Green ## 29 D29 F Adult Norwegian Ridgeback ## 30 D30 F Adult Chinese Fireball ## 31 D31 &lt;NA&gt; Juvenile Common Welsh Green ## 32 D32 M Adult Ukrainian Ironbelly ## 33 D33 F Adult Romanian Longhorn ## 34 D34 F Adult Norwegian Ridgeback ## 35 D35 F Adult Ukrainian Ironbelly ## 36 D36 &lt;NA&gt; Juvenile Romanian Longhorn ## 37 D37 F Subadult Common Welsh Green ## 38 D38 F Adult Hungarian Horntail ## 39 D39 &lt;NA&gt; Juvenile Antipodean Opaleye ## 40 D40 &lt;NA&gt; Juvenile Common Welsh Green ## 41 D41 &lt;NA&gt; Juvenile Ukrainian Ironbelly ## 42 D42 M Adult Swedish Short-Snout ## 43 D43 F Subadult Antipodean Opaleye ## 44 D44 M Adult Romanian Longhorn ## 45 D45 F Adult Peruvian Vipertooth ## 46 D46 M Subadult Hebridean Black ## 47 D47 F Adult Ukrainian Ironbelly ## 48 D48 M Adult Ukrainian Ironbelly ## 49 D49 &lt;NA&gt; Juvenile Common Welsh Green ## 50 D50 F Adult Chinese Fireball ## 51 D51 F Subadult Norwegian Ridgeback ## 52 D52 M Adult Common Welsh Green ## 53 D53 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 54 D54 F Adult Norwegian Ridgeback ## 55 D55 &lt;NA&gt; Juvenile Common Welsh Green ## 56 D56 F Subadult Norwegian Ridgeback ## 57 D57 F Adult Common Welsh Green ## 58 D58 M Adult Hebridean Black ## 59 D59 F Adult Peruvian Vipertooth ## 60 D60 F Adult Hebridean Black ## 61 D61 M Subadult Romanian Longhorn ## 62 D62 F Adult Hungarian Horntail ## 63 D63 F Adult Antipodean Opaleye ## 64 D64 &lt;NA&gt; Juvenile Romanian Longhorn ## 65 D65 &lt;NA&gt; Juvenile Romanian Longhorn ## 66 D66 &lt;NA&gt; Juvenile Ukrainian Ironbelly ## 67 D67 M Adult Norwegian Ridgeback ## 68 D68 M Adult Antipodean Opaleye ## 69 D69 F Subadult Hebridean Black ## 70 D70 F Adult Norwegian Ridgeback ## 71 D71 M Adult Hebridean Black ## 72 D72 &lt;NA&gt; Juvenile Common Welsh Green ## 73 D73 F Adult Romanian Longhorn ## 74 D74 &lt;NA&gt; Juvenile Antipodean Opaleye ## 75 D75 M Adult Swedish Short-Snout ## 76 D76 M Adult Romanian Longhorn ## 77 D77 &lt;NA&gt; Juvenile Hebridean Black ## 78 D78 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 79 D79 M Adult Common Welsh Green ## 80 D80 F Adult Romanian Longhorn ## 81 D81 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 82 D82 F Adult Hebridean Black ## 83 D83 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 84 D84 M Adult Norwegian Ridgeback ## 85 D85 F Adult Hebridean Black ## 86 D86 F Adult Hebridean Black ## 87 D87 M Adult Hungarian Horntail ## 88 D88 M Adult Swedish Short-Snout ## 89 D89 F Adult Norwegian Ridgeback ## 90 D90 M Adult Peruvian Vipertooth ## 91 D91 F Adult Hebridean Black ## 92 D92 M Adult Hebridean Black ## 93 D93 M Subadult Peruvian Vipertooth ## 94 D94 M Adult Romanian Longhorn ## 95 D95 M Adult Romanian Longhorn ## 96 D96 F Adult Common Welsh Green ## 97 D97 &lt;NA&gt; Juvenile Chinese Fireball ## 98 D98 &lt;NA&gt; Juvenile Hebridean Black ## 99 D99 F Adult Hebridean Black ## 100 D100 &lt;NA&gt; Juvenile Common Welsh Green ## 101 D101 &lt;NA&gt; Juvenile Hungarian Horntail ## 102 D102 F Subadult Hungarian Horntail ## 103 D103 F Adult Hebridean Black ## 104 D104 F Adult Hebridean Black ## 105 D105 M Adult Common Welsh Green ## 106 D106 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 107 D107 &lt;NA&gt; Juvenile Hungarian Horntail ## 108 D108 F Adult Norwegian Ridgeback ## 109 D109 M Adult Swedish Short-Snout ## 110 D110 F Adult Peruvian Vipertooth ## 111 D111 M Adult Norwegian Ridgeback ## 112 D112 F Adult Peruvian Vipertooth ## 113 D113 &lt;NA&gt; Juvenile Romanian Longhorn ## 114 D114 &lt;NA&gt; Juvenile Chinese Fireball ## 115 D115 F Adult Common Welsh Green ## 116 D116 F Adult Norwegian Ridgeback ## 117 D117 &lt;NA&gt; Juvenile Antipodean Opaleye ## 118 D118 &lt;NA&gt; Juvenile Hungarian Horntail ## 119 D119 F Adult Norwegian Ridgeback ## 120 D120 F Adult Hebridean Black ## 121 D121 &lt;NA&gt; Juvenile Common Welsh Green ## 122 D122 F Adult Ukrainian Ironbelly ## 123 D123 &lt;NA&gt; Juvenile Common Welsh Green ## 124 D124 M Adult Chinese Fireball ## 125 D125 &lt;NA&gt; Juvenile Swedish Short-Snout ## 126 D126 M Adult Swedish Short-Snout ## 127 D127 M Subadult Ukrainian Ironbelly ## 128 D128 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 129 D129 M Adult Romanian Longhorn ## 130 D130 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 131 D131 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 132 D132 F Adult Norwegian Ridgeback ## 133 D133 F Adult Ukrainian Ironbelly ## 134 D134 F Adult Hebridean Black ## 135 D135 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 136 D136 F Subadult Chinese Fireball ## 137 D137 F Adult Antipodean Opaleye ## 138 D138 F Adult Common Welsh Green ## 139 D139 F Adult Hebridean Black ## 140 D140 &lt;NA&gt; Juvenile Hebridean Black ## 141 D141 F Adult Romanian Longhorn ## 142 D142 M Subadult Common Welsh Green ## 143 D143 F Adult Antipodean Opaleye ## 144 D144 M Adult Norwegian Ridgeback ## 145 D145 M Adult Norwegian Ridgeback ## 146 D146 M Adult Norwegian Ridgeback ## 147 D147 &lt;NA&gt; Juvenile Common Welsh Green ## 148 D148 &lt;NA&gt; Juvenile Romanian Longhorn ## 149 D149 M Adult Norwegian Ridgeback ## 150 D150 F Adult Hungarian Horntail ## 151 D151 &lt;NA&gt; Juvenile Common Welsh Green ## 152 D152 F Subadult Peruvian Vipertooth ## 153 D153 M Adult Antipodean Opaleye ## 154 D154 F Adult Hebridean Black ## 155 D155 F Adult Common Welsh Green ## 156 D156 M Adult Peruvian Vipertooth ## 157 D157 F Subadult Swedish Short-Snout ## 158 D158 &lt;NA&gt; Juvenile Ukrainian Ironbelly ## 159 D159 &lt;NA&gt; Juvenile Common Welsh Green ## 160 D160 F Adult Common Welsh Green ## 161 D161 F Adult Chinese Fireball ## 162 D162 F Adult Hungarian Horntail ## 163 D163 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 164 D164 &lt;NA&gt; Juvenile Chinese Fireball ## 165 D165 M Adult Hungarian Horntail ## 166 D166 &lt;NA&gt; Juvenile Swedish Short-Snout ## 167 D167 M Adult Norwegian Ridgeback ## 168 D168 F Adult Swedish Short-Snout ## 169 D169 F Adult Hebridean Black ## 170 D170 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 171 D171 M Subadult Ukrainian Ironbelly ## 172 D172 M Adult Peruvian Vipertooth ## 173 D173 F Adult Swedish Short-Snout ## 174 D174 &lt;NA&gt; Juvenile Romanian Longhorn ## 175 D175 M Adult Chinese Fireball ## 176 D176 F Adult Ukrainian Ironbelly ## 177 D177 F Adult Romanian Longhorn ## 178 D178 F Adult Hebridean Black ## 179 D179 &lt;NA&gt; Juvenile Common Welsh Green ## 180 D180 F Adult Norwegian Ridgeback ## 181 D181 F Adult Common Welsh Green ## 182 D182 F Adult Common Welsh Green ## 183 D183 F Adult Common Welsh Green ## 184 D184 F Adult Norwegian Ridgeback ## 185 D185 M Adult Chinese Fireball ## 186 D186 &lt;NA&gt; Juvenile Common Welsh Green ## 187 D187 &lt;NA&gt; Juvenile Hebridean Black ## 188 D188 M Adult Hungarian Horntail ## 189 D189 F Adult Hungarian Horntail ## 190 D190 F Adult Hebridean Black ## 191 D191 M Adult Peruvian Vipertooth ## 192 D192 M Adult Norwegian Ridgeback ## 193 D193 M Adult Peruvian Vipertooth ## 194 D194 &lt;NA&gt; Juvenile Romanian Longhorn ## 195 D195 F Adult Romanian Longhorn ## 196 D196 F Adult Romanian Longhorn ## 197 D197 F Adult Hungarian Horntail ## 198 D198 M Adult Ukrainian Ironbelly ## 199 D199 &lt;NA&gt; Juvenile Hungarian Horntail ## 200 D200 &lt;NA&gt; Juvenile Hungarian Horntail ## 201 D201 &lt;NA&gt; Juvenile Common Welsh Green ## 202 D202 M Adult Common Welsh Green ## 203 D203 &lt;NA&gt; Juvenile Romanian Longhorn ## 204 D204 M Adult Romanian Longhorn ## 205 D205 F Adult Hungarian Horntail ## 206 D206 F Adult Hungarian Horntail ## 207 D207 &lt;NA&gt; Juvenile Romanian Longhorn ## 208 D208 M Adult Norwegian Ridgeback ## 209 D209 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 210 D210 M Adult Norwegian Ridgeback ## 211 D211 F Adult Hebridean Black ## 212 D212 F Adult Antipodean Opaleye ## 213 D213 &lt;NA&gt; Juvenile Hebridean Black ## 214 D214 F Subadult Hungarian Horntail ## 215 D215 F Adult Norwegian Ridgeback ## 216 D216 &lt;NA&gt; Juvenile Antipodean Opaleye ## 217 D217 F Adult Peruvian Vipertooth ## 218 D218 F Adult Hebridean Black ## 219 D219 M Adult Peruvian Vipertooth ## 220 D220 F Adult Common Welsh Green ## 221 D221 M Adult Peruvian Vipertooth ## 222 D222 M Subadult Hungarian Horntail ## 223 D223 M Adult Antipodean Opaleye ## 224 D224 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 225 D225 M Adult Norwegian Ridgeback ## 226 D226 &lt;NA&gt; Juvenile Swedish Short-Snout ## 227 D227 F Adult Romanian Longhorn ## 228 D228 F Adult Hebridean Black ## 229 D229 &lt;NA&gt; Juvenile Hungarian Horntail ## 230 D230 M Adult Norwegian Ridgeback ## 231 D231 M Adult Norwegian Ridgeback ## 232 D232 F Subadult Hebridean Black ## 233 D233 F Subadult Romanian Longhorn ## 234 D234 F Adult Norwegian Ridgeback ## 235 D235 &lt;NA&gt; Juvenile Hebridean Black ## 236 D236 F Adult Hungarian Horntail ## 237 D237 M Adult Hungarian Horntail ## 238 D238 F Adult Swedish Short-Snout ## 239 D239 F Adult Hebridean Black ## 240 D240 F Adult Ukrainian Ironbelly ## 241 D241 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 242 D242 M Adult Romanian Longhorn ## 243 D243 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 244 D244 F Adult Hungarian Horntail ## 245 D245 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 246 D246 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 247 D247 M Adult Norwegian Ridgeback ## 248 D248 M Subadult Common Welsh Green ## 249 D249 &lt;NA&gt; Juvenile Romanian Longhorn ## 250 D250 F Adult Romanian Longhorn ## 251 D251 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 252 D252 &lt;NA&gt; Juvenile Common Welsh Green ## 253 D253 F Adult Norwegian Ridgeback ## 254 D254 F Adult Romanian Longhorn ## 255 D255 &lt;NA&gt; Juvenile Hungarian Horntail ## 256 D256 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 257 D257 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 258 D258 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 259 D259 F Adult Hebridean Black ## 260 D260 F Adult Common Welsh Green ## 261 D261 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 262 D262 M Adult Peruvian Vipertooth ## 263 D263 M Adult Hebridean Black ## 264 D264 F Subadult Norwegian Ridgeback ## 265 D265 M Adult Hebridean Black ## 266 D266 &lt;NA&gt; Juvenile Swedish Short-Snout ## 267 D267 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 268 D268 F Adult Romanian Longhorn ## 269 D269 F Adult Swedish Short-Snout ## 270 D270 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 271 D271 F Adult Romanian Longhorn ## 272 D272 F Adult Romanian Longhorn ## 273 D273 &lt;NA&gt; Juvenile Common Welsh Green ## 274 D274 F Adult Norwegian Ridgeback ## 275 D275 F Adult Hebridean Black ## 276 D276 M Adult Norwegian Ridgeback ## 277 D277 F Subadult Swedish Short-Snout ## 278 D278 F Adult Common Welsh Green ## 279 D279 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 280 D280 M Adult Ukrainian Ironbelly ## 281 D281 F Adult Romanian Longhorn ## 282 D282 F Adult Peruvian Vipertooth ## 283 D283 F Adult Common Welsh Green ## 284 D284 F Adult Romanian Longhorn ## 285 D285 &lt;NA&gt; Juvenile Hebridean Black ## 286 D286 F Adult Ukrainian Ironbelly ## 287 D287 M Adult Norwegian Ridgeback ## 288 D288 M Subadult Hebridean Black ## 289 D289 &lt;NA&gt; Juvenile Ukrainian Ironbelly ## 290 D290 &lt;NA&gt; Juvenile Common Welsh Green ## 291 D291 F Adult Hebridean Black ## 292 D292 &lt;NA&gt; Juvenile Hebridean Black ## 293 D293 F Adult Chinese Fireball ## 294 D294 F Adult Common Welsh Green ## 295 D295 M Subadult Antipodean Opaleye ## 296 D296 &lt;NA&gt; Juvenile Hungarian Horntail ## 297 D297 &lt;NA&gt; Juvenile Hebridean Black ## 298 D298 M Adult Peruvian Vipertooth ## 299 D299 F Adult Romanian Longhorn ## 300 D300 F Adult Peruvian Vipertooth ## 301 D301 F Subadult Common Welsh Green ## 302 D302 F Adult Ukrainian Ironbelly ## 303 D303 &lt;NA&gt; Juvenile Antipodean Opaleye ## 304 D304 F Subadult Romanian Longhorn ## 305 D305 M Adult Common Welsh Green ## 306 D306 &lt;NA&gt; Juvenile Common Welsh Green ## 307 D307 &lt;NA&gt; Juvenile Ukrainian Ironbelly ## 308 D308 F Adult Romanian Longhorn ## 309 D309 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 310 D310 &lt;NA&gt; Juvenile Common Welsh Green ## 311 D311 M Adult Norwegian Ridgeback ## 312 D312 M Subadult Chinese Fireball ## 313 D313 F Adult Antipodean Opaleye ## 314 D314 M Adult Romanian Longhorn ## 315 D315 F Adult Common Welsh Green ## 316 D316 M Subadult Hebridean Black ## 317 D317 F Adult Antipodean Opaleye ## 318 D318 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 319 D319 &lt;NA&gt; Juvenile Swedish Short-Snout ## 320 D320 &lt;NA&gt; Juvenile Hungarian Horntail ## 321 D321 M Adult Norwegian Ridgeback ## 322 D322 &lt;NA&gt; Juvenile Chinese Fireball ## 323 D323 M Adult Romanian Longhorn ## 324 D324 &lt;NA&gt; Juvenile Common Welsh Green ## 325 D325 F Adult Norwegian Ridgeback ## 326 D326 F Adult Ukrainian Ironbelly ## 327 D327 M Subadult Romanian Longhorn ## 328 D328 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 329 D329 M Adult Romanian Longhorn ## 330 D330 F Adult Peruvian Vipertooth ## 331 D331 &lt;NA&gt; Juvenile Swedish Short-Snout ## 332 D332 F Subadult Common Welsh Green ## 333 D333 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 334 D334 &lt;NA&gt; Juvenile Romanian Longhorn ## 335 D335 F Adult Romanian Longhorn ## 336 D336 &lt;NA&gt; Juvenile Common Welsh Green ## 337 D337 M Adult Peruvian Vipertooth ## 338 D338 &lt;NA&gt; Juvenile Antipodean Opaleye ## 339 D339 &lt;NA&gt; Juvenile Chinese Fireball ## 340 D340 &lt;NA&gt; Juvenile Antipodean Opaleye ## 341 D341 F Adult Norwegian Ridgeback ## 342 D342 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 343 D343 F Adult Antipodean Opaleye ## 344 D344 &lt;NA&gt; Juvenile Romanian Longhorn ## 345 D345 M Adult Swedish Short-Snout ## 346 D346 F Adult Romanian Longhorn ## 347 D347 F Subadult Common Welsh Green ## 348 D348 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 349 D349 M Adult Peruvian Vipertooth ## 350 D350 M Adult Hebridean Black ## 351 D351 M Adult Peruvian Vipertooth ## 352 D352 M Adult Romanian Longhorn ## 353 D353 &lt;NA&gt; Juvenile Hebridean Black ## 354 D354 F Adult Norwegian Ridgeback ## 355 D355 &lt;NA&gt; Juvenile Hungarian Horntail ## 356 D356 F Adult Romanian Longhorn ## 357 D357 F Subadult Romanian Longhorn ## 358 D358 &lt;NA&gt; Juvenile Common Welsh Green ## 359 D359 F Adult Hebridean Black ## 360 D360 M Adult Norwegian Ridgeback ## 361 D361 M Adult Swedish Short-Snout ## 362 D362 F Subadult Norwegian Ridgeback ## 363 D363 &lt;NA&gt; Juvenile Romanian Longhorn ## 364 D364 &lt;NA&gt; Juvenile Common Welsh Green ## 365 D365 M Adult Romanian Longhorn ## 366 D366 M Adult Norwegian Ridgeback ## 367 D367 M Adult Peruvian Vipertooth ## 368 D368 F Adult Common Welsh Green ## 369 D369 M Adult Norwegian Ridgeback ## 370 D370 &lt;NA&gt; Juvenile Common Welsh Green ## 371 D371 &lt;NA&gt; Juvenile Ukrainian Ironbelly ## 372 D372 M Adult Peruvian Vipertooth ## 373 D373 F Adult Peruvian Vipertooth ## 374 D374 M Adult Swedish Short-Snout ## 375 D375 M Adult Norwegian Ridgeback ## 376 D376 &lt;NA&gt; Juvenile Swedish Short-Snout ## 377 D377 F Adult Hebridean Black ## 378 D378 M Adult Romanian Longhorn ## 379 D379 F Adult Antipodean Opaleye ## 380 D380 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 381 D381 M Adult Common Welsh Green ## 382 D382 F Adult Norwegian Ridgeback ## 383 D383 F Adult Hebridean Black ## 384 D384 M Adult Hungarian Horntail ## 385 D385 F Adult Common Welsh Green ## 386 D386 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 387 D387 M Adult Hebridean Black ## 388 D388 F Subadult Common Welsh Green ## 389 D389 F Adult Hebridean Black ## 390 D390 F Adult Common Welsh Green ## 391 D391 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 392 D392 M Adult Peruvian Vipertooth ## 393 D393 M Adult Hebridean Black ## 394 D394 M Adult Swedish Short-Snout ## 395 D395 &lt;NA&gt; Juvenile Antipodean Opaleye ## 396 D396 F Subadult Norwegian Ridgeback ## 397 D397 &lt;NA&gt; Juvenile Ukrainian Ironbelly ## 398 D398 F Adult Common Welsh Green ## 399 D399 F Adult Romanian Longhorn ## 400 D400 &lt;NA&gt; Juvenile Hungarian Horntail ## 401 D401 M Subadult Norwegian Ridgeback ## 402 D402 F Adult Common Welsh Green ## 403 D403 &lt;NA&gt; Juvenile Common Welsh Green ## 404 D404 F Adult Common Welsh Green ## 405 D405 M Adult Romanian Longhorn ## 406 D406 M Adult Hebridean Black ## 407 D407 M Adult Antipodean Opaleye ## 408 D408 F Adult Common Welsh Green ## 409 D409 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 410 D410 F Adult Hebridean Black ## 411 D411 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 412 D412 &lt;NA&gt; Juvenile Romanian Longhorn ## 413 D413 F Adult Romanian Longhorn ## 414 D414 F Adult Peruvian Vipertooth ## 415 D415 F Adult Romanian Longhorn ## 416 D416 F Adult Romanian Longhorn ## 417 D417 M Adult Norwegian Ridgeback ## 418 D418 M Subadult Common Welsh Green ## 419 D419 F Adult Norwegian Ridgeback ## 420 D420 &lt;NA&gt; Juvenile Common Welsh Green ## 421 D421 &lt;NA&gt; Juvenile Common Welsh Green ## 422 D422 F Adult Norwegian Ridgeback ## 423 D423 M Adult Common Welsh Green ## 424 D424 F Adult Hebridean Black ## 425 D425 M Adult Romanian Longhorn ## 426 D426 F Adult Norwegian Ridgeback ## 427 D427 F Adult Peruvian Vipertooth ## 428 D428 &lt;NA&gt; Juvenile Common Welsh Green ## 429 D429 &lt;NA&gt; Juvenile Common Welsh Green ## 430 D430 F Adult Hungarian Horntail ## 431 D431 &lt;NA&gt; Juvenile Ukrainian Ironbelly ## 432 D432 M Adult Antipodean Opaleye ## 433 D433 M Adult Peruvian Vipertooth ## 434 D434 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 435 D435 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 436 D436 &lt;NA&gt; Juvenile Romanian Longhorn ## 437 D437 M Adult Common Welsh Green ## 438 D438 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 439 D439 F Subadult Hungarian Horntail ## 440 D440 M Adult Common Welsh Green ## 441 D441 F Adult Norwegian Ridgeback ## 442 D442 M Adult Romanian Longhorn ## 443 D443 F Adult Hebridean Black ## 444 D444 M Adult Hebridean Black ## 445 D445 M Adult Norwegian Ridgeback ## 446 D446 F Adult Swedish Short-Snout ## 447 D447 &lt;NA&gt; Juvenile Romanian Longhorn ## 448 D448 F Adult Peruvian Vipertooth ## 449 D449 M Adult Chinese Fireball ## 450 D450 F Adult Peruvian Vipertooth ## 451 D451 F Adult Common Welsh Green ## 452 D452 F Adult Swedish Short-Snout ## 453 D453 F Adult Antipodean Opaleye ## 454 D454 M Adult Romanian Longhorn ## 455 D455 F Adult Common Welsh Green ## 456 D456 F Adult Peruvian Vipertooth ## 457 D457 F Adult Antipodean Opaleye ## 458 D458 F Adult Romanian Longhorn ## 459 D459 F Subadult Swedish Short-Snout ## 460 D460 F Adult Norwegian Ridgeback ## 461 D461 M Adult Hebridean Black ## 462 D462 &lt;NA&gt; Juvenile Common Welsh Green ## 463 D463 M Adult Peruvian Vipertooth ## 464 D464 F Adult Hebridean Black ## 465 D465 M Adult Hungarian Horntail ## 466 D466 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 467 D467 &lt;NA&gt; Juvenile Hungarian Horntail ## 468 D468 M Adult Peruvian Vipertooth ## 469 D469 F Adult Romanian Longhorn ## 470 D470 F Adult Hungarian Horntail ## 471 D471 F Adult Peruvian Vipertooth ## 472 D472 M Adult Hungarian Horntail ## 473 D473 M Adult Peruvian Vipertooth ## 474 D474 F Adult Ukrainian Ironbelly ## 475 D475 M Subadult Norwegian Ridgeback ## 476 D476 F Adult Norwegian Ridgeback ## 477 D477 M Adult Norwegian Ridgeback ## 478 D478 M Adult Common Welsh Green ## 479 D479 F Adult Chinese Fireball ## 480 D480 F Adult Hebridean Black ## 481 D481 F Adult Hungarian Horntail ## 482 D482 M Subadult Romanian Longhorn ## 483 D483 &lt;NA&gt; Juvenile Hebridean Black ## 484 D484 M Adult Hebridean Black ## 485 D485 M Adult Hebridean Black ## 486 D486 &lt;NA&gt; Juvenile Common Welsh Green ## 487 D487 F Adult Hungarian Horntail ## 488 D488 &lt;NA&gt; Juvenile Hungarian Horntail ## 489 D489 F Adult Common Welsh Green ## 490 D490 F Adult Romanian Longhorn ## 491 D491 F Adult Hebridean Black ## 492 D492 F Adult Hungarian Horntail ## 493 D493 F Adult Hebridean Black ## 494 D494 F Adult Chinese Fireball ## 495 D495 M Adult Romanian Longhorn ## 496 D496 F Adult Romanian Longhorn ## 497 D497 F Adult Hungarian Horntail ## 498 D498 F Adult Common Welsh Green ## 499 D499 F Adult Peruvian Vipertooth ## 500 D500 F Adult Common Welsh Green 6.2.1 Limiting results If the whole table is too big and we only want to take a look at the first, say, 10 rows, we can add a LIMIT clause: SELECT * FROM dragons LIMIT 10; ## dragon_id sex age_class species ## 1 D1 F Subadult Hebridean Black ## 2 D2 &lt;NA&gt; Juvenile Romanian Longhorn ## 3 D3 F Adult Hebridean Black ## 4 D4 F Adult Peruvian Vipertooth ## 5 D5 &lt;NA&gt; Juvenile Ukrainian Ironbelly ## 6 D6 F Adult Norwegian Ridgeback ## 7 D7 M Adult Hebridean Black ## 8 D8 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 9 D9 F Adult Norwegian Ridgeback ## 10 D10 F Adult Common Welsh Green 6.2.2 Sorting results One thing to remember with SQL is that the data returned by a SELECT statement does not necessarily return the data in any specific order unless we tell it to. You can never assume the output is already sorted. To be explicit about how you want the data ordered, you can add an ORDER BY clause: SELECT * FROM dragons ORDER BY species LIMIT 10; ## dragon_id sex age_class species ## 1 D39 &lt;NA&gt; Juvenile Antipodean Opaleye ## 2 D43 F Subadult Antipodean Opaleye ## 3 D63 F Adult Antipodean Opaleye ## 4 D68 M Adult Antipodean Opaleye ## 5 D74 &lt;NA&gt; Juvenile Antipodean Opaleye ## 6 D117 &lt;NA&gt; Juvenile Antipodean Opaleye ## 7 D137 F Adult Antipodean Opaleye ## 8 D143 F Adult Antipodean Opaleye ## 9 D153 M Adult Antipodean Opaleye ## 10 D212 F Adult Antipodean Opaleye The default ordering will be ascending. If we want descending ordering instead, we can specify that as follows: SELECT * FROM dragons ORDER BY species DESC LIMIT 10; ## dragon_id sex age_class species ## 1 D5 &lt;NA&gt; Juvenile Ukrainian Ironbelly ## 2 D21 F Adult Ukrainian Ironbelly ## 3 D32 M Adult Ukrainian Ironbelly ## 4 D35 F Adult Ukrainian Ironbelly ## 5 D41 &lt;NA&gt; Juvenile Ukrainian Ironbelly ## 6 D47 F Adult Ukrainian Ironbelly ## 7 D48 M Adult Ukrainian Ironbelly ## 8 D66 &lt;NA&gt; Juvenile Ukrainian Ironbelly ## 9 D122 F Adult Ukrainian Ironbelly ## 10 D127 M Subadult Ukrainian Ironbelly 6.2.3 Finding unique values Say that we wanted to know what species of dragons are in the database. We can ask for unique values as follows: SELECT DISTINCT species FROM dragons; ## species ## 1 Hebridean Black ## 2 Romanian Longhorn ## 3 Peruvian Vipertooth ## 4 Ukrainian Ironbelly ## 5 Norwegian Ridgeback ## 6 Common Welsh Green ## 7 Swedish Short-Snout ## 8 Chinese Fireball ## 9 Hungarian Horntail ## 10 Antipodean Opaleye 6.2.4 Filtering We can filter data based on any logical condition using a WHERE clause. For instance, say that we we only want Norwegian Ridgebacks: SELECT * FROM dragons WHERE species = &#39;Norwegian Ridgeback&#39; LIMIT 10; ## dragon_id sex age_class species ## 1 D6 F Adult Norwegian Ridgeback ## 2 D9 F Adult Norwegian Ridgeback ## 3 D18 F Adult Norwegian Ridgeback ## 4 D22 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 5 D27 F Adult Norwegian Ridgeback ## 6 D29 F Adult Norwegian Ridgeback ## 7 D34 F Adult Norwegian Ridgeback ## 8 D51 F Subadult Norwegian Ridgeback ## 9 D53 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 10 D54 F Adult Norwegian Ridgeback We can specify multiple conditions at once. For example, if we want only female Norwegian Ridgebacks: SELECT * FROM dragons WHERE species = &#39;Norwegian Ridgeback&#39; AND sex = &#39;F&#39; LIMIT 10; ## dragon_id sex age_class species ## 1 D6 F Adult Norwegian Ridgeback ## 2 D9 F Adult Norwegian Ridgeback ## 3 D18 F Adult Norwegian Ridgeback ## 4 D27 F Adult Norwegian Ridgeback ## 5 D29 F Adult Norwegian Ridgeback ## 6 D34 F Adult Norwegian Ridgeback ## 7 D51 F Subadult Norwegian Ridgeback ## 8 D54 F Adult Norwegian Ridgeback ## 9 D56 F Subadult Norwegian Ridgeback ## 10 D70 F Adult Norwegian Ridgeback In the example above, both conditions have to be satisfied at once – dragons have to be Norwegian Ridgeback and females to appear in the results. What if we want to return data where at least one of two conditions is satisfied? The following query will return dragons that are either Norwegian Ridgebacks or Peruvian Vipertooths: SELECT * FROM dragons WHERE species = &#39;Norwegian Ridgeback&#39; OR species = &#39;Peruvian Vipertooth&#39; LIMIT 10; ## dragon_id sex age_class species ## 1 D4 F Adult Peruvian Vipertooth ## 2 D6 F Adult Norwegian Ridgeback ## 3 D8 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 4 D9 F Adult Norwegian Ridgeback ## 5 D11 F Adult Peruvian Vipertooth ## 6 D13 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 7 D17 F Adult Peruvian Vipertooth ## 8 D18 F Adult Norwegian Ridgeback ## 9 D22 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 10 D25 M Adult Peruvian Vipertooth A more concise way to write the same query would be: SELECT * FROM dragons WHERE species IN (&#39;Norwegian Ridgeback&#39;, &#39;Peruvian Vipertooth&#39;) LIMIT 10; ## dragon_id sex age_class species ## 1 D4 F Adult Peruvian Vipertooth ## 2 D6 F Adult Norwegian Ridgeback ## 3 D8 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 4 D9 F Adult Norwegian Ridgeback ## 5 D11 F Adult Peruvian Vipertooth ## 6 D13 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 7 D17 F Adult Peruvian Vipertooth ## 8 D18 F Adult Norwegian Ridgeback ## 9 D22 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 10 D25 M Adult Peruvian Vipertooth Logical conditions also include “greater than”, “less than”, “not equal to”. For instance, we can exclude Norwegian Ridgeback like so: SELECT * FROM dragons WHERE species != &#39;Norwegian Ridgeback&#39; LIMIT 10; ## dragon_id sex age_class species ## 1 D1 F Subadult Hebridean Black ## 2 D2 &lt;NA&gt; Juvenile Romanian Longhorn ## 3 D3 F Adult Hebridean Black ## 4 D4 F Adult Peruvian Vipertooth ## 5 D5 &lt;NA&gt; Juvenile Ukrainian Ironbelly ## 6 D7 M Adult Hebridean Black ## 7 D8 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 8 D10 F Adult Common Welsh Green ## 9 D11 F Adult Peruvian Vipertooth ## 10 D12 F Adult Swedish Short-Snout Let’s see some examples with numbers using the morphometrics table. The following query returns any dragons with wingspan greater than 8 meters (incidentally, you can include comments in SQL is by using a double dash): SELECT * FROM morphometrics WHERE wingspan_cm &gt; 800 -- 800 cm is 8 meters LIMIT 10; ## measurement_id dragon_id date total_body_length_cm wingspan_cm ## 1 1 D96 2012-10-10 1069.8965 1389.553 ## 2 3 D316 2017-09-08 866.8935 1052.370 ## 3 4 D317 2016-09-05 1146.9708 1356.808 ## 4 5 D484 2016-12-04 1032.0520 1720.864 ## 5 6 D149 2012-02-13 919.9908 1533.599 ## 6 9 D283 2007-06-21 1698.1918 1387.194 ## 7 11 D485 2002-10-04 957.4830 1780.262 ## 8 16 D343 2016-04-08 1520.7012 1537.747 ## 9 19 D237 2009-02-22 1204.7588 2120.408 ## 10 20 D312 2001-06-16 927.1642 1267.669 ## tail_length_cm tarsus_length_cm claw_length_cm ## 1 595.2706 121.65175 15.59622 ## 2 373.7619 68.16869 12.71970 ## 3 542.5670 172.43663 14.80936 ## 4 596.4419 114.05057 11.98567 ## 5 563.9201 134.18051 11.00507 ## 6 666.4246 147.44219 13.18923 ## 7 560.8861 130.86021 16.52066 ## 8 618.2842 151.93929 10.37198 ## 9 655.5090 134.75780 11.13375 ## 10 452.7417 108.84082 11.93288 We can also sort the output of the filter: SELECT * FROM morphometrics WHERE wingspan_cm &gt; 800 ORDER BY wingspan_cm DESC LIMIT 10; ## measurement_id dragon_id date total_body_length_cm wingspan_cm ## 1 90 D494 2004-06-12 1307.224 3101.688 ## 2 39 D99 2016-11-16 1334.744 2891.525 ## 3 86 D378 2013-09-14 1311.868 2792.250 ## 4 138 D414 2015-08-28 1721.825 2653.967 ## 5 240 D228 2019-06-28 1789.812 2653.470 ## 6 312 D476 2000-06-20 1391.101 2617.818 ## 7 127 D70 2010-09-10 1601.945 2518.449 ## 8 23 D499 2011-12-09 1268.471 2481.832 ## 9 282 D496 2006-08-18 1536.888 2460.436 ## 10 256 D321 2017-03-19 1423.789 2440.229 ## tail_length_cm tarsus_length_cm claw_length_cm ## 1 609.9900 131.2439 14.031487 ## 2 596.7174 144.0813 7.619286 ## 3 601.6576 107.9930 20.714964 ## 4 619.6061 128.5858 18.447108 ## 5 604.2838 162.4562 8.846004 ## 6 599.2680 138.8046 9.720670 ## 7 598.8351 135.7797 8.544782 ## 8 609.8503 129.6169 10.313340 ## 9 679.7031 136.7213 17.495741 ## 10 619.7223 116.3764 7.266753 6.2.5 Calculations The morphometric measurements are in centimeters, but we often define our filtering conditions using meters in our minds (see above, “wingspan greater than 8 meters”). Instead of converting the condition into centimeters, wouldn’t it be easier to have SQLite transform the data in meters and then evaluate the condition? We can do this calculation on the fly: SELECT * FROM morphometrics WHERE wingspan_cm/100 &gt; 8 LIMIT 10; ## measurement_id dragon_id date total_body_length_cm wingspan_cm ## 1 1 D96 2012-10-10 1069.8965 1389.553 ## 2 3 D316 2017-09-08 866.8935 1052.370 ## 3 4 D317 2016-09-05 1146.9708 1356.808 ## 4 5 D484 2016-12-04 1032.0520 1720.864 ## 5 6 D149 2012-02-13 919.9908 1533.599 ## 6 9 D283 2007-06-21 1698.1918 1387.194 ## 7 11 D485 2002-10-04 957.4830 1780.262 ## 8 16 D343 2016-04-08 1520.7012 1537.747 ## 9 19 D237 2009-02-22 1204.7588 2120.408 ## 10 20 D312 2001-06-16 927.1642 1267.669 ## tail_length_cm tarsus_length_cm claw_length_cm ## 1 595.2706 121.65175 15.59622 ## 2 373.7619 68.16869 12.71970 ## 3 542.5670 172.43663 14.80936 ## 4 596.4419 114.05057 11.98567 ## 5 563.9201 134.18051 11.00507 ## 6 666.4246 147.44219 13.18923 ## 7 560.8861 130.86021 16.52066 ## 8 618.2842 151.93929 10.37198 ## 9 655.5090 134.75780 11.13375 ## 10 452.7417 108.84082 11.93288 6.2.6 Aggregate functions Summary statistics are calculated using aggregate functions in SQL. Counting, summing, calculating the mean, minimum, maximum values are all examples of aggregate functions. Let’s see how they work. If we want to know how many Norwegian Ridgebacks are in the database, we can use: SELECT COUNT(*) FROM dragons WHERE species = &#39;Norwegian Ridgeback&#39;; ## COUNT(*) ## 1 86 The dragons table has no repeated IDs, so we shouldn’t have counted anybody twice. However, let’s double check if that’s true by specifying that we want to only count distinct IDs: SELECT COUNT(DISTINCT dragon_id) FROM dragons WHERE species = &#39;Norwegian Ridgeback&#39;; ## COUNT(DISTINCT dragon_id) ## 1 86 Now let’s see how to calculate some summary stats on dragon morphometrics. What is the mean total body length of dragons in our sample? SELECT AVG(total_body_length_cm) FROM morphometrics; ## AVG(total_body_length_cm) ## 1 961.3612 We can also calculate several different things at once: SELECT AVG(total_body_length_cm), MIN(total_body_length_cm), MAX(total_body_length_cm) FROM morphometrics; ## AVG(total_body_length_cm) MIN(total_body_length_cm) MAX(total_body_length_cm) ## 1 961.3612 285.6049 2250.789 6.2.7 Aliases Aliases are temporary names that we can assign to a column (or a table) during the execution of a query. For example, we can use an alias to rename the output of our mean body length calculation: SELECT AVG(total_body_length_cm) AS mean_body_length FROM morphometrics; ## mean_body_length ## 1 961.3612 6.2.8 Grouping If we want to apply the same calculation to different groups within the data, we can use the GROUP BY clause. GROUP BY is used in conjunction with an aggregate function to return the computed values broken down by group. For instance, if we want to count how many dragons we have for each species (and sort them from the most numerous to the least numerous): SELECT species, COUNT(*) AS n_dragons FROM dragons GROUP BY species ORDER BY n_dragons DESC; ## species n_dragons ## 1 Norwegian Ridgeback 86 ## 2 Common Welsh Green 81 ## 3 Romanian Longhorn 69 ## 4 Hebridean Black 66 ## 5 Peruvian Vipertooth 60 ## 6 Hungarian Horntail 40 ## 7 Swedish Short-Snout 27 ## 8 Ukrainian Ironbelly 26 ## 9 Antipodean Opaleye 25 ## 10 Chinese Fireball 20 6.2.9 Filtering based on computed values If we want to apply any filtering to our results based on calculated values, the WHERE clause is not going to work. Instead, a HAVING clause is used in combination with an aggregate function and a GROUP BY. HAVING does the same thing as WHERE except that it handles logical conditions on computed values. For example, say that we want to count how many individuals we have in our database and then only keep the species for which we have at least 50 individuals. The following query counts how many individual dragons we have for each species: SELECT COUNT(DISTINCT dragon_id) AS n_dragons, species FROM dragons GROUP BY species; ## n_dragons species ## 1 25 Antipodean Opaleye ## 2 20 Chinese Fireball ## 3 81 Common Welsh Green ## 4 66 Hebridean Black ## 5 40 Hungarian Horntail ## 6 86 Norwegian Ridgeback ## 7 60 Peruvian Vipertooth ## 8 69 Romanian Longhorn ## 9 27 Swedish Short-Snout ## 10 26 Ukrainian Ironbelly Because the count is a calculated value (the output of the aggregate function COUNT), if we try to apply a filter using WHERE we’ll get an error. Instead, we can use HAVING: SELECT COUNT(DISTINCT dragon_id) AS n_dragons, species FROM dragons GROUP BY species HAVING n_dragons &gt; 50; ## n_dragons species ## 1 81 Common Welsh Green ## 2 66 Hebridean Black ## 3 86 Norwegian Ridgeback ## 4 60 Peruvian Vipertooth ## 5 69 Romanian Longhorn 6.2.10 Null values Missing values in SQL are represented as NULL. We can filter (or filter out) these values using the IS NULL operator: SELECT * FROM dragons WHERE sex IS NULL LIMIT 10; ## dragon_id sex age_class species ## 1 D2 &lt;NA&gt; Juvenile Romanian Longhorn ## 2 D5 &lt;NA&gt; Juvenile Ukrainian Ironbelly ## 3 D8 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 4 D13 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 5 D14 &lt;NA&gt; Juvenile Hebridean Black ## 6 D15 &lt;NA&gt; Juvenile Chinese Fireball ## 7 D22 &lt;NA&gt; Juvenile Norwegian Ridgeback ## 8 D24 &lt;NA&gt; Juvenile Common Welsh Green ## 9 D26 &lt;NA&gt; Juvenile Common Welsh Green ## 10 D31 &lt;NA&gt; Juvenile Common Welsh Green The query above returns all the dragons for which sex is unknown. If we want to exclude any individuals for which sex is unknown, then we can add the NOT operator to our statement: SELECT * FROM dragons WHERE sex IS NOT NULL LIMIT 10; ## dragon_id sex age_class species ## 1 D1 F Subadult Hebridean Black ## 2 D3 F Adult Hebridean Black ## 3 D4 F Adult Peruvian Vipertooth ## 4 D6 F Adult Norwegian Ridgeback ## 5 D7 M Adult Hebridean Black ## 6 D9 F Adult Norwegian Ridgeback ## 7 D10 F Adult Common Welsh Green ## 8 D11 F Adult Peruvian Vipertooth ## 9 D12 F Adult Swedish Short-Snout ## 10 D16 F Adult Chinese Fireball 6.2.11 Joins So far, we have learned how to query data from a single table. But what if we need to combine information from multiple tables to get the result we want? Let’s make an example. Say that we want to calculate the average wingspan for male versus female dragons. The wingspan measurements are in the morphometrics table. However, the morphometrics table does not have a “sex” column. The information on sex is in the dragons table. To get our answer, we need to combine information from the dragons and morphometrics tables. To do so, we introduce SQL joins. Joins are the heart of relational database use. Without joins, there is no point in a relational database because we can’t take advantage of the relations between tables. Joins exploit the links we established between tables via foreign keys to combine information across them. There are several types of join. The most common types are left join, inner join, or full join. To understand this terminology, consider this: whenever you are joining two tables, the first table you mention (the one to which you’re joining) is called the left table, whereas the second table (the one you’re joining to the first) is called the right table. With a left join, you keep all the records in the left table and add information from the right table whenever there’s a matching row. A full join means that you retain all rows from both tables, matching them whenever possible. An inner join means that you only retain the rows that match between the two tables. Figure 6.1: SQL Joins Let’s look at this in practice and it will make more sense. Our database contains a deployments table and a morphometrics table. Not all dragons that were tracked were also measured. If we do a left join using the deployments as the left table, we get in output the whole deployments table (all the dragons that were tracked) with the associated morphometric information whenever available (for the dragons that were also measured): SELECT * FROM deployments -- this is our left table LEFT JOIN morphometrics -- this is our right table ON deployments.dragon_id = morphometrics.dragon_id -- this is the shared column LIMIT 10; ## deployment_id dragon_id tag_id start_deployment end_deployment ## 1 1 D486 N33529 2006-12-20 2007-07-04 ## 2 2 D393 J47978 2008-01-13 2008-10-13 ## 3 3 D88 R61684 2004-09-19 2004-12-01 ## 4 4 D330 B35524 2015-11-21 2016-08-02 ## 5 5 D478 T55954 2002-05-07 2002-10-26 ## 6 6 D300 O31688 2006-01-20 2006-08-23 ## 7 7 D380 B61925 2015-01-27 2015-10-21 ## 8 8 D315 P47677 2006-03-03 2006-06-06 ## 9 9 D209 P35987 2007-02-26 2007-05-31 ## 10 10 D357 I41609 2013-09-09 2014-03-08 ## measurement_id dragon_id date total_body_length_cm wingspan_cm ## 1 14 D486 2006-12-20 315.2255 616.5057 ## 2 146 D393 2008-01-13 1275.6809 803.7776 ## 3 NA &lt;NA&gt; &lt;NA&gt; NA NA ## 4 252 D330 2015-11-21 1364.8418 1351.6375 ## 5 NA &lt;NA&gt; &lt;NA&gt; NA NA ## 6 NA &lt;NA&gt; &lt;NA&gt; NA NA ## 7 260 D380 2015-01-27 327.5435 616.5409 ## 8 NA &lt;NA&gt; &lt;NA&gt; NA NA ## 9 82 D209 2007-02-26 325.2996 670.5136 ## 10 31 D357 2013-09-09 730.9783 972.8464 ## tail_length_cm tarsus_length_cm claw_length_cm ## 1 117.3121 31.70299 4.980824 ## 2 638.4500 133.38012 12.472582 ## 3 NA NA NA ## 4 637.7992 140.29208 14.076526 ## 5 NA NA NA ## 6 NA NA NA ## 7 102.2240 35.78315 4.716980 ## 8 NA NA NA ## 9 118.8795 41.10574 4.926693 ## 10 489.0859 93.98672 17.895960 Since the shared column is named the same in the two tables (dragon_id), I had to specify which table I was referring to each time in the ON clause, or it would have been ambiguous. The syntax to do so is table.column. Also note that, because the dragon ID column appears in both tables and we did not specify which table we wanted it from, SQLite is duplicating it. To avoid that, we need to get rid of the wildcard and spell out the name of each of the columns we want in output (also specifying the table when ambiguous): SELECT deployments.dragon_id, date, tag_id, start_deployment, end_deployment, total_body_length_cm, wingspan_cm, tail_length_cm, tarsus_length_cm, claw_length_cm FROM deployments LEFT JOIN morphometrics ON deployments.dragon_id = morphometrics.dragon_id LIMIT 10; ## dragon_id date tag_id start_deployment end_deployment ## 1 D486 2006-12-20 N33529 2006-12-20 2007-07-04 ## 2 D393 2008-01-13 J47978 2008-01-13 2008-10-13 ## 3 D88 &lt;NA&gt; R61684 2004-09-19 2004-12-01 ## 4 D330 2015-11-21 B35524 2015-11-21 2016-08-02 ## 5 D478 &lt;NA&gt; T55954 2002-05-07 2002-10-26 ## 6 D300 &lt;NA&gt; O31688 2006-01-20 2006-08-23 ## 7 D380 2015-01-27 B61925 2015-01-27 2015-10-21 ## 8 D315 &lt;NA&gt; P47677 2006-03-03 2006-06-06 ## 9 D209 2007-02-26 P35987 2007-02-26 2007-05-31 ## 10 D357 2013-09-09 I41609 2013-09-09 2014-03-08 ## total_body_length_cm wingspan_cm tail_length_cm tarsus_length_cm ## 1 315.2255 616.5057 117.3121 31.70299 ## 2 1275.6809 803.7776 638.4500 133.38012 ## 3 NA NA NA NA ## 4 1364.8418 1351.6375 637.7992 140.29208 ## 5 NA NA NA NA ## 6 NA NA NA NA ## 7 327.5435 616.5409 102.2240 35.78315 ## 8 NA NA NA NA ## 9 325.2996 670.5136 118.8795 41.10574 ## 10 730.9783 972.8464 489.0859 93.98672 ## claw_length_cm ## 1 4.980824 ## 2 12.472582 ## 3 NA ## 4 14.076526 ## 5 NA ## 6 NA ## 7 4.716980 ## 8 NA ## 9 4.926693 ## 10 17.895960 If we invert the tables (the morphometrics becomes the left table and the deployments becomes the right), we get in output the whole morphometric table (all the dragons that were measured) with the associated deployment information whenever available (for the dragons that were also tracked): SELECT * FROM morphometrics -- this is our left table LEFT JOIN deployments -- this is our right table ON morphometrics.dragon_id = deployments.dragon_id LIMIT 10; ## measurement_id dragon_id date total_body_length_cm wingspan_cm ## 1 1 D96 2012-10-10 1069.8965 1389.5527 ## 2 2 D400 2003-07-03 333.4600 634.9109 ## 3 3 D316 2017-09-08 866.8935 1052.3702 ## 4 4 D317 2016-09-05 1146.9708 1356.8084 ## 5 5 D484 2016-12-04 1032.0520 1720.8641 ## 6 6 D149 2012-02-13 919.9908 1533.5991 ## 7 7 D285 2016-03-23 304.8285 698.8157 ## 8 8 D256 2013-09-07 358.9701 652.0053 ## 9 9 D283 2007-06-21 1698.1918 1387.1943 ## 10 10 D213 2001-12-12 353.6952 670.5283 ## tail_length_cm tarsus_length_cm claw_length_cm deployment_id dragon_id ## 1 595.2706 121.65175 15.596219 274 D96 ## 2 104.2241 38.10844 4.305086 260 D400 ## 3 373.7619 68.16869 12.719697 NA &lt;NA&gt; ## 4 542.5670 172.43663 14.809363 98 D317 ## 5 596.4419 114.05057 11.985672 285 D484 ## 6 563.9201 134.18051 11.005070 NA &lt;NA&gt; ## 7 115.8964 42.18657 5.041634 126 D285 ## 8 148.3656 43.57849 4.576640 291 D256 ## 9 666.4246 147.44219 13.189233 145 D283 ## 10 140.4342 43.60513 4.248564 128 D213 ## tag_id start_deployment end_deployment ## 1 H83101 2012-10-10 2013-06-02 ## 2 S49621 2003-07-03 2004-01-17 ## 3 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 4 A49007 2016-09-05 2017-01-09 ## 5 V63425 2016-12-04 2017-02-19 ## 6 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 7 B74989 2016-03-23 2016-11-08 ## 8 O66678 2013-09-07 2013-11-10 ## 9 G59298 2007-06-21 2007-11-14 ## 10 F64333 2001-12-12 2002-02-05 An inner join only keeps the rows that match between two tables. In this case, that means we only get in output data for animals that were both tracked and measured: SELECT * FROM morphometrics INNER JOIN deployments ON morphometrics.dragon_id = deployments.dragon_id LIMIT 10; ## measurement_id dragon_id date total_body_length_cm wingspan_cm ## 1 1 D96 2012-10-10 1069.8965 1389.5527 ## 2 2 D400 2003-07-03 333.4600 634.9109 ## 3 4 D317 2016-09-05 1146.9708 1356.8084 ## 4 5 D484 2016-12-04 1032.0520 1720.8641 ## 5 7 D285 2016-03-23 304.8285 698.8157 ## 6 8 D256 2013-09-07 358.9701 652.0053 ## 7 9 D283 2007-06-21 1698.1918 1387.1943 ## 8 10 D213 2001-12-12 353.6952 670.5283 ## 9 13 D41 2016-11-03 325.5946 626.2576 ## 10 14 D486 2006-12-20 315.2255 616.5057 ## tail_length_cm tarsus_length_cm claw_length_cm deployment_id dragon_id ## 1 595.27056 121.65175 15.596219 274 D96 ## 2 104.22414 38.10844 4.305086 260 D400 ## 3 542.56700 172.43663 14.809363 98 D317 ## 4 596.44195 114.05057 11.985672 285 D484 ## 5 115.89640 42.18657 5.041634 126 D285 ## 6 148.36555 43.57849 4.576640 291 D256 ## 7 666.42455 147.44219 13.189233 145 D283 ## 8 140.43424 43.60513 4.248564 128 D213 ## 9 86.63968 39.26696 6.077829 114 D41 ## 10 117.31209 31.70299 4.980824 1 D486 ## tag_id start_deployment end_deployment ## 1 H83101 2012-10-10 2013-06-02 ## 2 S49621 2003-07-03 2004-01-17 ## 3 A49007 2016-09-05 2017-01-09 ## 4 V63425 2016-12-04 2017-02-19 ## 5 B74989 2016-03-23 2016-11-08 ## 6 O66678 2013-09-07 2013-11-10 ## 7 G59298 2007-06-21 2007-11-14 ## 8 F64333 2001-12-12 2002-02-05 ## 9 X71699 2016-11-03 2017-05-10 ## 10 N33529 2006-12-20 2007-07-04 A full join keeps all records from both the left and the right table, matching them whenever possible. That is, we get in output all the dragons, with blanks in the morphometrics table for those that were only tracked and blanks in the deployments table for those that were only measured. Unfortunately, SQLite does not support full joins, so we cannot demonstrate it here, but it’s important to know that a full join exists and what it does because you’ll find yourself using it in any other database management program or even in R (see Chapter 13). 6.2.12 Nested SELECT statements Now that we know how to use joins, we can go back to our challenge of calculating the average wingspan for male versus female dragons. What we need to do is add the sex column to the morphometrics table. We can do this by looking at the dragon ID, which is the column the two tables have in common. So the join clause will look like this: SELECT morphometrics.dragon_id, wingspan_cm, sex FROM morphometrics -- this is our left table LEFT JOIN dragons -- this is our left table ON morphometrics.dragon_id = dragons.dragon_id -- this is the shared column LIMIT 10; ## dragon_id wingspan_cm sex ## 1 D96 1389.5527 F ## 2 D400 634.9109 &lt;NA&gt; ## 3 D316 1052.3702 M ## 4 D317 1356.8084 F ## 5 D484 1720.8641 M ## 6 D149 1533.5991 M ## 7 D285 698.8157 &lt;NA&gt; ## 8 D256 652.0053 &lt;NA&gt; ## 9 D283 1387.1943 F ## 10 D213 670.5283 &lt;NA&gt; By using a left join, we are saying that we want to keep all rows from the left table (morphometrics) while adding information on sex whenever available. Now we can compute the average wingspan broken down by sex: SELECT sex, AVG(wingspan_cm) AS mean_wingspan FROM ( SELECT morphometrics.dragon_id, wingspan_cm, sex FROM morphometrics LEFT JOIN dragons ON morphometrics.dragon_id = dragons.dragon_id ) GROUP BY sex; ## sex mean_wingspan ## 1 &lt;NA&gt; 645.3158 ## 2 F 1550.0009 ## 3 M 1549.1300 The one above is a nested query, which means there are two SELECT statements nested within one another. The inner SELECT statement (everything between the parentheses) is treated as if it were a table in the database. SQL will execute the query from the inside out, so even though that table physically does not exist, it gets temporarily created when the inner query is run and is then used in input to the second query. 6.2.13 Order of operations The fact that SQL will execute nested queries from the inside out is one aspect of order of operations. But there’s also a logic to the order in which SQL executes clauses within a query: first, it gathers the data, then it filters it and aggregates it as needed, then it computes results, and finally it sorts them and truncate them if necessary. Let’s look at this step by step: First, SQL executes the FROM clause and any JOIN clauses, if present, to determine what tables are being queried. Then, it will execute the WHERE clause to filter the data. Then, it will GROUP BY the column/s of interest. Then it will calculate any derived values based on aggregate functions. Then, it will apply any filters specified by HAVING. Now, and only now, it will execute the SELECT clause! Once the computations are completed and the output of SELECT is ready, SQL can start refining it. First, it will discard any duplicates if DISTINCT is specified. Then, it will sort the results based on ORDER BY. Finally, it will truncate the output if a LIMIT is specified. If you think about it, all of this makes logical sense. You can’t select a column if you’re not sure what table to look in. You can’t compute a per-group count before defining the groups. You can’t order results that you haven’t computed yet. But then why do we start our queries with SELECT? And does the order in which we write our queries matter? The answer to both of those questions is that there is a difference between the logical order of operations and the lexical (or syntactical) order of operations, which is how we actually write queries. Even though these don’t correspond, writing a query in any other order than the following is incorrect (and will return an error): SELECT FROM JOIN ON WHERE GROUP BY HAVING ORDER BY LIMIT; 6.3 Building a database 6.3.1 Creating a new database in SQLite Studio We are now going to see how to build a database by recreating the dragons database we have been practicing on. Let’s open up SQLite Studio and, on the Database tab, click “Add a database” (or use Ctrl/Cmd + O as a shortcut). Click on the green plus sign, navigate to the folder where you want to save the database, and choose a file name. Click “Save”. Now we need to also choose a name to use internally (this name will appear in the drop-down list of databases within SQLite, but it does not necessarily need to be the same as the filename.) Click “OK” and you should see your new database in the list on the left. 6.3.2 Creating tables Now let’s open the SQL editor (Tools &gt; SQL editor). Double check that you are working on the correct database (the name of the active database is shown in the toolbar). We are ready to create our first table! To create a table, we need to specify a name for the table, as well as a name and a data type for each column. The basic format is as follows: CREATE TABLE table_name ( column_1 data_type, column_2 data_type, column_3 data_type, ... ) Let’s start by creating the dragons table. Remember that each table needs to have a primary key, i.e., a column that serves as the unique identifier of each row. The values in this column need to be unique and cannot be null. In this table, we can use the dragon ID as the primary key: CREATE TABLE dragons ( dragon_id varchar(5), sex char(1), age_class varchar(8), species varchar(50), PRIMARY KEY (dragon_id) ); Notice that I specified a number of digits for each character variable. Because the format of the dragon ID is “D” + number from 1 up to 500 (for now), setting the ID as a character string with varying size up to 5 digits allows for IDs from “D1” to “D9999”. So far, we only have 500 individuals, so strictly it would have been enough to set the limit to 4 digits only, but it’s good to have some forethought and allow for growth into the future. At the same time, it seems reasonable to assume we won’t catch 10 thousand dragons in this project, so 5 digits is a good compromise. In reality, space is rarely limiting to the point where 4 or 10 digits makes a difference, so when in doubt err on the side of more room for growth. While dragon ID, age class, and species have a variable number of digits, sex always has one (it can be “M” or “F”). So we can make this a char instead of a varchar and specify it will have 1 digit. 6.3.3 Adding constraints We can also add some constraints for the purpose of quality assurance. For example, because the dragon ID is the primary key, we can’t accept null values in this column. Sex is always one of “M” or “F” and age is always one of “Juvenile”, “Subadult”, or “Adult”. In other SQL dialects you can add these after the fact, but in SQLite the only way to add these constraints is at the same time as you create the table. We can delete the table and re-create it by modifying the above syntax as follows: DROP TABLE dragons; CREATE TABLE dragons ( dragon_id varchar(5) NOT NULL, sex char(1) CHECK (sex IN (&#39;M&#39;, &#39;F&#39;)), age_class varchar(8) CHECK (age_class IN (&#39;Juvenile&#39;, &#39;Subadult&#39;, &#39;Adult&#39;)), species varchar(50), PRIMARY KEY (dragon_id) ); 6.3.4 Order of table creation Foreign keys are also specified as constraints. Because it’s not possible to enforce constraints as an afterthought, we need to plan the order in which we add tables carefully. If we try to add a foreign key that refers to a table that doesn’t exist yet, we won’t be able to. Let’s take another look at the diagram of our table relationships: Figure 6.2: Diagram of the dragons database Any table that has one or more foreign keys needs to be added after the related table/s. In our case, there are three “root” tables that do not have any foreign keys: the dragons table, the tags table, and the capture sites table. We can add these three first and then all the others. The tags table has a tag_id field which is unique and can therefore be used as a primary key. Note that when you make a column the primary key you automatically enforce a unique constraint on that column. However, SQLite does not enforce a not-null constraint on primary keys like most other SQL dialects. Because SQLite doesn’t, we have to do it ourselves: CREATE TABLE tags ( tag_id char(6) NOT NULL PRIMARY KEY, brand varchar(50), status varchar(20) ); The capture sites table has a site field which contains a 3-letter code that uniquely identifies the site. We can use that as a primary key. The UTM coordinates are numeric values for which we can use the data type called “double precision”, or just “double”. There are several possible choices for numeric data types. “Double precision” and “float” are both suitable data types for storing real numbers, but double precision stores numeric values with higher precision than float. Both of these allow for variable decimal places, whereas the data type “decimal” enforces the same number of decimal places across records. The choice between these data types depends on 1. whether we want the measurements to all have the same number of decimal places or not, and 2. how many significant digits do we expect/care about. Double precision can store up to 15 significant digits (unlike float which can store up to 8), but it also occupies double the space (64 bit instead of 32.) For UTM coordinates, the Y value has a minimum of 7 digits, and we want to keep decimal places because we need the highest precision possible on the position of animals in space. Therefore, we’ll go with double precision: CREATE TABLE capture_sites ( site char(3) NOT NULL PRIMARY KEY, utm_x double, utm_y double ); Note that I used an alternative syntax to specify the primary key. This is equivalent to the one I used above for the dragons table. 6.3.5 Populating the tables Now that we added a few tables, we can start to populate the database by loading the data as .csv files. On the Tools tab, click “Import.” Check that the database is correct and then select the table you want to import data into. For example, let’s start with the dragons table: Click Next. Now, browse your directory to select the input file. Then check the box that says “First line represents CSV column names”, make sure the field separator is a comma, and set the NULL values to NA (which is how they are encoded in the .csv.) Click Finish. To check if the table was imported correctly, go back into the query editor and try to look at the first 10 rows: SELECT * FROM dragons LIMIT 10; ## dragon_id sex age_class species ## 1 D1 F Subadult Hebridean Black ## 2 D2 &lt;NA&gt; Juvenile Romanian Longhorn ## 3 D3 F Adult Hebridean Black ## 4 D4 F Adult Peruvian Vipertooth ## 5 D5 &lt;NA&gt; Juvenile Ukrainian Ironbelly ## 6 D6 F Adult Norwegian Ridgeback ## 7 D7 M Adult Hebridean Black ## 8 D8 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 9 D9 F Adult Norwegian Ridgeback ## 10 D10 F Adult Common Welsh Green If everything looks good, we can go ahead and import data in the other two tables. 6.3.6 Autoincrements as primary keys Sometimes a table does not contain any columns with unique values. This is the case for all the tables we have left to add. What do we use as primary key in these situations? Adding a column with a serial number that gets automatically updated is a good option. SQLite has something called auto-increment, which is an integer column that automatically increases by 1 each time you add a row to a table. Because it’s incremental, the values of an auto-increment will always be unique, and because it’s automatic, they will never be null. Sounds like a perfect candidate for a primary key. The problem with using an auto-increment as a primary key arises when you’re trying to import data from a .csv file. If the column with the auto-increment does not already exist in the .csv, SQLite won’t let you import the file into the table because the number of columns does not match. We don’t want to add the auto-increment into the .csv ourselves because that defeats the purpose of having SQLite doing it for us. But if we import the .csv as it is (without primary key) and then add the auto-increment column later, we won’t be able to make it the primary key because SQLite won’t let us. So, what do we do? One workaround that people have found to solve this issue is to trick SQLite by using a temporary table. This is how the process works: Create the table the way we want it, with an auto-increment primary key plus all the columns we want to import from the .csv; Create a temporary table without primary key that only contains the columns from the .csv; Import the .csv into the temporary table; Populate the final table by pulling data from the temporary table; Delete the temporary table. A little convoluted, but it does the job. Let’s demonstrate this on the captures table. First, we create the table like we want it to look in the end (note that I am adding foreign keys; we’ll go over that part in the next section): CREATE TABLE captures ( capture_id INTEGER PRIMARY KEY AUTOINCREMENT, dragon_id varchar(5), date text, site char(3), FOREIGN KEY(dragon_id) REFERENCES dragons(dragon_id) FOREIGN KEY(site) REFERENCES capture_sites(site) ); Second, we create a temporary table without the primary key (no need to add foreign keys to this one as we are going to delete it anyway): CREATE TABLE captures_temp ( dragon_id varchar(5), date text, site char(3)); Now on Tools &gt; Import, we upload captures.csv into captures_temp. Then we can populate the final table as follows: INSERT INTO captures(dragon_id, date, site) SELECT * FROM captures_temp; And finally we delete our temporary table: DROP TABLE captures_temp; We better get familiar with this workflow because we are going to use it for all the other tables now. 6.3.7 Foreign keys For each of the remaining tables, we will specify one or more foreign keys to enforce the relationships between tables. Each foreign key is the primary key of another table. See for example what we did above: the captures table we just imported contains information on when and where each dragon was captured. This means this table needs to have two foreign keys: the dragon_id column links it to the dragons table and the site column links it to the capture sites table. Now let’s apply the concept to the other tables. The morphometrics table will have a single foreign key linking it to the dragons table (the dragon ID). The second column is a date – SQLite does not have a dedicated data type for dates. Instead, we stored this as a character string in ISO8601 format (“YYYY-MM-DD HH:MM:SS.SSS”). This time there is no need for double precision because we want to only retain up to the third decimal place and the numbers are not larger than ~3000, so 8 significant digits is sufficient. We’ll use float as the data type for the measurements. Because individuals may have been measured multiple times, none of the existing columns are unique. This means we’ll create a serial number to use as the primary key. We’ll use the same trick as above: CREATE TABLE morphometrics ( measurement_id INTEGER PRIMARY KEY AUTOINCREMENT, dragon_id varchar(5), date text, total_body_length_cm float, wingspan_cm float, tail_length_cm float, tarsus_length_cm float, claw_length_cm float, FOREIGN KEY (dragon_id) REFERENCES dragons(dragon_id) ); CREATE TABLE morphometrics_temp ( dragon_id varchar(5), date text, total_body_length_cm float, wingspan_cm float, tail_length_cm float, tarsus_length_cm float, claw_length_cm float ); Now on Tools &gt; Import, we upload morphometrics.csv into morphometrics_temp. Then we populate the final table: INSERT INTO morphometrics(dragon_id, date, total_body_length_cm, wingspan_cm, tail_length_cm, tarsus_length_cm, claw_length_cm) SELECT * FROM morphometrics_temp; And delete our temporary table: DROP TABLE morphometrics_temp; The diet table contains repeated sample IDs and repeated item IDs within each sample. We’ll need a serial number here too because none of the columns are unique. The item ID is an integer so we are going to use a new numeric data type for it. The foreign key will be, again, the dragon ID referring to the dragons table: CREATE TABLE diet ( diet_id INTEGER PRIMARY KEY AUTOINCREMENT, dragon_id varchar(5), sample_id varchar(8), date text, item_id integer, item varchar(50), FOREIGN KEY (dragon_id) REFERENCES dragons(dragon_id) ); CREATE TABLE diet_temp ( dragon_id varchar(5), sample_id varchar(8), date text, item_id integer, item varchar(50) ); Upload diet.csv into diet_temp. INSERT INTO diet(dragon_id, sample_id, date, item_id, item) SELECT * FROM diet_temp; DROP TABLE diet_temp; The deployments table assigns a tag to each individual within a certain period of time. The dragon_id column will be the foreign key that links it to the dragons table, and the tag_id column will link it to the tags table. The start and end deployment dates will be stored as ISO8601 text. Again, we’ll need a serial number to use as a primary key: CREATE TABLE deployments ( deployment_id INTEGER PRIMARY KEY AUTOINCREMENT, dragon_id varchar(5), tag_id char(6), start_deployment text, end_deployment text, FOREIGN KEY(dragon_id) REFERENCES dragons(dragon_id) FOREIGN KEY(tag_id) REFERENCES tags(tag_id) ); CREATE TABLE deployments_temp ( dragon_id varchar(5), tag_id char(6), start_deployment text, end_deployment text ); Upload deployments.csv into deployments_temp. INSERT INTO deployments(dragon_id, tag_id, start_deployment, end_deployment) SELECT * FROM deployments_temp; DROP TABLE deployments_temp; Now we can input the telemetry data. This table contains the raw tracking data as we download it from the tags. We’ll need a serial number to uniquely identify each record, and we’ll add the tag ID as the foreign key to the tags table: CREATE TABLE gps_data_raw ( gps_id INTEGER PRIMARY KEY AUTOINCREMENT, tag_id char(6), timestamp text, utm_x double, utm_y double, FOREIGN KEY(tag_id) REFERENCES tags(tag_id) ); CREATE TABLE gps_data_raw_temp ( tag_id char(6), timestamp text, utm_x double, utm_y double ); Upload telemetry_raw.csv into gps_data_raw_temp. INSERT INTO gps_data_raw(tag_id, timestamp, utm_x, utm_y) SELECT * FROM gps_data_raw_temp; DROP TABLE gps_data_raw_temp; 6.3.8 Crossing existing information to derive new tables The raw GPS data table does not give us any information about which animal each location corresponds to; all we know is the tag ID. Each tag does not correspond to an individual, because some tags are reused on multiple dragons. So how do we make these data usable? How do we know who is who? To associate each location to the correct animal, we need to know who was wearing the tag at the time that location was taken. There is a very elegant solution to our problem, as we can pull the range of dates an individual was wearing a certain tag from the deployments table, cross those dates with the dates in the raw GPS data, and create an updated telemetry table where each location is assigned to the correct individual. No manual work involved. Are you ready for some magic?! First, we create the table structure: CREATE TABLE gps_data ( loc_id INTEGER PRIMARY KEY, tag_id char(6), dragon_id varchar(5), timestamp text, utm_x double, utm_y double, FOREIGN KEY (tag_id) REFERENCES tags(tag_id) FOREIGN KEY (dragon_id) REFERENCES dragons(dragon_id) ); And then we populate it by pulling information from the raw GPS and deployment tables. Locations are assigned to the individual that was wearing the tag at the time based on the WHERE clause: INSERT INTO gps_data ( tag_id, dragon_id, timestamp, utm_x, utm_y) SELECT deployments.tag_id, deployments.dragon_id, gps_data_raw.timestamp, gps_data_raw.utm_x, gps_data_raw.utm_y FROM deployments LEFT JOIN gps_data_raw USING (tag_id) WHERE gps_data_raw.tag_id = deployments.tag_id AND ( ( (strftime(gps_data_raw.timestamp) &gt;= strftime(deployments.start_deployment)) AND (strftime(gps_data_raw.timestamp) &lt;= strftime(deployments.end_deployment)) ) OR ( (gps_data_raw.timestamp &gt;= deployments.start_deployment) AND (deployments.end_deployment IS NULL) ) ); Note that, because we populated this table with data from other existing tables, we ended up using INSERT INTO anyway and there was no need to use our trick with a temporary table. It should now be apparent that keeping the deployments table correctly filled out with no gaps or errors is of vital importance for the integrity of the whole telemetry database. Having the database set up this way means we never have to manually assign locations to animals, which would for sure lead to errors, but it also means that any analysis downstream hinges on keeping the deployments table up-to-date with new captures, tag retrievals, and deaths. This is just one example of how databases can save us time and ensure data integrity with minimal routine effort, but only if the data is curated with care in the first place. "],
["rsqlite.html", "Chapter 7 Interfacing Databases in R with RSQLite 7.1 The RSQLite package 7.2 Establising a database connection 7.3 Sending queries to the database 7.4 A note on reproducibility", " Chapter 7 Interfacing Databases in R with RSQLite 7.1 The RSQLite package RSQLite is an R package that provides an interface with SQLite such that you can interact with the database from within R. Everything we have done so far on the database can be done from R without ever opening SQLite Studio. You could actually do all of those things without even having SQLite installed on your computer, because the R package itself contains SQLite. In turn, RSQLite relies on another R package called DBI (which stands for database interface). DBI is a package that provides generic functions for interfacing databases with R, and RSQLite makes adjustments that are specific to SQLite. So, first things first, we are going to load the DBI package: library(DBI) 7.2 Establising a database connection We start by connecting to a database, either an existing one or one we create new. The dbConnect function takes as input a file path for the database. If the path exists, it will connect to the existing database; if it does not, it will create it. We also specify that the type of database connection is SQLite: dragons_db &lt;- dbConnect(RSQLite::SQLite(), &quot;../../Course Material/Data/dragons/dragons.db&quot;) 7.3 Sending queries to the database Now that the connection is established, we can start sending queries to the database. Any time we perform actions that affect the database (creating or deleting tables, inserting data, etc.) we use the function dbExecute. This function takes as input a database connection and the SQL code that we want to run (as a character string). For example, we can copy-paste the code we used in Chapter 6 to create the dragons table: dbExecute(dragons_db, &quot;CREATE TABLE dragons ( dragon_id varchar(5) NOT NULL, sex char(1) CHECK (sex IN (&#39;M&#39;, &#39;F&#39;)), age_class varchar(8) CHECK (age_class IN (&#39;Juvenile&#39;, &#39;Subadult&#39;, &#39;Adult&#39;)), species varchar(50), PRIMARY KEY (dragon_id) );&quot;) Now, instead of manually importing the data by pointing and clicking, we can load the data from .csv files into R and insert it into the newly created table. dragons &lt;- read.csv(&quot;../../Course Material/Data/dragons/dragons.csv&quot;, stringsAsFactors = FALSE) names(dragons) ## [1] &quot;dragon&quot; &quot;sex&quot; &quot;age_class&quot; &quot;species&quot; Note that the column names in the .csv differ slightly from the column names we assigned when creating the dragons table. This is a problem because RSQLite won’t recognize the columns and won’t be able to insert the data. We can prevent this by changing any names that do not match so that they match the database: names(dragons)[1] &lt;- &quot;dragon_id&quot; Now we can enter the data from the .csv into the dragons table. The function dbWriteTable takes as input the database connection, the name of the table we want to fill (in quotes), and the name of the data frame we want to input. Note that I’m using append = TRUE because otherwise RSQLite will overwrite the current table with whatever is in the .csv, and any constraints we have enforced (primary key, foreign key, etc.) will be lost: dbWriteTable(dragons_db, &quot;dragons&quot;, dragons, append = TRUE) Now we can send a query to the database to check that the data were inserted correctly. Because this is a query that retrieves data, not a query that modifies the database, we use dbGetQuery instead of dbExecute: dbGetQuery(dragons_db, &quot;SELECT * FROM dragons LIMIT 10;&quot;) ## dragon_id sex age_class species ## 1 D1 F Subadult Hebridean Black ## 2 D2 &lt;NA&gt; Juvenile Romanian Longhorn ## 3 D3 F Adult Hebridean Black ## 4 D4 F Adult Peruvian Vipertooth ## 5 D5 &lt;NA&gt; Juvenile Ukrainian Ironbelly ## 6 D6 F Adult Norwegian Ridgeback ## 7 D7 M Adult Hebridean Black ## 8 D8 &lt;NA&gt; Juvenile Peruvian Vipertooth ## 9 D9 F Adult Norwegian Ridgeback ## 10 D10 F Adult Common Welsh Green Now we can repeat this process with the other tables: dbExecute(dragons_db, &quot;CREATE TABLE tags ( tag_id char(6) NOT NULL PRIMARY KEY, brand varchar(50), status varchar(20) );&quot;) tags &lt;- read.csv(&quot;../../Course Material/Data/dragons/tags.csv&quot;) dbWriteTable(dragons_db, &quot;tags&quot;, tags, append = TRUE) dbGetQuery(dragons_db, &quot;SELECT * FROM tags LIMIT 10;&quot;) ## tag_id brand status ## 1 N33529 Heatwave Telemetry Refurbished ## 2 J47978 Undertone New ## 3 R61684 Heatwave Telemetry New ## 4 B35524 Aerotronic New ## 5 T55954 Aerotronic New ## 6 O31688 Undertone New ## 7 B61925 Undertone New ## 8 P47677 Aerotronic New ## 9 P35987 Aerotronic New ## 10 I41609 Heatwave Telemetry Refurbished dbExecute(dragons_db, &quot;CREATE TABLE capture_sites ( site char(3) NOT NULL PRIMARY KEY, utm_x double, utm_y double );&quot;) capture_sites &lt;- read.csv(&quot;../../Course Material/Data/dragons/capture_sites.csv&quot;) names(capture_sites)[2:3] &lt;- c(&quot;utm_x&quot;, &quot;utm_y&quot;) dbWriteTable(dragons_db, &quot;capture_sites&quot;, capture_sites, append = TRUE) dbGetQuery(dragons_db, &quot;SELECT * FROM capture_sites;&quot;) ## site utm_x utm_y ## 1 LOG 430659 4620909 ## 2 SLC 424790 4512583 ## 3 MOA 626325 4270426 ## 4 STG 271064 4108535 ## 5 DLT 364106 4357045 Remember how in SQLite we had to find a workaround to add auto-incremental primary keys? Well, using RSQLite to build the database instead means we do not need that trick anymore. We can just add the auto-incremental serial number to the data and append it to the table while keeping all the structure and the constraints we have enforced. Let’s try this with the captures table. First, we create the table: dbExecute(dragons_db, &quot;CREATE TABLE captures ( capture_id INTEGER PRIMARY KEY AUTOINCREMENT, dragon_id varchar(5), date text, site char(3), FOREIGN KEY(dragon_id) REFERENCES dragons(dragon_id) FOREIGN KEY(site) REFERENCES capture_sites(site) );&quot;) Then we read in the .csv file and add a column called capture_id with the serial number we’ll use as primary key: captures &lt;- read.csv(&quot;../../Course Material/Data/dragons/captures.csv&quot;) captures$capture_id &lt;- 1:nrow(captures) head(captures) ## dragon capture_date capture_site capture_id ## 1 D1 2012-08-10 MOA 1 ## 2 D2 2013-07-23 MOA 2 ## 3 D3 2016-10-19 SLC 3 ## 4 D4 2001-01-10 LOG 4 ## 5 D5 2000-09-28 MOA 5 ## 6 D6 2016-02-25 LOG 6 Not only the column names need to match the names in the database table, but the order has to match too. So we re-order the columns: captures &lt;- captures[, c(&quot;capture_id&quot;, &quot;dragon&quot;, &quot;capture_date&quot;, &quot;capture_site&quot;)] We fix the names so they match: names(captures)[2:4] &lt;- c(&quot;dragon_id&quot;, &quot;date&quot;, &quot;site&quot;) And we append the data frame to the database table: dbWriteTable(dragons_db, &quot;captures&quot;, captures, append = TRUE) Let’s check that everything worked: dbGetQuery(dragons_db, &quot;SELECT * FROM captures LIMIT 10;&quot;) ## capture_id dragon_id date site ## 1 1 D1 2012-08-10 MOA ## 2 2 D2 2013-07-23 MOA ## 3 3 D3 2016-10-19 SLC ## 4 4 D4 2001-01-10 LOG ## 5 5 D5 2000-09-28 MOA ## 6 6 D6 2016-02-25 LOG ## 7 7 D7 2012-11-05 MOA ## 8 8 D8 2009-07-14 LOG ## 9 9 D9 2001-08-17 STG ## 10 10 D10 2017-01-17 LOG Now we can repeat this process with the remaining tables: dbExecute(dragons_db, &quot;CREATE TABLE morphometrics ( measurement_id INTEGER PRIMARY KEY AUTOINCREMENT, dragon_id varchar(5), date text, total_body_length_cm float, wingspan_cm float, tail_length_cm float, tarsus_length_cm float, claw_length_cm float, FOREIGN KEY (dragon_id) REFERENCES dragons(dragon_id) );&quot;) # Load csv file morphometrics &lt;- read.csv(&quot;../../Course Material/Data/dragons/morphometrics.csv&quot;) # Add auto-incremental number morphometrics$measurement_id &lt;- 1:nrow(morphometrics) # Re-order columns morphometrics &lt;- morphometrics[, c(&quot;measurement_id&quot;, &quot;dragon&quot;, &quot;date&quot;, &quot;total_body_length_cm&quot;, &quot;wingspan_cm&quot;, &quot;tail_length_cm&quot;, &quot;tarsus_length_cm&quot;, &quot;claw_length_cm&quot;)] # Change column names to match names(morphometrics)[2] &lt;- &quot;dragon_id&quot; # Append to database table dbWriteTable(dragons_db, &quot;morphometrics&quot;, morphometrics, append = TRUE) dbGetQuery(dragons_db, &quot;SELECT * FROM morphometrics LIMIT 10;&quot;) ## measurement_id dragon_id date total_body_length_cm wingspan_cm ## 1 1 D96 2012-10-10 1069.8965 1389.5527 ## 2 2 D400 2003-07-03 333.4600 634.9109 ## 3 3 D316 2017-09-08 866.8935 1052.3702 ## 4 4 D317 2016-09-05 1146.9708 1356.8084 ## 5 5 D484 2016-12-04 1032.0520 1720.8641 ## 6 6 D149 2012-02-13 919.9908 1533.5991 ## 7 7 D285 2016-03-23 304.8285 698.8157 ## 8 8 D256 2013-09-07 358.9701 652.0053 ## 9 9 D283 2007-06-21 1698.1918 1387.1943 ## 10 10 D213 2001-12-12 353.6952 670.5283 ## tail_length_cm tarsus_length_cm claw_length_cm ## 1 595.2706 121.65175 15.596219 ## 2 104.2241 38.10844 4.305086 ## 3 373.7619 68.16869 12.719697 ## 4 542.5670 172.43663 14.809363 ## 5 596.4419 114.05057 11.985672 ## 6 563.9201 134.18051 11.005070 ## 7 115.8964 42.18657 5.041634 ## 8 148.3656 43.57849 4.576640 ## 9 666.4246 147.44219 13.189233 ## 10 140.4342 43.60513 4.248564 dbExecute(dragons_db, &quot;CREATE TABLE diet ( diet_id INTEGER PRIMARY KEY AUTOINCREMENT, dragon_id varchar(5), sample_id varchar(8), date text, item_id integer, item varchar(50), FOREIGN KEY (dragon_id) REFERENCES dragons(dragon_id) );&quot;) diet &lt;- read.csv(&quot;../../Course Material/Data/dragons/diet.csv&quot;) diet$diet_id &lt;- 1:nrow(diet) diet &lt;- diet[, c(&quot;diet_id&quot;, &quot;dragon&quot;, &quot;sample_id&quot;, &quot;sample_dates&quot;, &quot;item_id&quot;, &quot;item&quot;)] names(diet)[c(2, 4)] &lt;- c(&quot;dragon_id&quot;, &quot;date&quot;) dbWriteTable(dragons_db, &quot;diet&quot;, diet, append = TRUE) dbGetQuery(dragons_db, &quot;SELECT * FROM diet LIMIT 10;&quot;) ## diet_id dragon_id sample_id date item_id item ## 1 1 D221 D221-1 2017-11-22 1 Domestic cow ## 2 2 D221 D221-1 2017-11-22 2 Domestic goat ## 3 3 D221 D221-1 2017-11-22 3 Coyote ## 4 4 D221 D221-1 2017-11-22 4 Domestic cow ## 5 5 D221 D221-1 2017-11-22 5 Domestic cow ## 6 6 D221 D221-1 2017-11-22 6 Mule deer ## 7 7 D119 D119-1 2012-06-28 1 Mule deer ## 8 8 D119 D119-1 2012-06-28 2 Cougar ## 9 9 D119 D119-1 2012-06-28 3 Domestic goat ## 10 10 D119 D119-1 2012-06-28 4 Mountain goat dbExecute(dragons_db, &quot;CREATE TABLE deployments ( deployment_id INTEGER PRIMARY KEY AUTOINCREMENT, dragon_id varchar(5), tag_id char(6), start_deployment text, end_deployment text, FOREIGN KEY(dragon_id) REFERENCES dragons(dragon_id) FOREIGN KEY(tag_id) REFERENCES tags(tag_id) );&quot;) deployments &lt;- read.csv(&quot;../../Course Material/Data/dragons/deployments.csv&quot;) deployments$deployment_id &lt;- 1:nrow(deployments) deployments &lt;- deployments[, c(&quot;deployment_id&quot;, &quot;dragon&quot;, &quot;tag&quot;, &quot;start_deploy&quot;, &quot;end_deploy&quot;)] names(deployments)[2:5] &lt;- c(&quot;dragon_id&quot;, &quot;tag_id&quot;, &quot;start_deployment&quot;, &quot;end_deployment&quot;) dbWriteTable(dragons_db, &quot;deployments&quot;, deployments, append = TRUE) dbGetQuery(dragons_db, &quot;SELECT * FROM deployments LIMIT 10;&quot;) ## deployment_id dragon_id tag_id start_deployment end_deployment ## 1 1 D486 N33529 2006-12-20 2007-07-04 ## 2 2 D393 J47978 2008-01-13 2008-10-13 ## 3 3 D88 R61684 2004-09-19 2004-12-01 ## 4 4 D330 B35524 2015-11-21 2016-08-02 ## 5 5 D478 T55954 2002-05-07 2002-10-26 ## 6 6 D300 O31688 2006-01-20 2006-08-23 ## 7 7 D380 B61925 2015-01-27 2015-10-21 ## 8 8 D315 P47677 2006-03-03 2006-06-06 ## 9 9 D209 P35987 2007-02-26 2007-05-31 ## 10 10 D357 I41609 2013-09-09 2014-03-08 dbExecute(dragons_db, &quot;CREATE TABLE gps_data_raw ( gps_id INTEGER PRIMARY KEY AUTOINCREMENT, tag_id char(6), timestamp text, utm_x double, utm_y double, FOREIGN KEY(tag_id) REFERENCES tags(tag_id) );&quot;) gps_data_raw &lt;- read.csv(&quot;../../Course Material/Data/dragons/telemetry_raw.csv&quot;) gps_data_raw$gps_id &lt;- 1:nrow(gps_data_raw) gps_data_raw &lt;- gps_data_raw[, c(&quot;gps_id&quot;, &quot;tag&quot;, &quot;timestamp&quot;, &quot;x&quot;, &quot;y&quot;)] names(gps_data_raw)[c(2, 4, 5)] &lt;- c(&quot;tag_id&quot;, &quot;utm_x&quot;, &quot;utm_y&quot;) dbWriteTable(dragons_db, &quot;gps_data_raw&quot;, gps_data_raw, append = TRUE) dbGetQuery(dragons_db, &quot;SELECT * FROM gps_data_raw LIMIT 10;&quot;) ## gps_id tag_id timestamp utm_x utm_y ## 1 1 N33529 2006-12-20 00:02:03 626479.9 4270480 ## 2 2 N33529 2006-12-20 03:02:01 628321.6 4271404 ## 3 3 N33529 2006-12-20 06:00:45 628111.1 4271812 ## 4 4 N33529 2006-12-20 08:59:56 628294.4 4271940 ## 5 5 N33529 2006-12-20 12:02:14 628642.2 4273090 ## 6 6 N33529 2006-12-20 15:00:12 628750.1 4273879 ## 7 7 N33529 2006-12-20 18:00:29 625775.1 4272723 ## 8 8 N33529 2006-12-20 20:59:54 625682.6 4272723 ## 9 9 N33529 2006-12-21 00:02:12 625493.0 4272917 ## 10 10 N33529 2006-12-21 03:01:18 628051.1 4272672 Now we are ready to generate the gps_data table based on information from existing tables. We can create and populate the table in 2 steps using dbExecute: dbExecute(dragons_db, &quot;CREATE TABLE gps_data ( loc_id INTEGER PRIMARY KEY, tag_id char(6), dragon_id varchar(5), timestamp text, utm_x double, utm_y double, FOREIGN KEY (tag_id) REFERENCES tags(tag_id) FOREIGN KEY (dragon_id) REFERENCES dragons(dragon_id) );&quot;) dbExecute(dragons_db, &quot;INSERT INTO gps_data ( tag_id, dragon_id, timestamp, utm_x, utm_y) SELECT deployments.tag_id, deployments.dragon_id, gps_data_raw.timestamp, gps_data_raw.utm_x, gps_data_raw.utm_y FROM deployments LEFT JOIN gps_data_raw USING (tag_id) WHERE gps_data_raw.tag_id = deployments.tag_id AND ( ( (strftime(gps_data_raw.timestamp) &gt;= strftime(deployments.start_deployment)) AND (strftime(gps_data_raw.timestamp) &lt;= strftime(deployments.end_deployment)) ) OR ( (gps_data_raw.timestamp &gt;= deployments.start_deployment) AND (deployments.end_deployment IS NULL) ) );&quot;) dbGetQuery(dragons_db, &quot;SELECT * FROM gps_data LIMIT 10;&quot;) ## loc_id tag_id dragon_id timestamp utm_x utm_y ## 1 1 N33529 D486 2006-12-20 00:02:03 626479.9 4270480 ## 2 2 N33529 D486 2006-12-20 03:02:01 628321.6 4271404 ## 3 3 N33529 D486 2006-12-20 06:00:45 628111.1 4271812 ## 4 4 N33529 D486 2006-12-20 08:59:56 628294.4 4271940 ## 5 5 N33529 D486 2006-12-20 12:02:14 628642.2 4273090 ## 6 6 N33529 D486 2006-12-20 15:00:12 628750.1 4273879 ## 7 7 N33529 D486 2006-12-20 18:00:29 625775.1 4272723 ## 8 8 N33529 D486 2006-12-20 20:59:54 625682.6 4272723 ## 9 9 N33529 D486 2006-12-21 00:02:12 625493.0 4272917 ## 10 10 N33529 D486 2006-12-21 03:01:18 628051.1 4272672 7.4 A note on reproducibility When considering the utility of interfacing a database with R, evaluating the benefits in terms of reproducibility is an important criterion. As far as the code to create the database, we could have saved a SQL script in the SQLite query editor and that would have been comparable to saving it as an R script. However, by loading the data into the database in R we eliminated the need for any pointing and clicking. We were able to fully build and populate the database using a single R script. This gives a major advantage in terms of reproducibility. Moreover, using R as an interface for the database means we can seamlessly transition from querying the data to processing it and analyzing it within the same programming framework, all while taking advantages of database-specific functionalities that R does not provide on its own. "],
["rmarkdown.html", "Chapter 8 Dynamic Documents with RMarkdown 8.1 What is a dynamic document? 8.2 Markdown and RMarkdown 8.3 Installing RMarkdown 8.4 Writing an RMarkdown document", " Chapter 8 Dynamic Documents with RMarkdown 8.1 What is a dynamic document? This Chapter is an introduction to creating dynamic documents in R using the rmarkdown package. But what do I mean by dynamic document? In this context, a dynamic document is a file that combines code, the output of that code, and narrative writing all in one. As a matter of fact, you are reading a dynamic document right now: this whole book is written in RMarkdown! Figure 8.1: Artwork by Allison Horst In a dynamic document, the code is executed within the document in real time and it produces “living” figures, tables, models, etc. that are updated any time the code itself or the underlying data is updated. We can combine text and code to reproduce any graphical output we want to display in our finished document without having to do anything manually, and the document gets automatically updated any time there is a change upstream in the code or the input data. Because of this, dynamic documents are also reproducible. 8.2 Markdown and RMarkdown Markdown is a system that translates plain text into HTML (the standard language for creating web pages). RMarkdown is a variant of Markdown specifically created for R that combines Markdown with code and allows you to export dynamic documents in a variety of formats ranging from PDF documents to presentation slides to web pages. The advantages of preparing documents in RMarkdown are numerous: Your text and code are consolidated in the same place rather than in separate documents; You don’t need to save code-generated images and then insert them into a different document; You don’t have to re-save all your plots and manually replace them if you change something in the data or the code; You can forget about all the headaches of having to figure out page breaks or figure placement; You can put all your documents under version control, not just your code. The file format for RMarkdown is .Rmd. This is the format of the dynamic document that includes code chunks and narrative text. The process of exporting this document into a publishable format (such as .pdf, .html, etc.) is called knitting. The knitting consists of two steps that happen under the hood. First, the R package knitr will take the .Rmd file, run the R code that is contained in it, and convert it into an .md file. The .md file is then passed on to Pandoc, which is a universal document converter. Pandoc will handle the conversion to the final file format. 8.3 Installing RMarkdown To get started with RMarkdown documents, we need to make sure we have the necessary R packages installed: install.packages(&quot;rmarkdown&quot;) install.packages(&quot;knitr&quot;) 8.4 Writing an RMarkdown document 8.4.1 Creating the document In RStudio, we create a new RMarkdown document by clicking on the File tab and selecting New File &gt; R Markdown. Figure 8.2: Create a new RMarkdown file A window will pop up asking us what do we want the default format of our document to be. If you are putting together a document to be displayed as a web page, you will select HTML. Even if you want to produce a PDF or other type of document, it’s still a good idea to select HTML here, because you can easily switch from HTML to PDF or others but not the other way around. Figure 8.3: Create a new RMarkdown file 8.4.2 YAML headers Once you click OK, RStudio will create a new document that automatically contains a YAML header. YAML stands for “YAML Ain’t Markup Language” and it encodes the metadata of the document. This is what it looks like: --- title: &quot;Untitled&quot; author: &quot;Simona Picardi&quot; date: &quot;2/18/2021&quot; output: html_document --- The author and date were automatically added in, as well as the default output format (HTML). We can go ahead and edit the title, or anything else that is in quotes if we want the date to be different our our name to appear differently (or add more names). The content of the YAML header will appear on top of our document. 8.4.3 Code chunks Under the YAML header, the template document contains what is called a code chunk: ```{r setup, include=FALSE} knitr::opts_chunk$set(echo = TRUE) ``` A code chunk is recognized by RMarkdown as containing code. Inside the curly brackets, we specify the language the code is written in (RStudio defaults to R, but we can change this to a different programming language – RMarkdown understands SQL, python, css, and many others.) Then comes the name of the code chunk. This one was automatically named “setup” by RStudio, but we can give it any other name. The important thing is that we can never repeat the same name for a code chunk within the same document. After the comma we can include options that will determine how the code chunk behaves. In this case, the code chunk has the option include=FALSE, which means neither the code or its result will be displayed in the finished document. Other frequently used TRUE/FALSE options are: eval: when set to FALSE, the code will not be run when knitting the document (default is TRUE); echo: when set to FALSE, the code will not show up in the document but it will be run under the hood and its results will be displayed (default is TRUE); warning: this option controls whether warning messages are displayed (default is TRUE); error: this option controls whether error messages are displayed (default is FALSE). By playing with eval and echo we can control whether our code is run and displayed or any combination of these. For example, eval = FALSE, echo = TRUE means our code chunk won’t be run but it will show up in the document (this is great for a tutorial where you want to show someone how to install a package, but you don’t want to reinstall it yourself every time you knit the document); eval = TRUE, echo = TRUE means our code chunk will be displayed as well as run, and its results will be displayed too (this is great for teaching purposes, when you want to show how to write code to produce a certain result); eval = TRUE, echo = FALSE means the code will be run but it will not be visible in the final document (this is great for including a graph in the final document, where the code that produced the graph is not the point.) To insert a new code chunk in your document, you can click on the green “+C” in your RStudio script toolbar (ore use the shortcut Ctrl + Alt + I). 8.4.4 Inline code Besides code chunks, you can also embed code within the text using the syntax `r my_code`. The code will be run and the results displayed in its place. For example, if I want to know what 2 + 2 is, I can type `r 2 + 2` in the document and the results displayed will be 4. To quote code verbatim (which means without interpreting it or executing it, just displaying it), omit the “r” between the two grave symbols. I also like to use the same syntax whenever I mention R functions or any other R-specific words, so it looks like this: function. That makes it clear to the reader that I’m using the word to refer to something that exists in R (a function, an object, a package) and not to the common meaning of that word. 8.4.5 Text formatting Anything that is not inside a code chunk or inline code is interpreted by RMarkdown as text. There are many different formatting styles that you can achieve with RMarkdown syntax. You can use italics by wrapping text in asterisks, bold with double asterisks, and strikethrough with double tilde. You can add block quotes using a &gt; at the beginning of a line: This is a block quote. Or equations: \\[E = mc^{2}\\] The headers in this book are formatted using RMarkdown, and so are bullet lists. Headers are lines that start with one or more hashtags, with the number of hashtags determining the size of the header (one hashtags for main headers, two for sections, three for subsections, etc.) For an overview of how to format text I recommend consulting the RMarkdown cheatsheet. Wonder how I just embedded that link? Just type the words you want to hyperlink in brackets followed by the link in parentheses: [](). 8.4.6 Embedding images Sometimes you may want to add an image in an RMarkdown document that is not code-generated (for example, a photo). There are several ways to do that. One is to use the syntax ![Caption](path_to_image.png) (this needs to be in a new line). Another option is to use the include_graphics function from knitr. You can create a new code chunk where you want the image to appear: ```{r image, fig.cap=&quot;this is a caption&quot;, fig.align=&#39;center&#39;, out.width=&#39;100%&#39;} knitr::include_graphics(&quot;img/my_image.png&quot;) ``` Note the chunk options: fig.cap allows you to add a caption under the figure, fig.align allows you to tweak the alignment of the image with respect to the page, and you can control the size with out.width. 8.4.7 Adding a table of contents You can add a table of contents to your document by adding an option for it in the YAML header: --- title: &quot;Untitled&quot; author: &quot;Simona Picardi&quot; date: &quot;2/18/2021&quot; output: html_document: toc: true toc_depth: 2 --- The option toc: true activates the table of contents. You can then list additional options to tweak the appearance of the table of contents. For example, toc_depth controls how many header levels are visible in the table of contents (default is 3, which means headers that range from #-###). Another option is toc_float, which means the table of content will float on the side of the page even as we scroll down. 8.4.8 Knitting the document When you are done composing your document and you want to see the rendered version, it’s time to knit. You can click Knit on the RStudio script toolbar and the process will start. Figure 8.4: Knitting an RMarkdown file You will see the progress status in the console. If there are any formatting mistakes, you will get an error that points you to the line where the problem is. A very common reason why knitting may fail is if you forgot to give the code chunks different names, so watch out for that! Once the knitting is complete, you’ll find an HTML file in your working directory with the same name as the .Rmd file. Double click on it, and your rendered document will open in a browser window. 8.4.9 The sky is the limit! This is a brief overview on how to get started with RMarkdown, but the sky is the limit when it comes to possibilities for customization of RMarkdown documents. You can add tables, footnotes, and even a bibliography to your document which can be automatically synchronized with your reference management system. You can choose among several different themes for your rendered document or you could even make your own theme. Here are some great resources if you want to learn more about these and other functionalities of RMarkdown: The RStudio tutorial to RMarkdown R Markdown: The Definitive Guide Creating Dynamic Documents with RMarkdown and Knitr "],
["github-pages.html", "Chapter 9 Automatically Generated Websites with GitHub Pages 9.1 Bookdown 9.2 Publishing a book with GitHub Pages 9.3 Maintaining the website 9.4 References", " Chapter 9 Automatically Generated Websites with GitHub Pages We have seen how to knit RMarkdown documents into HTML, which is the standard format for web pages. From this to publishing your HTML documents as an actual website is a short step, thanks to GitHub Pages. GitHub Pages lets you turn your GitHub repositories into websites for free. Because it is GitHub, you can manage all the content of your website from RStudio and have it under version control, which means your website is reproducible. Sign us up, amirite?! Here, we are going to see how to create a web book using the R package bookdown and GitHub Pages. 9.1 Bookdown The R package bookdown is built on top of RMarkdown, so it uses the same syntax we have learned so far for writing documents. On top of it, bookdown lets you have multi-page output, cross-referencing between different pages, and it uses the GitBook style to create beautiful, professional-looking digital books. In fact, the book you are reading right now is built with bookdown! 9.1.1 Creating a book Once you have bookdown installed, you can create your first book by opening RStudio and creating a new Project. Select “New Directory”, and then “Book Project using bookdown”. Create a Project in a new directory. Choose “Book Project using bookdown” When you create the Project, bookdown automatically generates all the files you need for your book to function. These include: A .Rproj file, which is your RStudio Project; A README file; An index.Rmd file, which is the first section of your book and by default will be the home page if you publish it as a website; A series of numbered chapters as .Rmd files; Two .yml files, _bookdown.yml and _output.yml, which contain metadata (stuff like the file name of the book, the word used to refer to chapters within the book, etc;) A style.css file, which defines the style and appearance of the book; A preamble.tex file, with more customization options; A book.bib file, which contains the bibliography. Files automatically created by bookdown. In practice, you can ignore most of these files unless you want to customize the appearance and functioning of your book. If all you want to do is edit the content, all you need to care about are the .Rmd files. The other files are necessary for the book to work properly, but you can simply leave them where they are and not worry about them. To knit the book, go to the “Build” tab in RStudio, open the “Build Book” dropdown menu, and choose “bookdown::gitbook” as the output format. This format is compatible with GitHub Pages and will allow us to publish our book as a website. When we do this, bookdown will knit each .Rmd file into HTML format and save them into a new folder called \"_book\". Build bookdown. 9.2 Publishing a book with GitHub Pages To publish the book online using GitHub Pages, we are going to initialize a Git repository in our Project folder, link it up with a GitHub repository, and enable Pages. To enable Pages, we need to tell GitHub where to go find the .html files that compose our book. We have two options: we can put these files into a dedicated branch called “gh-pages”, or we can have them in a folder called “docs” on the main branch. The second option allows for a slightly simpler workflow, so we’ll go with that. 9.2.1 Step 1: Set up compatibility with GitHub Pages By default, bookdown puts the .html files it generates when knitting the book into the \"_book\" folder. Instead, we want these to be in a “docs” folder. We can go ahead and delete the _book folder with all its content (everything in this folder is generated when knitting the files so we can delete it without fear.) Then, we tell bookdown that it should save all the .html files into a folder called “docs” instead of the default \"_book\". We do this by opening the _bookdown.yml file and adding this line to the bottom of it: output_dir: “docs”. We also need to create a file called .nojekyll in the “docs” folder. You can do this by typing touch .nojekyll in your command line (make sure you’re in the Project folder), or you can simply use the notepad to create a new empty file, name it “.nojekyll”, and save it in “docs”. Make sure there’s no file extension (e.g., .txt) at the end of the filename. Notepad will complain and warn you that terrible things will happen if you remove the file extension, but actually they won’t. The reason why we need to create this “.nojekyll” file is because GitHub Pages will assume that your website is built using Jekyll, a static website builder, unless you tell it otherwise. Our website does not use Jekyll, so we tell GitHub that. 9.2.2 Step 2: Set up Git repository It’s time to put our book under version control. To do so, we open a terminal into our Project folder and we initialize a repository: git init After we create our .gitignore file, we can add and commit our files: git add --all git commit -m &quot;First commit&quot; Let’s also rename our main branch: git branch -M main 9.2.3 Step 3: Link Git repository to remote GitHub repository Now, we create an empty GitHub repository to link with our local one. Because we are setting this as the upstream for an existing repository, it must be completely empty, so make sure you are not creating a README file or anything (uncheck all those boxes). Also, make sure you choose the option for a Public repository. GitHub Pages are not available for private repositories. Back in the terminal, we link this newly created remote repository to our local copy (make sure you replace the URL below with the correct one): git remote add origin https://github.com/username/my-repo And we push our files to it: git push -u origin main 9.2.4 Step 4: Enable GitHub Pages The final step is to enable GitHub Pages on our repository. On GitHub, go to the repository Settings. Scroll down to the “GitHub Pages” section. Change the source to the docs folder in the main branch and save: Set up GitHub Pages to work from main, /docs. The site will be published within a few minutes at the address in the green box that just appeared on your screen. 9.3 Maintaining the website Once the website is live, it will be automatically updated any time we push updates to the .html files in the docs folder. Remember that modifying the .Rmd files is not enough for the website to update: we also need to knit the book so that bookdown will update the .html files. This is also a great reminder that you can play around with edits without them showing up on the website if you’re not ready to broadcast them: until you knit the book and push to the remote, the website won’t be updated. 9.4 References https://bookdown.org/yihui/bookdown/ "],
["intro-to-r.html", "Chapter 10 Introduction to R 10.1 Getting started 10.2 Basics of R programming 10.3 References", " Chapter 10 Introduction to R 10.1 Getting started Some of you may already be familiar with R, so we are going to go over some basics and then breeze through the fundamentals of R programming to get to the more advanced stuff. Figure 10.1: Artwork by Allison Horst Let’s start with some definitions: R is both a programming language and a software. However, the R software is just an R command line and it has no additional interface. RStudio is an Integrated Development Environment (IDE) that facilitates working with R by providing an interface that makes it easy to save code script, keeping track of your working environment, looking up your directory structure, and visualize your plots while you’re coding. We’ll be using RStudio throughout the remainder of this course. Remember what we said in Chapter 1 about RStudio Projects – make sure you are always working within a Project and you’re aware of your working directory! You can check what Project you are working on on the top-right corner of your RStudio window. When you open up a Project, the working directory will show up in the Files tab in the bottom-right panel. This is also the panel where your plots appear and where you can look up help files for R functions. The top-left panel is where you will type your code to then save it in a script. The bottom-left panel is the console and it is where you will see results and run any line of code that you do not need to save. The top-right panel has several tabs but by default it shows your R environment, that is, all the objects and functions that exist in your session at any given time. When you want to run code from your script, you can send it to the console to execute by pressing Ctrl (or Cmd) + Enter. If nothing in the script is highlighted, the command that gets run is the one where your cursor is. If something is highlighted, that will be the only piece of code that gets run (this will turn out to be very useful). The &gt; prompt means R is ready to execute a command. If a + sign shows up instead, it means the code you tried to run is incomplete (in many cases, this means you’re missing a closing parenthesis). You can press Esc to abort the command when this happens and you’re not sure what’s missing. 10.2 Basics of R programming 10.2.1 Assigning objects The &lt;- operator is called an assignment operator. Whatever is on the right of the arrow is going to be assigned to the name on the left, and the object will show up in your Environment tab on the top-right. A shortcut for the assignment operator is Alt + -. x &lt;- 2 You can name an object anything you want, but the name cannot start with a number. Also, R is case-sensitive, so make sure you are consistent with uppercase/lowercase. Back in the day someone would have told you to choose names that are short so you save yourself some typing, but RStudio has an autocomplete option that makes this not a problem at all, so I say: above all, choose names that are descriptive because that will make your code much more readable and easy to understand! 10.2.2 Adding comments One of the recommendations you are going to hear most often is, “always comment your code”. Indeed, it is very important to make sure your scripts contain enough information that a reader unfamiliar with your code (a colleague, or yourself in a few weeks) can understand what’s going on and what each piece is doing. You can add comments using a hashtag. Anything on a line after the # will not be treated as code. x &lt;- 2 # This is a comment 10.2.3 Headers and description Even when I’m not writing an RMarkdown file and I’m just working with a .R file, I like to start my scripts with a header that says who the author is, what the script is about, when it was created, and when it was last modified. Something like this: # # # # # # # # # # # # Simona Picardi # Getting started with R # Created January 8th, 2020 # Last modified January 25th, 2020 # # # # # # # # # # # After the header, I like to add a general description providing some context of what the script does and where it fits in with related ones. For example, you may want to describe what project the script is part of, what is it for, what are the inputs and outputs, etc. 10.2.4 Navigating through the script Often you’ll find yourself writing scripts that are many many lines long. If you are looking for a specific piece within a large script, you could spend a long time crossing your eyes trying to find it. Because nobody likes their eyes to bleed, it’s much more convenient to add bookmarks to your script so that you can easily jump to the section you’re looking for. You can add a bookmark using four hastags like so: # Data processing #### # some code # Data analysis #### # some code The Data processing and Data analysis bookmarks will appear under your script panel and you can click to navigate between them. Figure 10.2: Bookmarks in RStudio help you efficiently navigate your script 10.2.5 Functions and their arguments A function is an executable scripts that takes a well-defined input and returns a certain desired output. The inputs of a function are called arguments. For example, the function round takes as input an argument called x which is the number you want to round: round(x = 10.46) ## [1] 10 The function takes also a digits argument, although it is optional: if we don’t specify it will just use the default value. You can check what the default is by looking at the help file for the function: ?round The default is 0 decimal digits, so unless we specify something different the function will round to the closest integer. Arguments that are optional are also called options. It’s important to be aware of what default values are assigned to optional arguments when we don’t manually specify them. Another thing to be aware of is that function interpret their inputs positionally unless the arguments are explicitly spelled out. So for example, running round(10.465, 1) is the same as running round(x = 10.465, digits = 1). If we shuffle the order of the inputs and do round(1, 10.465) the function won’t understand that x is 10.465 and not 1. But if we spell out which input is which, the order no longer matters: round(digits = 1, x = 10.465) works just fine. 10.2.6 Writing functions Now that we learned about the anatomy of a function, we can write our own. A function is like a recipe where the arguments are the ingredients and the function code is the procedure. At the end, you get your baked goods. The syntax to write a function is function(arguments){code}. First, we define what inputs the function should take (i.e., we pick names for the arguments). Then, inside the curly braces, we describe what the function does with those inputs. For example, let’s write a function to add two numbers together: # We&#39;ll call this function &#39;add&#39;. add &lt;- function(x, y) { # It takes as input two arguments named `x` and `y` return(x + y) # and it returns x + y } add(4, 5) ## [1] 9 We can then assign this value to an object: (z &lt;- add(4, 5)) # by wrapping the assignment statement in parentheses I also automatically print it to the console ## [1] 9 We can also write functions that, instead of returning a value that can be assigned to an object, print something in the console without returning anything: print_words &lt;- function(x, y) { print(paste(x, y)) } x &lt;- &quot;Hello&quot; y &lt;- &quot;world!&quot; print_words(x, y) ## [1] &quot;Hello world!&quot; x &lt;- &quot;Hello&quot; y &lt;- &quot;Simona!&quot; print_words(x, y) ## [1] &quot;Hello Simona!&quot; 10.2.7 Data types Data in R can be of several types. The four most common ones are character, numeric, integer, and logical. There’s also complex and raw, but we won’t talk about those here. Character data consists of strings of text and it is defined using quotes: x &lt;- &quot;some text&quot; class(x) ## [1] &quot;character&quot; Numbers and integers are pretty self-explanatory. Logical data is boolean TRUE/ FALSE: x &lt;- TRUE class(x) ## [1] &quot;logical&quot; 10.2.8 Vectors A vector (or atomic vector) is the most basic data structure in R. It is a collection of items of the same data type. You can concatenate different elements into a vector using c: x &lt;- c(1, 4, 27, 5, 32) # this is a numeric vector class(x) ## [1] &quot;numeric&quot; y &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;) # this is a character vector class(y) ## [1] &quot;character&quot; As a matter of fact, a vector that only has one element is still a vector! So x &lt;- 43 is a vector with 1 element (that is, a vector of length = 1). You can’t have elements of different data types within the same vector. If we try to mix data types inside a vector, R will fall back to the data type that is most inclusive and interpret all the elements in the vector as belonging to that data type. For example, if we do: x &lt;- c(1, &quot;B&quot;, 3, 4) class(x) ## [1] &quot;character&quot; R interpreted the whole vector as character because there’s no way to turn “B” into a number, but you can read numbers as text strings. If instead we do: x &lt;- c(FALSE, 1) class(x) ## [1] &quot;numeric&quot; R interprets the whole vector as numeric because TRUE and FALSE are encoded as 1 and 0, respectively. So R converted the logical element into a number and now the entire vector is numeric. If we mix logical and character, character will win because there is no way to turn a text string into TRUE or FALSE, but TRUE and FALSE are literally words so it’s easy to read them as text: x &lt;- c(&quot;test&quot;, &quot;FALSE&quot;) class(x) ## [1] &quot;character&quot; Anything in quotes is always interpreted as character, no matter what: class(&quot;1&quot;) ## [1] &quot;character&quot; class(&quot;TRUE&quot;) ## [1] &quot;character&quot; So, in the hierarchy of data types, character is the most general because you can always turn something into a character; numeric follows because you can read all other data types (integer and logical) as numbers; and logical is the least general because you cannot turn any of the others into logical. The process of converting an object of one type into another type is called coercing. You may run into this term in error messages so it’s good to know what it means so you can diagnose problems. 10.2.9 Factors Categorical data is represented in R using factors. A factor is stored as a vector of labels called levels but, under the hood, each level gets assigned an integer (or index value). R uses the integer component of a factor to do its job but it displays the level to you so that it’s descriptive and meaningful. This weird nature of factors is often a source of confusion. For example, if we have the following factor, years &lt;- factor(c(2017, 2018, 2019, 2020, 2021)) and we want to convert the years back into numeric, we would maybe try: as.numeric(years) ## [1] 1 2 3 4 5 The result is not what we expected. This is because R converted the index values into numbers, not the factor levels. To specify that we want to convert the factor levels into numbers, not the underlying vector of integers, we have to be explicit about it: as.numeric(levels(years)) ## [1] 2017 2018 2019 2020 2021 10.2.10 Data frames R stores tabular data in data frames. A data frame is a data structure composed by rows and columns, where each column is a vector (and therefore contains elements of the same type). Different columns in a data frame can contain data of different type but they must all be the same length or they won’t line up. More often than not, you’ll create data frames by importing external files (such as .csv) or by connecting to a SQL database, in which case the output of a query is returned as a data frame by RSQLite (see Chapter 7). But you can also manually create a data frame: df &lt;- data.frame(numbers = c(1, 2, 3), letters = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), colors = factor(c(&quot;blue&quot;, &quot;red&quot;, &quot;green&quot;))) str(df) ## &#39;data.frame&#39;: 3 obs. of 3 variables: ## $ numbers: num 1 2 3 ## $ letters: chr &quot;A&quot; &quot;B&quot; &quot;C&quot; ## $ colors : Factor w/ 3 levels &quot;blue&quot;,&quot;green&quot;,..: 1 3 2 Using str to look at the structure of the data frame, we can confirm that it contains three columns: a numeric vector, a character vector, and a factor. You can select columns of a data frame by name using a $: df$colors ## [1] blue red green ## Levels: blue green red 10.2.11 Dimensions One thing that it’s important to be aware of is the dimensions of the objects we work with. A vector is a one-dimensional data structure. If we wanted to make an analogy with geometry, a vector is like a line. There is no scalar in R because a single element is still a vector (of length 1). A data frame is like a plane because it has two dimensions (rows and columns). This is important to understand because it determines how we subset data. For example, let’s look at the dimensions of the data frame we just created: dim(df) ## [1] 3 3 This is a 3x3 object (3 rows and 3 columns), and therefore it has 2 dimensions. A vector, on the other hand, only has a length (its one dimension): length(x) ## [1] 2 Matrices are also 2-dimensional objects like data frames, but they differ from data frames because they can only contain elements of the same data types, while columns in a data frame can be of different data types. For example: (mat &lt;- matrix(data = 1:25, nrow = 5, ncol = 5)) ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 6 11 16 21 ## [2,] 2 7 12 17 22 ## [3,] 3 8 13 18 23 ## [4,] 4 9 14 19 24 ## [5,] 5 10 15 20 25 Arrays are objects that can have more than 2 dimensions. For example, an array with 3 dimension is like a 3D matrix, where the first dimension is the number of rows, the second is the number of columns, and the third is the number of matrices that compose the array. For example: (arr &lt;- array(data = 1:24, dim = c(2, 4, 3))) ## , , 1 ## ## [,1] [,2] [,3] [,4] ## [1,] 1 3 5 7 ## [2,] 2 4 6 8 ## ## , , 2 ## ## [,1] [,2] [,3] [,4] ## [1,] 9 11 13 15 ## [2,] 10 12 14 16 ## ## , , 3 ## ## [,1] [,2] [,3] [,4] ## [1,] 17 19 21 23 ## [2,] 18 20 22 24 This array has 3 dimensions: dim(arr) ## [1] 2 4 3 10.2.12 Subsetting Knowing how many dimensions an object has makes it straightforward to write syntax to subset it. For example, to subset the following vector to only include the first two elements: test &lt;- c(&quot;blue&quot;, &quot;red&quot;, &quot;green&quot;) We can specify which elements we want to subset in brackets: test[c(1, 2)] ## [1] &quot;blue&quot; &quot;red&quot; # A better way to write this: test[1:2] # using : automatically returns a vector of integers from the number on the left to the one on the right ## [1] &quot;blue&quot; &quot;red&quot; The numbers in square brackets provide the indexes of the elements we want to keep. For an object that has more than one dimension, we need to specify 2 sets of indexes, one for each dimension. In the case of a data frame, these would be rows and columns: df ## numbers letters colors ## 1 1 A blue ## 2 2 B red ## 3 3 C green df[1, 2] # subset the first row of the second column ## [1] &quot;A&quot; df[1, ] # subset the entire first row ## numbers letters colors ## 1 1 A blue df[, 2] # subset the entire second column ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; Note that when we subset a column, the output is a vector (all elements are of the same type). But when we subset a row, the output is still a data frame (elements need not be of the same type): class(df[, 2]) ## [1] &quot;character&quot; class(df[1, ]) ## [1] &quot;data.frame&quot; If you want to exclude a row or a column instead of keeping it, you can use a - in front of the index: df[, -1] ## letters colors ## 1 A blue ## 2 B red ## 3 C green df[-2, ] ## numbers letters colors ## 1 1 A blue ## 3 3 C green We can subset a matrix with positional indexes the same way we would subset a data frame: mat[1, 2] ## [1] 6 To subset rows, columns, or matrices within a 3-dimensional array we need to use 3 indexes instead of 2, like we’ve been doing for matrices and data frames. For example, to subset the first row: arr[1, , ] ## [,1] [,2] [,3] ## [1,] 1 9 17 ## [2,] 3 11 19 ## [3,] 5 13 21 ## [4,] 7 15 23 To subset the first column: arr[, 1, ] ## [,1] [,2] [,3] ## [1,] 1 9 17 ## [2,] 2 10 18 To subset the first matrix: arr[, , 1] ## [,1] [,2] [,3] [,4] ## [1,] 1 3 5 7 ## [2,] 2 4 6 8 10.2.13 Logical conditions Logical conditions are statements that can be answered with TRUE or FALSE. For example, is 10 greater than 5? 10 &gt; 5 ## [1] TRUE Is 2 + 2 = 3? 2 + 2 == 3 ## [1] FALSE Is df a data frame? class(df) == &quot;data.frame&quot; ## [1] TRUE Logical conditions are very useful for conditional subsetting. More often than wanting to subset a specific row or column of a data frame, we may want to subset rows based on a condition. For example, if we only want rows where the color is blue: df[df$colors == &quot;blue&quot;, ] ## numbers letters colors ## 1 1 A blue Instead of putting a numeric index where we tell R which rows we want, we used a logical condition. R will evaluate that logical condition and only keep the rows for which it’s true. Let’s decompose that: df$colors == &quot;blue&quot; ## [1] TRUE FALSE FALSE When you plug in the above statement in place of the subsetting index, R will return the rows that satisfy the condition (the ones that return TRUE): df[df$colors == &quot;blue&quot;, ] ## numbers letters colors ## 1 1 A blue Note that a double equal == will evaluate a logical condition, while a single equal sign = is equivalent to an assignment operator &lt;-. These are not the same thing! To exclude a column or a row when using conditional subsetting, we can’t use - like we did when we were using indexes. Instead, logical conditions are denied with !: df[!df$colors == &quot;blue&quot;, ] ## numbers letters colors ## 2 2 B red ## 3 3 C green In the example above, we write the logical condition “color is equal to blue” and then we deny it by putting ! in front of it. We can also directly write the logical condition “color is NOT equal to blue”: df[df$colors != &quot;blue&quot;, ] ## numbers letters colors ## 2 2 B red ## 3 3 C green So far, we have seen four logical operators: &gt;, &lt;, ==, !=. Another one you’ll be finding yourself using a lot is %in%, which tests whether a value is within a list of values: df[df$colors %in% c(&quot;red&quot;, &quot;blue&quot;), ] ## numbers letters colors ## 1 1 A blue ## 2 2 B red 10.2.14 Lists Lists are the most flexible data structure in R. They can contain elements of different data type and size. For example: # This list contains numeric vectors of different length (list1 &lt;- list(1, 1:2, 1:10)) ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 1 2 ## ## [[3]] ## [1] 1 2 3 4 5 6 7 8 9 10 # This list contains vectors of different data types (list2 &lt;- list(1:5, c(&quot;cat&quot;, &quot;dog&quot;, &quot;lion&quot;, &quot;giraffe&quot;))) ## [[1]] ## [1] 1 2 3 4 5 ## ## [[2]] ## [1] &quot;cat&quot; &quot;dog&quot; &quot;lion&quot; &quot;giraffe&quot; # This list contains a numeric vector, a character vector, a matrix, and a function (list3 &lt;- list(1:10, c(&quot;A&quot;, &quot;B&quot;), matrix(0, 4, 4), function(x) {x + 1})) ## [[1]] ## [1] 1 2 3 4 5 6 7 8 9 10 ## ## [[2]] ## [1] &quot;A&quot; &quot;B&quot; ## ## [[3]] ## [,1] [,2] [,3] [,4] ## [1,] 0 0 0 0 ## [2,] 0 0 0 0 ## [3,] 0 0 0 0 ## [4,] 0 0 0 0 ## ## [[4]] ## function(x) {x + 1} We can name the elements of a list: names(list3) &lt;- c(&quot;numbers&quot;, &quot;letters&quot;, &quot;matrix&quot;, &quot;function&quot;) list3 ## $numbers ## [1] 1 2 3 4 5 6 7 8 9 10 ## ## $letters ## [1] &quot;A&quot; &quot;B&quot; ## ## $matrix ## [,1] [,2] [,3] [,4] ## [1,] 0 0 0 0 ## [2,] 0 0 0 0 ## [3,] 0 0 0 0 ## [4,] 0 0 0 0 ## ## $`function` ## function(x) {x + 1} We can subset lists by using double brackets. For example, to extract the second element of list3 we would do: list3[[2]] ## [1] &quot;A&quot; &quot;B&quot; This returns the character vector with the letters A and B. Using a single bracket instead of a double bracket will return a list with the element/s we called for: list3[2] ## $letters ## [1] &quot;A&quot; &quot;B&quot; Imagine the single bracket as returning the bin where the object is and the double bracket as returning the actual content of the bin. 10.2.15 Control structures Control structures allow you to “activate” or “de-activate” your code based on circumstances you can define as you need. Think of them as switches that modulate the operations you do on your data. The most commonly used control structure in R is the combination of if and else. By using if, you can specify a logical condition and the code that you want to run if that condition is verified. The syntax is as follows: if (condition) {# do something} If condition returns TRUE, the code in the curly braces will be executed, otherwise it won’t. If you want to specify what to do in case the condition is FALSE, you can pair the if with an else: if (condition) {# do something } else { # do something else } Other control structures include break, which stops a loop when a condition is met, and next, which skips one iteration of a loop. Loops themselves are control structures, but we’ll talk about them in the next section. 10.2.16 Repeating operations Many times in R you will find yourself having to repeat the same operation over a set of values/rows. There are multiple ways to do so: vectorized operations, loops, and apply functions. 10.2.16.1 Vectorization Unlike many other programming languages, R supports vectorization, which means some operations can be carried out in parallel across R objects. Without knowing, we’ve already made some examples of vectorized calculations in R. For instance, applying a logical comparison to all elements of a vector: vec &lt;- 1:10 vec &gt; 4 ## [1] FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE The sum of two vectors can also be vectorized: x &lt;- 1:5 y &lt;- 6:10 x + y ## [1] 7 9 11 13 15 In languages that don’t use vectorization, you would have to write a loop to sum each element of x to the corresponding element of y. Vectorization makes many operations very fast and it also makes your code more readable because all you have to type is x + y instead of for (i in 1:length(x)) {for (j in 1:length(y)) {sum(x[i], y[j])}}… A pitfall that it’s important to be aware of when doing vectorized calculations is vector recycling. In the example above, the two vectors x and y have the same length: they are each composed of five elements. If we try to do a vectorized calculation on two vectors that aren’t the same length, R will recycle values from the shortest vector when it runs out, leading to unexpected results: x &lt;- 1:6 y &lt;- 7:10 x + y ## Warning in x + y: longer object length is not a multiple of shorter object ## length ## [1] 8 10 12 14 12 14 The vector y has only 4 elements. So for the first 4 values we got what we expected: 1 + 7, 2 + 8, 3 + 9, 4 + 10. From the fifth value onwards, R kept going with the values of x but started over with y and returned 5 + 7, 6 + 8. The output was accompanied by a warning message. Whenever you see this warning message, it means there’s an instance of vector recycling going on in your code. 10.2.16.2 Loops The first thing to know about loops is when you should or shouldn’t use a loop. Loops can be inefficient when compared to vectorized alternatives, so whenever you can do what you need by using a vectorized operation, do that instead of a loop. The second thing to know about loops is that there are multiple types of them (for, while, repeat). These mostly differ in the way you tell the loop how many times it should repeat the operation. Most of the time you’ll find yourself using for loops, so we’ll go over those in detail. A for loop is written by specifying how many times we want to repeat an operation and what is the operation we want to repeat: for (i in n_times) { # do something } This can be as simple as printing the numbers from 1 to 10: for (i in 1:10) { print(i) } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 ## [1] 6 ## [1] 7 ## [1] 8 ## [1] 9 ## [1] 10 Or it can be more complicated, such as multiple consecutive operations: for (i in 1:10) { x &lt;- i * 2 y &lt;- x^2 print(x + y) } ## [1] 6 ## [1] 20 ## [1] 42 ## [1] 72 ## [1] 110 ## [1] 156 ## [1] 210 ## [1] 272 ## [1] 342 ## [1] 420 The two examples above print the results to the console. If you want to store the results, you start by defining an object that will store the values as you compute them: res &lt;- c() for (i in 1:10) { x &lt;- i * 2 y &lt;- x^2 res[i] &lt;- x + y } 10.2.16.3 The apply family Functions from the apply family include apply, sapply, tapply, mapply, vapply, lapply. All of these functions work similarly to a loop by applying the same operation to a certain piece of input data. However, they differ from one another in the data structure they take in input and those they return in output. The most basic member of the family is the apply function. This takes as input a matrix or array and it can return a vector, an array, or a list according to what we’re asking it to do. The function takes three arguments: X is the matrix or array that we’re doing calculations on; MARGIN specifies whether we want to apply the operation across rows (if set to 1) or columns (if set to 2); FUN is the function we want to apply. For example, remember our matrix? mat ## [,1] [,2] [,3] [,4] [,5] ## [1,] 1 6 11 16 21 ## [2,] 2 7 12 17 22 ## [3,] 3 8 13 18 23 ## [4,] 4 9 14 19 24 ## [5,] 5 10 15 20 25 We can use apply to get a row-wise sum: apply(mat, 1, sum) ## [1] 55 60 65 70 75 All other members of the apply family are a variation on this basic theme. One other member of the apply family that you will find extremely useful is lapply. This function applies an operation to each element of a list. Given the flexibility lists give in terms of what they can contain, using lapply opens up a world of possibilities in terms of what kind of operations we can automate. Here is a basic example that illustrates how to use lapply: (l &lt;- list(1:10, 2:20, 3:30)) ## [[1]] ## [1] 1 2 3 4 5 6 7 8 9 10 ## ## [[2]] ## [1] 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 ## ## [[3]] ## [1] 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 ## [26] 28 29 30 Notice that this list contains 3 elements of different length. This means they could not be rows or columns in the same matrix or data frame, and we couldn’t just use apply to repeat an operation on each of them. But because we’re using a list and lapply, we can. If we want to get the sum of values within each element of the list: lapply(l, sum) ## [[1]] ## [1] 55 ## ## [[2]] ## [1] 209 ## ## [[3]] ## [1] 462 Or if we want to apply a custom function: lapply(l, function(x) {mean(x + 2 * 456)}) ## [[1]] ## [1] 917.5 ## ## [[2]] ## [1] 923 ## ## [[3]] ## [1] 928.5 10.3 References https://bookdown.org/rdpeng/rprogdatascience/ https://swcarpentry.github.io/r-novice-inflammation/ https://datacarpentry.org/R-ecology-lesson/index.html "],
["troubleshooting.html", "Chapter 11 Troubleshooting in R 11.1 How to interpret error messages 11.2 How to look for help 11.3 How to troubleshoot a loop 11.4 How to troubleshoot a function 11.5 Reproducible examples 11.6 The rubber duck", " Chapter 11 Troubleshooting in R Troubleshooting is a fundamental programming skill. There is no way to become fluent in a programming language without learning how to troubleshoot errors, which are every programmer’s daily bread, no matter the skill level. In this Chapter, we’ll go over the basics of troubleshooting: how to read and interpret error messages, how to take advantage of resources that can help, and how to troubleshoot loops and functions. One thing that I have found useful in my growth as a programmer was to get myself out of the mindset that the computer must be wrong (which, to be fair, sometimes seems like the only possible explanation) and accept the fact that, if I am getting an error or if the results aren’t what they are supposed to be, it is almost certainly because of user error. While this can seem like a heavy load to bear, it actually is liberating because it means that you can fix it. It’s not out of your control and if you carefully analyze what you wrote you will succeed in finding the problem and correcting it. 11.1 How to interpret error messages Error messages can be terrifying – nobody likes to see a tide of red invading their R console – but they can be an important ally in diagnosing problems in your code. Some error messages (the good ones) are clear and point you to the problem quite explicitly. Others are cryptic, but they are so typical of certain situations that they end up working as pretty good hints of what is wrong. The worst kind of error is the undescriptive, rare one that gives you no real clue where the problem is. Also, all that is red is not an error. Making sure you check whether what you got in output is a warning or an actual error message is important, not because warning messages can necessarily be ignored, but because a warning means the code went through, it just may not have done what you thought it would do. Unlike with an error message, where the code stopped and didn’t produce an output, when you get a warning you can actually double check the output and make sure everything makes sense. 11.1.1 Locating the problematic piece of code RStudio helps you identify which line generated the error by placing little red marks on the left of your script next to the line numbers. However, these can also be misleading because they can appear far downstream of where the original problem is. Also, these marks only warn you of syntax errors: missing commas, missing parentheses or quotes, etc. They cannot warn you about improper use of a function or wrong data dimensions. The best way to isolate a problematic piece of code is to step through the script line by line until the error occurs. Then, there can either be a problem in that line itself or there can be a mistake in the lines that lead up to that and produced the objects that went as input into that line. So, the first thing to do before you try to dig deeper in the error message is checking that what went in input into that line actually looks like it’s supposed to. 11.1.2 Isolating the error In general, isolating the problem is the first step in troubleshooting. We’ve talked about running the code line by line to identify which line is problematic, but even within the same line it’s useful to run each piece of code that can be run independently to check that it’s giving the expected output. For example, if I am running the following code: df &lt;- data.frame(numbers = 1:5, letters = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;), animals = c(&quot;cat&quot;, &quot;dog&quot;, &quot;lion&quot;, &quot;cheetah&quot;, &quot;giraffe&quot;)) I can run each piece to look at it and double check it: 1:5 ## [1] 1 2 3 4 5 c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;) ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; c(&quot;cat&quot;, &quot;dog&quot;, &quot;lion&quot;, &quot;cheetah&quot;, &quot;giraffe&quot;) ## [1] &quot;cat&quot; &quot;dog&quot; &quot;lion&quot; &quot;cheetah&quot; &quot;giraffe&quot; 11.1.3 Deciphering error messages If the input looks good, it’s time to start deciphering the error message. Here are some examples of common errors and what they usually mean (not literally, but what type of mistake do they usually result from): test &lt;- 1:10 sum(tets) ## Error in eval(expr, envir, enclos): object &#39;tets&#39; not found An object can be “not found” when you misspelled its name or when you didn’t run your code in the correct order and you haven’t created it yet. This is also an error message that you’ll often see when you try to run a whole script and some problem occurs in the middle: as R tries to keep going after the first error, chances are it will have to look for some objects that do not exist because the previous code failed. So, make sure you start troubleshooting from the first error that occurred upstream. Here’s another evergreen: df &lt;- data.frame(numbers = 1:5, letters = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;)) df$animals &lt;- c(&quot;cat&quot;, &quot;dog&quot;, &quot;lion&quot;, &quot;giraffe&quot;) ## Error in `$&lt;-.data.frame`(`*tmp*`, animals, value = c(&quot;cat&quot;, &quot;dog&quot;, &quot;lion&quot;, : replacement has 4 rows, data has 5 Whenever you see an error of the form replacement has... data has... you know that you’re trying to plug in the wrong number of values into an object. In this case, I tried to add a column with four elements to a data frame that has five rows. Notice that this error is a bit more specific than the previous example because it gives us an indication of what line failed. This is not particularly useful in this case where we only ran one line, but when you’re troubleshooting a function or a larger piece of code that works as one it’s useful to know at which point within it the error occurred. Bottom line: use the first component of the error message (the one after Error in) to identify where the error occurred, and use the second component (the one after the :) to understand what went wrong. 11.1.4 Syntax errors Perhaps the most classic of error messages is this: vec &lt;- c(1, 4, 6, 7, 8)) ## Error: &lt;text&gt;:1:24: unexpected &#39;)&#39; ## 1: vec &lt;- c(1, 4, 6, 7, 8)) ## ^ Make sure you take advantage of RStudio’s highlighting tool to check if you closed all the parentheses you opened. If you move your cursor to an opening (or closing) parenthesis (or bracket), RStudio will highlight the closing (or opening) one. Another classic: df[df$numbers &gt; 4] ## Error in `[.data.frame`(df, df$numbers &gt; 4): undefined columns selected This is most likely the symptom that we forgot a comma inside the brackets and therefore the indexing isn’t working correctly. 11.1.5 Errors from using package functions In some situations, you will get an error message that will point you to a line of code that you haven’t written. That is most likely because a function that you are calling ran into an internal error, and the code you’re seeing in the error message is inside that function. In that case, it’s a good idea to focus on that function and try to figure out why it’s not working like expected. This mostly happens when using functions from a package other than base. Another common problem when using functions from packages is that a function can exist in two packages, have the same name but take in a completely different set of arguments and do different things. If you call one of these functions thinking you’re calling it from package A and it’s coming from package B instead, chances are the inputs you gave it do not work. When a function with the same name exists in more than one package among those you have loaded, R assumes you are trying to use the function from the package you loaded most recently. This is why the order in which you load packages matter. Another (the best) solution is to use the syntax package::function to specify which package you’re calling the function from. This removes any ambiguity. 11.2 How to look for help 11.2.1 R documentation The first thing to check when a function is not working like expected is to look up the documentation and double check that you provided all the necessary input in the right format. You can look up the help file of a function like so: ?mean 11.2.2 Google Googling error messages is an art. Here are my go-to rules for how to put together an effective Google search for an error message: Don’t just copy-paste the whole error message; first, remove anything that is specific to your situation. For example, if the error message says, Error in data.frame(numbers = 1:5, letters = c(“A”, “B”, “C”, “D”, “E”), : arguments imply differing number of rows: 5, 4` the content of the data frame is specific to my situation, and so are the numbers at the end. I need to remove those and only include the following in my Google search: Error in data.frame arguments imply differing number of rows Always add “in R” at the end of your search; If you have identified what function the error comes from, add the name of the function to your search (this does not always help, but it often does); If the problematic function comes from a package, add the name of the package to your search. 11.2.3 StackOverflow et al. The world is so big and there are so many humans on this planet and so many of them program that you will struggle to find a problem somebody else hasn’t already run into and posted about on StackOverflow or similar websites. The difficult part is to take advantage of this endless resource in an effective way. Even after you have looked up an error message and found a post on StackOverflow about it, the specifics of the dataset the other person is using may not be exactly identical to yours. This is where thinking outside the box and drawing parallels between your case and somebody else’s case becomes critical. For instance, say that I run the following code and get an error: vec &lt;- 1:10 mat &lt;- matrix(NA, 5, 5) mat[1, ] &lt;- vec ## Error in mat[1, ] &lt;- vec: number of items to replace is not a multiple of replacement length If I go and Google the error, this is the first post I find on StackOverflow about it. This person is trying to do a different thing than me: they are trying to assign new values to a column in a data frame based on another column. Their problem is that, because they only want to replace the values that are NA, the slots to replace are fewer than the total length of the column. Therefore, there are too many items for too few spaces. In my case, I am not subsetting the target column, so what I’m doing is a bit different. However, what both situations have in common is that the number of spaces to be filled is not the same as the number of items to fill them with. So now I know that my problem must be that I have too many (or too few) values to fit in my column. Figure 11.1: Artwork by Allison Horst 11.3 How to troubleshoot a loop Consider the following loop: my_list &lt;- list(11, 4, TRUE, 98, FALSE, &quot;yellow&quot;, 34, FALSE, TRUE, &quot;dog&quot;) for (i in 1:length(my_list)) { item &lt;- my_list[[i]] res &lt;- item + 10 } ## Error in item + 10: non-numeric argument to binary operator Something is wrong with this loop because I am getting an error. But how do I know where the error happened? The first trick to know is that loops work through the indexes you provide as i in order (first 1, then 2, and so on, until it gets to the end, which in this case is length(my_list)). Each time it runs through an iteration, the loop will assign to i the current value; thus, i is an object in your environment. If one iteration returns an error, the loop stops. So the value of i after the loop stops will tell you which was the element that produced the error: i ## [1] 6 In this case, the sixth iteration is the one that failed. Now that we know this, the second trick to know is that we can step through the loop one line at a time while having i = 6 and see where the error occurs: i &lt;- 6 item &lt;- my_list[[i]] # this line returns no error res &lt;- item + 10 # this is the culprit! ## Error in item + 10: non-numeric argument to binary operator In this case, the problem was that item 6 of my list is a character string and I’m asking R to do math on it. I was able to do math on elements 1 through 5 because they were either numbers or logical (which can be coerced to numbers like we saw in Chapter 10.) Note that this is a useful trick to use not only to troubleshoot loops when something goes wrong, but also to verify that the loop is functioning correctly on a single item before you pull the trigger on the whole thing. You can set i &lt;- 1 and step through the loop line by line to do a test run. 11.4 How to troubleshoot a function In Chapter 10 we have seen how to write functions and also how to use lapply to run the same function on a list of objects. Functions can be as simple or as complicated as we need them to be, but the more complex they get the more likely it is it will take some trial and error to get them to work correctly. We need some troubleshooting tools! Unlike loops, functions do not save any objects to the global environment other than the final result (wrapped in the return statement). In a loop, every intermediate product (as well as the index i) are saved to the global environment at each iteration. Functions, instead, work by creating their own environment where temporary objects are saved. Then, once the final output is ready to be returned, the function saves that and only that to the global environment. Consider the following function: fun_test &lt;- function(x) { y &lt;- x * 2 z &lt;- y + 10 return(z) } (output &lt;- fun_test(1)) ## [1] 12 The intermediate object y is never saved to our global environment. The z object is the one we’re returning, and it gets saved to the environment with the name we give it (output). To troubleshoot or verify what’s going on inside of the function, we need to “move” the process into our global environment. This means that we need to define an x object in our global environment and then step through the code inside the curly braces manually: (x &lt;- 1) ## [1] 1 (y &lt;- x * 2) ## [1] 2 (z &lt;- y + 10) ## [1] 12 Now let’s make an example with lapply. Say that we want to apply our function to the list we used in the loop above: my_list &lt;- list(11, 4, TRUE, 98, FALSE, &quot;yellow&quot;, 34, FALSE, TRUE, &quot;dog&quot;) lapply(my_list, fun_test) ## Error in x * 2: non-numeric argument to binary operator Here’s the error again. This time, we don’t get the luxury of looking at the iteration index to get a hint on where things went wrong. So what we can do instead is step through the list elements one at a time: x &lt;- my_list[[1]] # first we assign the first element of the list to x # then we step through the code inside the function (y &lt;- x * 2) ## [1] 22 (z &lt;- y + 10) ## [1] 32 This went smoothly, so that must not have been the problematic item. If we keep going with the other elements, eventually we find the culprit: x &lt;- my_list[[6]] (y &lt;- x * 2) ## Error in x * 2: non-numeric argument to binary operator (z &lt;- y + 10) ## [1] 32 x ## [1] &quot;yellow&quot; And there it is: element #6 is a character string and we get an error because we are trying to do math on it. 11.5 Reproducible examples In the unlikely event that you run into an error that no human has posted on StackOverflow before, you can post a request for help. It is best to do so by sharing a reproducible example. A reproducible example is a standalone script that allows someone else to reproduce your problem on their computer. Without it, all people can do is read your code and imagine what the output of each step should look like, and it’s hard to diagnose errors that way. To write a good reproducible example, you need to provide the following: Required packages: it’s good practice to load these at the top of your script so people can quickly see if they need to install anything before running the code; Data: if you can reproduce your problem using one of the built-in datasets available in R, you can use that. Otherwise, you can use the function dput to generate code to recreate your current dataset and then copy-paste it into your script: df &lt;- data.frame(numbers = 1:5, letters = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;), animals = c(&quot;cat&quot;, &quot;dog&quot;, &quot;lion&quot;, &quot;cheetah&quot;, &quot;giraffe&quot;)) dput(df) ## structure(list(numbers = 1:5, letters = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, ## &quot;E&quot;), animals = c(&quot;cat&quot;, &quot;dog&quot;, &quot;lion&quot;, &quot;cheetah&quot;, &quot;giraffe&quot;)), class = &quot;data.frame&quot;, row.names = c(NA, ## -5L)) df &lt;- structure(list(numbers = 1:5, letters = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;), animals = c(&quot;cat&quot;, &quot;dog&quot;, &quot;lion&quot;, &quot;cheetah&quot;, &quot;giraffe&quot;)), class = &quot;data.frame&quot;, row.names = c(NA, -5L)) Code: the code that you want to get help with; R environment: you can obtain information on your current session environment using the sessionInfo function. Copy-paste the output as a comment into your reproducible example script: sessionInfo() ## R version 4.0.2 (2020-06-22) ## Platform: x86_64-w64-mingw32/x64 (64-bit) ## Running under: Windows 10 x64 (build 18363) ## ## Matrix products: default ## ## locale: ## [1] LC_COLLATE=English_United States.1252 ## [2] LC_CTYPE=English_United States.1252 ## [3] LC_MONETARY=English_United States.1252 ## [4] LC_NUMERIC=C ## [5] LC_TIME=English_United States.1252 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] DBI_1.1.0 ## ## loaded via a namespace (and not attached): ## [1] Rcpp_1.0.6 rstudioapi_0.11 knitr_1.29 magrittr_2.0.1 ## [5] bit_4.0.4 jpeg_0.1-8.1 rlang_0.4.10 stringr_1.4.0 ## [9] blob_1.2.1 highr_0.8 tools_4.0.2 xfun_0.16 ## [13] png_0.1-7 htmltools_0.5.0 yaml_2.2.1 bit64_4.0.5 ## [17] digest_0.6.27 bookdown_0.20 vctrs_0.3.6 memoise_1.1.0 ## [21] evaluate_0.14 RSQLite_2.2.1 rmarkdown_2.3 stringi_1.4.6 ## [25] compiler_4.0.2 pkgconfig_2.0.3 11.6 The rubber duck The rubber duck is a method of debugging code introduced by software engineers. It consists of explaining code, line by line, to a rubber duck. If you don’t have a rubber duck, people have reportedly been successful using their cat, dog, or other pet instead. While this debugging technique may sound laughable at first, it goes to show that verbalizing out loud what the code is supposed to do in each step (and what it does instead) may force us to recognize connections and details that were not clear in our mind to the point that the solution becomes apparent. On a similar note, never underestimate the power of reading your code aloud. "],
["renv.html", "Chapter 12 Dependency Management in R 12.1 What’s the need for dependency management? 12.2 The renv package 12.3 References", " Chapter 12 Dependency Management in R The next two Chapters will be focused on the tidyverse, so we will be introducing R packages. This is the first time we’ll be using external packages in this course, so this seems like a great time to introduce dependency management systems. 12.1 What’s the need for dependency management? An external R package is any software library that is not included with base R (it doesn’t just come automatically with the R installation.) Packages are one of the biggest advantages of using R: there are so many packages available to allow us to do so many different things without having to code the functions ourselves. However, using packages can result in some headaches, too. Using packages in our code means that the code depends on those packages to run correctly as it was meant to. If someone else wants to run our code, they will have to install the necessary packages first. But what happens if the code was written using a long time ago using an old version of a package, and by doing install.packages that person gets a newer version that does not work the same way? This can also happen when we try to run our own code a year after we have written it, after having reinstalled R, or after changing computers. Packages are constantly maintained and they can change. Functions can be re-written and behave differently than they did when we first wrote the code. Sometimes our code can break even if something changes in a package that we are not loading directly, but that the package we’re using depends on. Even though it’s good practice to keep our software up-to-date, updating packages can break things and generate a lot of frustration. These frustrations can be greatly reduced by adopting a dependency management system. Dependency management is the process of keeping track of dependencies in our code. This means keeping track of which packages we are loading, which packages those packages depend on, and which version of each package we are using. 12.2 The renv package The renv package is a dependency management system for R. Normally, when you install an R package, this gets saved in your user library, which is centralized somewhere in your computer (find out where using .libPaths()). Each time you load a package in an R session, the package will be loaded from that centralized library. The basic concept behind renv is to de-centralize this process by having Project-specific libraries. This means that you can have different RStudio Projects each with their own version of the same package. The library and all your package dependencies are a property of an RStudio Project. However, because renv uses a global package cache that is shared across all the projects that use renv, packages are not physically duplicated (which would be very inefficient in terms of space.) Having Project-specific libraries means that installing a new version of a package in one Project won’t break any others that may rely on a different version. It also means that your RStudio Project is truly a portable unit, where it’s easy to get all your dependencies working if you transport the Project on a different computer. This also helps make your code reproducible because you can share your project environment alongside the code so that somebody else can automatically reproduce it on their computer. 12.2.1 Usage When you create a new RStudio Project, you can initialize a project-local environment by using renv::init(). This will identify all the packages that are currently in use and install them into the project library. Initializing renv on a project will save four files to your project directory: An .Rprofile file, which will activate your environment each time you open a new project session; An renv.lock file, which describes the state of your project’s library (what packages are loaded and in what version) at some point in time; An renv/activate.R file which is the script run by .Rprofile; And an renv/library folder which is your local project library. The first three files should be put under version control. The library itself is automatically put in .gitignore by renv (it can’t hurt to double check). After your project-local environment is set up, you can keep working on your project normally. You can save a snapshot of the project library with renv::snapshot(). The current status of the library will be saved to renv.loc. You can always go back to a previous snapshot in time by using renv::restore(). Note: make sure you don’t save any of your renv commands in the script, only run them in the console. In general, you should never leave code to install any package in your script (or you will re-install packages that you already have any time you run your whole script at once). Only leave the library() loading command in your script. All the other renv commands should not be saved in the script either, because you or your collaborator are likely to accidentally modify your environment without realizing. Let’s go over the workflow you would follow in each of the following situations: You want to start a new RStudio Project and you want to manage your dependencies with renv; You want to start using renv on an existing project; You want to share your project with somebody else making sure they get all the dependencies they need; Somebody shared a project with you using renv and you want to reproduce their environment. 12.2.1.1 Case 1 You want to start a new RStudio Project and you want to manage your dependencies with renv. Step 1 of 5: install renv (install.packages(\"renv\"); no need to load it using library(renv)); Step 2 of 5: initialize your project environment (renv::init() in the console); Step 3 of 5: whenever you need to use a package, you will need to reinstall it (even if it is already installed in your central user library); Step 4 of 5: whenever you write code to use a new package (e.g., library(tidyverse)), run renv::snapshot() in the console to save the status of your current environment in renv.lock (save your script first or renv won’t notice you added a new package). If you have installed or updated a package that breaks your code, run renv::restore() to go back to the previous snapshot; Step 5 of 5: work as you normally would. 12.2.1.2 Case 2 You want to start using renv on an existing project. Step 1 of 1: open your existing project and run renv::init(). Then proceed as above. 12.2.1.3 Case 3 You want to share your project with somebody else making sure they get all the dependencies they need. Step 1 of 1: in addition to sharing your code and data, also share your renv.lock file with your collaborator. 12.2.1.4 Case 4 Somebody shared a project with you using renv and you want to reproduce their environment. Step 1 of 4: save your collaborator’s files (RStudio Project, code, data, renv.lock in the same folder); Step 2 of 4: open the project and run renv::init (this will initialize your environment); Step 3 of 4: run renv::restore() (this will look in the renv.lock file and install any packages you need); Step 4 of 4: run the code normally. 12.3 References https://rstudio.github.io/renv/articles/renv.html https://rpubs.com/glennwithtwons/reproducible-r-toolbox "],
["tidyverse.html", "Chapter 13 Data Wrangling with tidyverse 13.1 Welcome to the tidyverse 13.2 Tidyverse functions 13.3 Style 13.4 References", " Chapter 13 Data Wrangling with tidyverse 13.1 Welcome to the tidyverse Figure 13.1: Artwork by Allison Horst The tidyverse is a collection of R packages designed to facilitate data science. The so-called core tidyverse includes the following packages: dplyr for data manipulation; tidyr for tidying data; ggplot2 for plotting; readr for reading in data files of various formats; stringr for manipulating character strings; tibble for a re-engineered alternative to data frames; purrr for functional programming; forcats for better handling categorical variables. While these are distinct packages and can be installed and loaded separately, they share common grammar, syntax, and data structures. Most of the functions we are going to see in this and the following Chapter are from dplyr and ggplot2, but we’ll sprinkle some tidyr, stringr, and tibble here and there. On top of the core packages, there are several other non-core packages that are installed together with the tidyverse but are not automatically loaded. These package are specialized on a few niche roles that users may not always need. To install the tidyverse, go ahead and run the following line: install.packages(&quot;tidyverse&quot;) Then load the package using: library(tidyverse) ## -- Attaching packages --------------------------------------- tidyverse 1.3.0 -- ## v ggplot2 3.3.2 v purrr 0.3.4 ## v tibble 3.0.5 v dplyr 1.0.3 ## v tidyr 1.1.1 v stringr 1.4.0 ## v readr 1.3.1 v forcats 0.5.0 ## -- Conflicts ------------------------------------------ tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() 13.2 Tidyverse functions To demonstrate the use of tidyverse functions, we are going to work on the dragons dataset we used in Chapters 5, 6, and 7. Let’s load our data in using RSQLite like we learned in Chapter 7: library(DBI) dragons_db &lt;- dbConnect(RSQLite::SQLite(), &quot;../../Course Material/Data/dragons/dragons.db&quot;) And let’s load all the tables: dragons &lt;- dbGetQuery(dragons_db, &quot;SELECT * FROM dragons;&quot;) capture_sites &lt;- dbGetQuery(dragons_db, &quot;SELECT * FROM capture_sites;&quot;) captures &lt;- dbGetQuery(dragons_db, &quot;SELECT * FROM captures;&quot;) morphometrics &lt;- dbGetQuery(dragons_db, &quot;SELECT * FROM morphometrics;&quot;) diet &lt;- dbGetQuery(dragons_db, &quot;SELECT * FROM diet;&quot;) tags &lt;- dbGetQuery(dragons_db, &quot;SELECT * FROM tags;&quot;) deployments &lt;- dbGetQuery(dragons_db, &quot;SELECT * FROM deployments;&quot;) telemetry &lt;- dbGetQuery(dragons_db, &quot;SELECT * FROM gps_data;&quot;) 13.2.1 Subsetting columns Let’s start practicing on the morphometrics table. class(morphometrics) ## [1] &quot;data.frame&quot; head(morphometrics) ## measurement_id dragon_id date total_body_length_cm wingspan_cm ## 1 1 D96 2012-10-10 1069.8965 1389.5527 ## 2 2 D400 2003-07-03 333.4600 634.9109 ## 3 3 D316 2017-09-08 866.8935 1052.3702 ## 4 4 D317 2016-09-05 1146.9708 1356.8084 ## 5 5 D484 2016-12-04 1032.0520 1720.8641 ## 6 6 D149 2012-02-13 919.9908 1533.5991 ## tail_length_cm tarsus_length_cm claw_length_cm ## 1 595.2706 121.65175 15.596219 ## 2 104.2241 38.10844 4.305086 ## 3 373.7619 68.16869 12.719697 ## 4 542.5670 172.43663 14.809363 ## 5 596.4419 114.05057 11.985672 ## 6 563.9201 134.18051 11.005070 We can subset columns of interest from a table using the select function. The function takes as arguments 1. the data and 2. the name/s of one or more columns that we want to keep: body_wing &lt;- select(morphometrics, dragon_id, date, total_body_length_cm, wingspan_cm) head(body_wing) ## dragon_id date total_body_length_cm wingspan_cm ## 1 D96 2012-10-10 1069.8965 1389.5527 ## 2 D400 2003-07-03 333.4600 634.9109 ## 3 D316 2017-09-08 866.8935 1052.3702 ## 4 D317 2016-09-05 1146.9708 1356.8084 ## 5 D484 2016-12-04 1032.0520 1720.8641 ## 6 D149 2012-02-13 919.9908 1533.5991 The measurement_id column is the primary key of the morphometrics table. This was important to have in the database but we may not want to keep that column now that we are processing the data in R. We could drop that column by selecting all the other ones, but that would be a lot of typing. There is a more convenient way: we can use select to discard columns by adding a - in front of their name: no_pkey &lt;- select(morphometrics, -measurement_id) head(no_pkey) ## dragon_id date total_body_length_cm wingspan_cm tail_length_cm ## 1 D96 2012-10-10 1069.8965 1389.5527 595.2706 ## 2 D400 2003-07-03 333.4600 634.9109 104.2241 ## 3 D316 2017-09-08 866.8935 1052.3702 373.7619 ## 4 D317 2016-09-05 1146.9708 1356.8084 542.5670 ## 5 D484 2016-12-04 1032.0520 1720.8641 596.4419 ## 6 D149 2012-02-13 919.9908 1533.5991 563.9201 ## tarsus_length_cm claw_length_cm ## 1 121.65175 15.596219 ## 2 38.10844 4.305086 ## 3 68.16869 12.719697 ## 4 172.43663 14.809363 ## 5 114.05057 11.985672 ## 6 134.18051 11.005070 13.2.2 Subsetting rows with logical conditions To subset rows of a table based on certain conditions, we can use the filter function. For example, to filter only wingspans larger than 10 m: larger_than_10m &lt;- filter(morphometrics, wingspan_cm &gt; 1000) head(larger_than_10m) ## measurement_id dragon_id date total_body_length_cm wingspan_cm ## 1 1 D96 2012-10-10 1069.8965 1389.553 ## 2 3 D316 2017-09-08 866.8935 1052.370 ## 3 4 D317 2016-09-05 1146.9708 1356.808 ## 4 5 D484 2016-12-04 1032.0520 1720.864 ## 5 6 D149 2012-02-13 919.9908 1533.599 ## 6 9 D283 2007-06-21 1698.1918 1387.194 ## tail_length_cm tarsus_length_cm claw_length_cm ## 1 595.2706 121.65175 15.59622 ## 2 373.7619 68.16869 12.71970 ## 3 542.5670 172.43663 14.80936 ## 4 596.4419 114.05057 11.98567 ## 5 563.9201 134.18051 11.00507 ## 6 666.4246 147.44219 13.18923 13.2.3 Concatenating operations with pipes One of the most revolutionary innovations that the tidyverse brings to R is this operator: %&gt;%, the pipe. A pipe is a connector that allows you to concatenate subsequent actions into one single chunk of code. For instance, if we wanted to drop the measurement_id column from the morphometrics table and filter rows where wingspan_cm is larger than 10 m, this is what we would do without the pipe: no_pkey &lt;- select(morphometrics, -measurement_id) larger_than_10m &lt;- filter(no_pkey, wingspan_cm &gt; 1000) Instead, we can concatenate the two actions: larger_than_10m &lt;- morphometrics %&gt;% select(-measurement_id) %&gt;% filter(wingspan_cm &gt; 1000) head(larger_than_10m) ## dragon_id date total_body_length_cm wingspan_cm tail_length_cm ## 1 D96 2012-10-10 1069.8965 1389.553 595.2706 ## 2 D316 2017-09-08 866.8935 1052.370 373.7619 ## 3 D317 2016-09-05 1146.9708 1356.808 542.5670 ## 4 D484 2016-12-04 1032.0520 1720.864 596.4419 ## 5 D149 2012-02-13 919.9908 1533.599 563.9201 ## 6 D283 2007-06-21 1698.1918 1387.194 666.4246 ## tarsus_length_cm claw_length_cm ## 1 121.65175 15.59622 ## 2 68.16869 12.71970 ## 3 172.43663 14.80936 ## 4 114.05057 11.98567 ## 5 134.18051 11.00507 ## 6 147.44219 13.18923 The pipe takes the output of the previous line and feeds it as input into the next one. Notice that you don’t have to repeat the name of the data object, because the data is whatever the pipe is feeding into the function. There are several advantages to using pipes compared to traditional syntax. First, by using a pipe in the example above, we avoided saving intermediate objects (e.g., no_pkey) to the environment: we only saved the final result we wanted. Second, we typed less. Third, our code is more readable because the syntax of our code reflects the logical structure of what we are doing. You can read the pipe as then: take the morphometrics table, then drop the measurement ID, then filter records with wingspan larger than 10 m. The shortcut for inserting a pipe is Ctrl + Shift + M on Windows and Cmd + Shift + M on Mac. 13.2.4 Creating new columns Figure 13.2: Artwork by Allison Horst The filtering we did above was pretty inconvenient because we had to calculate the conversion between meters and centimeters in our head before applying the wingspan filter. It would be easier to convert the column to meters to begin with. We can create a new column using mutate: larger_than_10m &lt;- morphometrics %&gt;% select(-measurement_id) %&gt;% mutate(wingspan_m = wingspan_cm/100) %&gt;% filter(wingspan_m &gt; 10) head(larger_than_10m) ## dragon_id date total_body_length_cm wingspan_cm tail_length_cm ## 1 D96 2012-10-10 1069.8965 1389.553 595.2706 ## 2 D316 2017-09-08 866.8935 1052.370 373.7619 ## 3 D317 2016-09-05 1146.9708 1356.808 542.5670 ## 4 D484 2016-12-04 1032.0520 1720.864 596.4419 ## 5 D149 2012-02-13 919.9908 1533.599 563.9201 ## 6 D283 2007-06-21 1698.1918 1387.194 666.4246 ## tarsus_length_cm claw_length_cm wingspan_m ## 1 121.65175 15.59622 13.89553 ## 2 68.16869 12.71970 10.52370 ## 3 172.43663 14.80936 13.56808 ## 4 114.05057 11.98567 17.20864 ## 5 134.18051 11.00507 15.33599 ## 6 147.44219 13.18923 13.87194 13.2.5 Limiting results I have been saving each of my queries as an object and then doing head() to show the first 6 rows of the result. Instead, I can save myself some typing and space in my environment (and make everything look cleaner) by adding another pipe at the end with the slice function. The slice function selects rows based on position, so if I want to look at the first 6 I can do: morphometrics %&gt;% select(-measurement_id) %&gt;% mutate(wingspan_m = wingspan_cm/100) %&gt;% filter(wingspan_m &gt; 10) %&gt;% slice(1:6) ## dragon_id date total_body_length_cm wingspan_cm tail_length_cm ## 1 D96 2012-10-10 1069.8965 1389.553 595.2706 ## 2 D316 2017-09-08 866.8935 1052.370 373.7619 ## 3 D317 2016-09-05 1146.9708 1356.808 542.5670 ## 4 D484 2016-12-04 1032.0520 1720.864 596.4419 ## 5 D149 2012-02-13 919.9908 1533.599 563.9201 ## 6 D283 2007-06-21 1698.1918 1387.194 666.4246 ## tarsus_length_cm claw_length_cm wingspan_m ## 1 121.65175 15.59622 13.89553 ## 2 68.16869 12.71970 10.52370 ## 3 172.43663 14.80936 13.56808 ## 4 114.05057 11.98567 17.20864 ## 5 134.18051 11.00507 15.33599 ## 6 147.44219 13.18923 13.87194 More generally, slice can be used as the equivalent of selecting rows from a data frame using indexes like we did in Chapter 10. If I want row 38 of the morphometrics table, I can do: morphometrics %&gt;% slice(38) ## measurement_id dragon_id date total_body_length_cm wingspan_cm ## 1 38 D367 2006-06-12 1129.259 1315.82 ## tail_length_cm tarsus_length_cm claw_length_cm ## 1 578.4428 133.3162 24.20511 This works with multiple rows too, and they don’t need to be consecutive: morphometrics %&gt;% slice(c(38, 12, 84)) ## measurement_id dragon_id date total_body_length_cm wingspan_cm ## 1 38 D367 2006-06-12 1129.2590 1315.8203 ## 2 12 D322 2009-03-09 309.3959 595.7932 ## 3 84 D351 2015-10-04 1439.1528 1213.9245 ## tail_length_cm tarsus_length_cm claw_length_cm ## 1 578.4428 133.31621 24.205108 ## 2 137.9718 40.53882 4.273016 ## 3 610.6215 110.42981 12.502822 13.2.6 Tibbles Another way to limit the output that gets printed to the console is to use tibbles instead of data frames. A tibble is tidyverse’s data structure for tabular data, so it is the tidyverse equivalent of a data frame. Tibbles implement some functionalities that make working with them a bit more foolproof than working with data frames (e.g., they’ll return an error instead of NULL if you try to access a column that does not exist), but 99% of the time you won’t notice the difference. This is because all tidyverse functions (as well as some base R ones) work just the same with data frames and tibbles. However, tibbles do have an advantage: when printing a tibble to the console, only the first 10 records will show up, which is convenient because it means you don’t need to use head() to prevent your console from being flooded with output. Case in point: morphometrics %&gt;% as_tibble() %&gt;% select(-measurement_id) %&gt;% mutate(wingspan_m = wingspan_cm/100) %&gt;% filter(wingspan_m &gt; 10) ## # A tibble: 192 x 8 ## dragon_id date total_body_leng~ wingspan_cm tail_length_cm tarsus_length_cm ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 D96 2012~ 1070. 1390. 595. 122. ## 2 D316 2017~ 867. 1052. 374. 68.2 ## 3 D317 2016~ 1147. 1357. 543. 172. ## 4 D484 2016~ 1032. 1721. 596. 114. ## 5 D149 2012~ 920. 1534. 564. 134. ## 6 D283 2007~ 1698. 1387. 666. 147. ## 7 D485 2002~ 957. 1780. 561. 131. ## 8 D343 2016~ 1521. 1538. 618. 152. ## 9 D237 2009~ 1205. 2120. 656. 135. ## 10 D312 2001~ 927. 1268. 453. 109. ## # ... with 182 more rows, and 2 more variables: claw_length_cm &lt;dbl&gt;, ## # wingspan_m &lt;dbl&gt; As you can see, the appearance of a tibble is very similar to the one of a data frame. In fact, objects can be of multiple classes in R, and tibbles are also data frames under the hood! class(as_tibble(morphometrics)) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; Converting between tibble and data frame is also super easy, so you can switch back and forth between them whenever you need: morph_tib &lt;- as_tibble(morphometrics) morph_df &lt;- as.data.frame(morph_tib) This last bit is useful to know especially when you are using other packages that were not written using tidyverse and strictly require data frames as input. 13.2.7 Joining tables In Chapter 6, we talked about SQL joins. The concept of a join is not exclusive to SQL, and in fact the tidyverse has functions that serve the same exact purpose of SQL joins. Let’s get familiar with the one you’ll use most often, left_join. As a reminder, a left join keeps all the rows of the left table (the one you mention first) while attaching information from the right table (the second one) whenever available. If no information is available, the columns coming from the right table will have NA but the row will be retained. To join two tables, these need to share at least one column. Let’s join the morphometrics table with the dragons table: morphometrics %&gt;% as_tibble() %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) ## # A tibble: 327 x 11 ## measurement_id dragon_id date total_body_leng~ wingspan_cm tail_length_cm ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 D96 2012~ 1070. 1390. 595. ## 2 2 D400 2003~ 333. 635. 104. ## 3 3 D316 2017~ 867. 1052. 374. ## 4 4 D317 2016~ 1147. 1357. 543. ## 5 5 D484 2016~ 1032. 1721. 596. ## 6 6 D149 2012~ 920. 1534. 564. ## 7 7 D285 2016~ 305. 699. 116. ## 8 8 D256 2013~ 359. 652. 148. ## 9 9 D283 2007~ 1698. 1387. 666. ## 10 10 D213 2001~ 354. 671. 140. ## # ... with 317 more rows, and 5 more variables: tarsus_length_cm &lt;dbl&gt;, ## # claw_length_cm &lt;dbl&gt;, sex &lt;chr&gt;, age_class &lt;chr&gt;, species &lt;chr&gt; In this case the shared column has the same name in the two tables. If it doesn’t, you can still join based on that column. Let’s demonstrate how: morphometrics %&gt;% as_tibble() %&gt;% rename(dragon = dragon_id) %&gt;% # now the dragon_id column is called &quot;dragon&quot; left_join(dragons, by = c(&quot;dragon&quot; = &quot;dragon_id&quot;)) ## # A tibble: 327 x 11 ## measurement_id dragon date total_body_leng~ wingspan_cm tail_length_cm ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 D96 2012~ 1070. 1390. 595. ## 2 2 D400 2003~ 333. 635. 104. ## 3 3 D316 2017~ 867. 1052. 374. ## 4 4 D317 2016~ 1147. 1357. 543. ## 5 5 D484 2016~ 1032. 1721. 596. ## 6 6 D149 2012~ 920. 1534. 564. ## 7 7 D285 2016~ 305. 699. 116. ## 8 8 D256 2013~ 359. 652. 148. ## 9 9 D283 2007~ 1698. 1387. 666. ## 10 10 D213 2001~ 354. 671. 140. ## # ... with 317 more rows, and 5 more variables: tarsus_length_cm &lt;dbl&gt;, ## # claw_length_cm &lt;dbl&gt;, sex &lt;chr&gt;, age_class &lt;chr&gt;, species &lt;chr&gt; So the syntax in the by argument when the names are different is column_name_in_left_table = column_name_in_right_table. 13.2.8 Changing the order of columns Incidentally, I have just shown how to change the name of a column by using rename. We can also change the order in which columns appear in our table using relocate. For example, say that we want to move the age class column to right after the dragon ID: morphometrics %&gt;% as_tibble() %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% relocate(age_class, .after = dragon_id) ## # A tibble: 327 x 11 ## measurement_id dragon_id age_class date total_body_leng~ wingspan_cm ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 D96 Adult 2012~ 1070. 1390. ## 2 2 D400 Juvenile 2003~ 333. 635. ## 3 3 D316 Subadult 2017~ 867. 1052. ## 4 4 D317 Adult 2016~ 1147. 1357. ## 5 5 D484 Adult 2016~ 1032. 1721. ## 6 6 D149 Adult 2012~ 920. 1534. ## 7 7 D285 Juvenile 2016~ 305. 699. ## 8 8 D256 Juvenile 2013~ 359. 652. ## 9 9 D283 Adult 2007~ 1698. 1387. ## 10 10 D213 Juvenile 2001~ 354. 671. ## # ... with 317 more rows, and 5 more variables: tail_length_cm &lt;dbl&gt;, ## # tarsus_length_cm &lt;dbl&gt;, claw_length_cm &lt;dbl&gt;, sex &lt;chr&gt;, species &lt;chr&gt; 13.2.9 Calculations by group Now that we know how to join the morphometrics table to the dragons table we can calculate some summary statistics based on different groups. To do so, we use the function group_by together with the function summarize. For instance, let’s calculate minimum, maximum, and mean tail length for dragons of different age classes: morphometrics %&gt;% as_tibble() %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% group_by(age_class) %&gt;% summarize(min_tail_length_cm = min(tail_length_cm), mean_tail_length_cm = mean(tail_length_cm), max_tail_length_cm = max(tail_length_cm)) ## # A tibble: 3 x 4 ## age_class min_tail_length_cm mean_tail_length_cm max_tail_length_cm ## * &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adult 502. 600. 686. ## 2 Juvenile 84.0 119. 148. ## 3 Subadult 338. 435. 544. We can also use group_by to count how many records we have for each group. Let’s say we want to know how many dragons of each species we captured: morphometrics %&gt;% as_tibble() %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% group_by(species) %&gt;% tally() ## # A tibble: 10 x 2 ## species n ## * &lt;chr&gt; &lt;int&gt; ## 1 Antipodean Opaleye 16 ## 2 Chinese Fireball 16 ## 3 Common Welsh Green 51 ## 4 Hebridean Black 42 ## 5 Hungarian Horntail 29 ## 6 Norwegian Ridgeback 59 ## 7 Peruvian Vipertooth 39 ## 8 Romanian Longhorn 44 ## 9 Swedish Short-Snout 14 ## 10 Ukrainian Ironbelly 17 13.2.10 Sorting results Let’s sort results of our count by species in decreasing order: morphometrics %&gt;% as_tibble() %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% group_by(species) %&gt;% tally() %&gt;% arrange(n) ## # A tibble: 10 x 2 ## species n ## &lt;chr&gt; &lt;int&gt; ## 1 Swedish Short-Snout 14 ## 2 Antipodean Opaleye 16 ## 3 Chinese Fireball 16 ## 4 Ukrainian Ironbelly 17 ## 5 Hungarian Horntail 29 ## 6 Peruvian Vipertooth 39 ## 7 Hebridean Black 42 ## 8 Romanian Longhorn 44 ## 9 Common Welsh Green 51 ## 10 Norwegian Ridgeback 59 Nope, that didn’t do it. The species are sorted from the least to the most numerous (the default). We need to specify that we want to sort results in descending order: morphometrics %&gt;% as_tibble() %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% group_by(species) %&gt;% tally() %&gt;% arrange(desc(n)) ## # A tibble: 10 x 2 ## species n ## &lt;chr&gt; &lt;int&gt; ## 1 Norwegian Ridgeback 59 ## 2 Common Welsh Green 51 ## 3 Romanian Longhorn 44 ## 4 Hebridean Black 42 ## 5 Peruvian Vipertooth 39 ## 6 Hungarian Horntail 29 ## 7 Ukrainian Ironbelly 17 ## 8 Antipodean Opaleye 16 ## 9 Chinese Fireball 16 ## 10 Swedish Short-Snout 14 13.2.11 Extracting columns as vectors Now say that we want to only keep morphometric measurements for dragons of species for which we have at least 30 individuals. We need to filter those whose species falls within that group. So this task can be divided in two steps: first, identify the group and store the result; second, filter the table based on records from those groups. Let’s see: (species_over30 &lt;- dragons %&gt;% group_by(species) %&gt;% tally() %&gt;% arrange(desc(n)) %&gt;% filter(n &gt; 30) %&gt;% pull(species)) ## [1] &quot;Norwegian Ridgeback&quot; &quot;Common Welsh Green&quot; &quot;Romanian Longhorn&quot; ## [4] &quot;Hebridean Black&quot; &quot;Peruvian Vipertooth&quot; &quot;Hungarian Horntail&quot; The function pull at the end extracts the values in my column of interest and returns them as a vector. ## [1] &quot;character&quot; If I used select instead, the result would be a tibble: ## # A tibble: 6 x 1 ## species ## &lt;chr&gt; ## 1 Norwegian Ridgeback ## 2 Common Welsh Green ## 3 Romanian Longhorn ## 4 Hebridean Black ## 5 Peruvian Vipertooth ## 6 Hungarian Horntail ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; Now that we have a vector with the species that we want to retain, we can apply our filter: ## # A tibble: 264 x 11 ## measurement_id dragon_id date total_body_leng~ wingspan_cm tail_length_cm ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 D96 2012~ 1070. 1390. 595. ## 2 2 D400 2003~ 333. 635. 104. ## 3 3 D316 2017~ 867. 1052. 374. ## 4 5 D484 2016~ 1032. 1721. 596. ## 5 6 D149 2012~ 920. 1534. 564. ## 6 7 D285 2016~ 305. 699. 116. ## 7 8 D256 2013~ 359. 652. 148. ## 8 9 D283 2007~ 1698. 1387. 666. ## 9 10 D213 2001~ 354. 671. 140. ## 10 11 D485 2002~ 957. 1780. 561. ## # ... with 254 more rows, and 5 more variables: tarsus_length_cm &lt;dbl&gt;, ## # claw_length_cm &lt;dbl&gt;, sex &lt;chr&gt;, age_class &lt;chr&gt;, species &lt;chr&gt; 13.2.12 Conditional value assignment Figure 13.3: Artwork by Allison Horst The last function we are going to look at is case_when. This function allows to do conditional value assignment by vectorizing multiple statements of the kind: if … else …. Let’s look at an example to understand what this means. The dragons table includes information on sex and on age class. Say that we wanted to create a composite variable combining sex and age class, with possible categories “adult female”, “adult male”, “juvenile female”, etc. We can gather the information from the two existing column and create a new column assigning the appropriate category to each individual using case_when: ## # A tibble: 327 x 4 ## dragon_id sex age_class sex_age_combo ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 D96 F Adult Adult Female ## 2 D400 &lt;NA&gt; Juvenile Juvenile Unknown ## 3 D316 M Subadult Subadult Male ## 4 D317 F Adult Adult Female ## 5 D484 M Adult Adult Male ## 6 D149 M Adult Adult Male ## 7 D285 &lt;NA&gt; Juvenile Juvenile Unknown ## 8 D256 &lt;NA&gt; Juvenile Juvenile Unknown ## 9 D283 F Adult Adult Female ## 10 D213 &lt;NA&gt; Juvenile Juvenile Unknown ## # ... with 317 more rows Let’s break down the syntax I used in the case_when statement. Each entry has the form logical condition ~ value to assign. Let’s isolate the left-hand side of the first entry: ## [1] FALSE FALSE TRUE TRUE FALSE TRUE There can be as many entries as we want, but they should fully cover the logical domain of the statement. In other words, we need to account for every possibility. If, say, we left out the male subadult combination, case_when is going to automatically assign NA: ## # A tibble: 327 x 4 ## dragon_id sex age_class sex_age_combo ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 D96 F Adult Adult Female ## 2 D400 &lt;NA&gt; Juvenile Juvenile Unknown ## 3 D316 M Subadult &lt;NA&gt; ## 4 D317 F Adult Adult Female ## 5 D484 M Adult Adult Male ## 6 D149 M Adult Adult Male ## 7 D285 &lt;NA&gt; Juvenile Juvenile Unknown ## 8 D256 &lt;NA&gt; Juvenile Juvenile Unknown ## 9 D283 F Adult Adult Female ## 10 D213 &lt;NA&gt; Juvenile Juvenile Unknown ## # ... with 317 more rows Once we’ve covered all of the possibilities except one, we can leave the last one implicit by using TRUE on the left-hand side of the last entry of the case_when statement. For example, if an individual does not fall in the first six categories it means its sex is unknown. We could lump these all together in one “Unknown” category: ## # A tibble: 327 x 4 ## dragon_id sex age_class sex_age_combo ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 D96 F Adult Adult Female ## 2 D400 &lt;NA&gt; Juvenile Unknown ## 3 D316 M Subadult Subadult Male ## 4 D317 F Adult Adult Female ## 5 D484 M Adult Adult Male ## 6 D149 M Adult Adult Male ## 7 D285 &lt;NA&gt; Juvenile Unknown ## 8 D256 &lt;NA&gt; Juvenile Unknown ## 9 D283 F Adult Adult Female ## 10 D213 &lt;NA&gt; Juvenile Unknown ## # ... with 317 more rows Or we could decide that if sex is unknown we just simply assign the value of age_class: ## # A tibble: 327 x 4 ## dragon_id sex age_class sex_age_combo ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 D96 F Adult Adult Female ## 2 D400 &lt;NA&gt; Juvenile Juvenile ## 3 D316 M Subadult Subadult Male ## 4 D317 F Adult Adult Female ## 5 D484 M Adult Adult Male ## 6 D149 M Adult Adult Male ## 7 D285 &lt;NA&gt; Juvenile Juvenile ## 8 D256 &lt;NA&gt; Juvenile Juvenile ## 9 D283 F Adult Adult Female ## 10 D213 &lt;NA&gt; Juvenile Juvenile ## # ... with 317 more rows 13.3 Style Tidyverse syntax helps to make code readable, but half of the deal with readability has to do with style. Hadley Whickham, the inventor of the tidyverse, has put together a handy style guide that lists things to pay attention to when writing code and best practices to adopt. Style is not so much about making things aesthetically pleasing (although it certainly does), but about making the code easy for your eyes to navigate through and understand. R already uses a type of font for which each character occupies the same amount of pixels, which makes things align nicely across rows. This makes it easy to recognize structure in the code at a glance, and this physical structure corresponds to logical structure so it helps you understand how the pieces fit together. But these qualities are no good if the user doesn’t put in the effort to take advantage of them. Here are my favorite style tips to make sure your code looks clean and reads easily: Always put spaces after your commas, on both sides of equal signs and other operators (e.g., do x &lt;- 1, not x&lt;-1); Do not exceed 80 characters per line in your script (you can check how many characters you’ve used at the bottom-left corner of the script panel, and recent versions of RStudio also have a handy gray vertical line that marks the 80 character limit); Be consistent in your variable names: don’t use CamelCase for some and lowercase_with_underscores for others. Actually, stick to lowercase_with_underscores. Start a new line after each pipe %&gt;%; I like to start a new line even after each column listed in a select statement, or even after each argument of a function (for sure whenever the code would overflow past 80 characters otherwise); Tidyverse automatically indents your code when you go to a new line (e.g., after a pipe), but if you happen to mess with the alignment while you’re editing the code, make sure to reindent it and realign it at the end (you don’t have to do it manually, just highlight the chunk of code you want to reindent and go to Code &gt; Reindent lines in RStudio, or press Ctrl + I). 13.4 References https://datacarpentry.org/R-ecology-lesson/ https://style.tidyverse.org/ "],
["ggplot2.html", "Chapter 14 Data Visualization with ggplot2 14.1 A Grammar of Graphics 14.2 Building plots 14.3 Customizing plots 14.4 Colorblind-friendly plots with viridis 14.5 Arranging multiple plots together with patchwork 14.6 Saving plots 14.7 References", " Chapter 14 Data Visualization with ggplot2 Data visualization and storytelling is one of the most important parts of the scientific process, and arguably the most fun. In this Chapter, we are going to see how to make beautiful, elegant plots using the core tidyverse package ggplot2. Figure 14.1: Artwork by Allison Horst library(tidyverse) We are going to practice using the dragon dataset again, so let’s load it in: library(DBI) dragons_db &lt;- dbConnect(RSQLite::SQLite(), &quot;../../Course Material/Data/dragons/dragons.db&quot;) dragons &lt;- dbGetQuery(dragons_db, &quot;SELECT * FROM dragons;&quot;) capture_sites &lt;- dbGetQuery(dragons_db, &quot;SELECT * FROM capture_sites;&quot;) captures &lt;- dbGetQuery(dragons_db, &quot;SELECT * FROM captures;&quot;) morphometrics &lt;- dbGetQuery(dragons_db, &quot;SELECT * FROM morphometrics;&quot;) diet &lt;- dbGetQuery(dragons_db, &quot;SELECT * FROM diet;&quot;) tags &lt;- dbGetQuery(dragons_db, &quot;SELECT * FROM tags;&quot;) deployments &lt;- dbGetQuery(dragons_db, &quot;SELECT * FROM deployments;&quot;) telemetry &lt;- dbGetQuery(dragons_db, &quot;SELECT * FROM gps_data;&quot;) 14.1 A Grammar of Graphics What makes data visualization in ggplot2 different from data visualization using base R functions? Instead of having to manually combine raw elements like points and lines to produce the figure you want, ggplot2 allows you to use a more structured approach so that a handful of commands will produce the plot you have in mind with minimal hassle. The logic of ggplot follows the “Grammar of Graphics” framework, which was first introduced in a book by Leland Wilkinson. This framework concisely describes the different components of a graphic. At a minimum, a plot is composed by data, aesthetics, and geometries: Data: this is the data you want to represent in your plot; Aesthetics: these are the variables that are represented on the plot (e.g., what goes on the axes, or what is encoded with different symbols and colors); Geometries: these are the actual symbols that appear on the plot (points, lines, etc.) On top of these fundamental components, there can be additional elements for customization. Another major difference between ggplot2 and plots in base R is that ggplot2 works like a declarative language. Declarative means that the code to make the plot is evaluated and interpreted all at once, not one line at a time like in base R, which by contrast is an imperative language. We are used to paying close attention to the order in which we run code in R, because if we run commands in the wrong order things won’t work, but as we’ll see the order in which we specify features of our plot is not as rigid in ggplot2. 14.2 Building plots ggplot works in layers. Each layer specifies one or more components of the plot, and layers can be added to progressively customize the final result. At a minimum, a plot has to contain layers for the three fundamental components that we’ve seen above: data, aesthetics, and geometries. Everything else is optional. Layers are added using a + sign. 14.2.1 Basic scatterplot Let’s say that we want to explore the correlation between total body length and wingspan in dragons. We may want to look at that using a scatterplot. This is how to build one in ggplot2: ggplot(data = morphometrics, mapping = aes(x = total_body_length_cm, y = wingspan_cm)) + geom_point() Let’s break down the syntax of what I just wrote. First, we start with the function ggplot. This function takes as input 1. the data that we want to plot and 2. the aesthetics for the plot. At a minimum, these include the variables that we want to plot on the two axes. Here, I specified that I want to plot the data frame called morphometrics and that I want to plot total body length on the x axis and wingspan on the y axis. Then there’s a + sign, which means that we’re adding a layer. The next layer describes the geometry we want to plot. A scatterplot is made of points, so the function to use is geom_point. So essentially you could read that whole code as, “make a scatterplot with the morphometrics table where total body length is on the x axis and wingspan is on the y axis.” Note that, if you look at the help file for geom_point or any other geom_ function, you’ll see that the first two arguments are mapping and data. These are the same as the ones we specified in ggplot. What’s up with that? The data and mapping options that we specify in ggplot are global plot settings that will be implicitly assumed for every layer downstream. If we don’t specify anything for these two arguments in the geom_ function, the geometries will inherit the global plot settings. But it’s possible to override the global plot settings by specifying different ones in a certain layer, for example if we want to overlay two different datasets. 14.2.2 Basic histogram What if we wanted to look at the distribution of total body length instead? We may want to use a histogram for that: ggplot(data = morphometrics, mapping = aes(x = total_body_length_cm)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. In this case we only have one aesthetic, because the y axis on a histogram is the bin frequency (by default, ggplot2 shows the absolute frequency). We can choose other options within geom_histogram, such as changing the number of bins: ggplot(data = morphometrics, mapping = aes(x = total_body_length_cm)) + geom_histogram(bins = 100) 14.2.3 Basic density plot Perhaps a better way to visualize the distribution of a variable is to use a density plot rather than a histogram. ggplot(data = morphometrics, mapping = aes(x = total_body_length_cm)) + geom_density() 14.2.4 Other geom functions The ones above are just four common examples of functions in the geom family, but there are many others that you may find yourself using (and we’ll see some of these in action throughout the rest of this Chapter and in class): geom_line for lines connecting observations based on their value (useful for time series plots and regression lines); geom_path for lines connecting observations based on the order they appear in (useful for movement data); geom_ribbon for shaded envelopes around lines (useful for representing confidence intervals); geom_hline and geom_vline, for horizontal and vertical intercepts, respectively; geom_boxplot and geom_violin for distributions of continuous variables; geom_pointrange for point estimates with uncertainty ranges; and many many more… 14.3 Customizing plots Now that we got the gist of how to build a basic plot in ggplot2, let’s start to learn how to make them pretty. 14.3.1 Changing axis labels Let’s go back to our scatterplot and fix some details. First, let’s change the axis labels. There are several ways to do this; one of them is this: ggplot(data = morphometrics, mapping = aes(x = total_body_length_cm, y = wingspan_cm)) + geom_point() + labs(x = &quot;Total body length (cm)&quot;, y = &quot;Wingspan (cm)&quot;) An alternative way is: ggplot(data = morphometrics, mapping = aes(x = total_body_length_cm, y = wingspan_cm)) + geom_point() + xlab(&quot;Total body length (cm)&quot;) + ylab(&quot;Wingspan (cm)&quot;) 14.3.2 Changing colors See that cluster of points in the bottom-left of the scatterplot? It seems like there’s a lot less variation in terms of body measurements in that cluster compared to the larger cloud on the right. Could that be because of an age effect? Perhaps young dragons are more consistent in their measurements, and as they reach adulthood their body size varies much more between individuals. Let’s try to get a clue to verify this hypothesis by coloring the dots on the scatterplot based on age. We are going to use some of the tools we learned in Chapter 13 to associate age information from the dragons table to the morphometrics table: morphometrics %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% # note that I am feeding the results of the pipe directly into ggplot: # whatever comes out of that pipe is used as the data argument for the plot ggplot(mapping = aes(x = total_body_length_cm, y = wingspan_cm, color = age_class)) + geom_point() + labs(x = &quot;Total body length (cm)&quot;, y = &quot;Wingspan (cm)&quot;) 14.3.3 Modifying legends Looks like our hypothesis was correct: that cluster of points includes measurements for juvenile dragons. Let’s make that legend a little prettier: morphometrics %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% ggplot(mapping = aes(x = total_body_length_cm, y = wingspan_cm, color = age_class)) + geom_point() + labs(x = &quot;Total body length (cm)&quot;, y = &quot;Wingspan (cm)&quot;, color = &quot;Age class&quot;) Besides changing the title of the legend, we can also change the labels on each of the categories that appear in it. For example, if we wanted to add age ranges to correspond to each age class: morphometrics %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% ggplot(mapping = aes(x = total_body_length_cm, y = wingspan_cm, color = age_class)) + geom_point() + labs(x = &quot;Total body length (cm)&quot;, y = &quot;Wingspan (cm)&quot;, color = &quot;Age class&quot;) + scale_color_discrete(labels = c(&quot;Adult (&gt; 3 years)&quot;, &quot;Juvenile (&lt; 1 year)&quot;, &quot;Subadult (2-3 years)&quot;)) What if we want to reorder legend items so that they appear in order of age? That is not something that we can do within the plot itself, it’s a change that needs to be done in the data before we plot. We need to change the order of the levels in the factor age_class. Once that’s done, we need to remember to also change the order of the labels to reflect the new order: morphometrics %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% mutate(age_class = factor(age_class, levels = c(&quot;Juvenile&quot;, &quot;Subadult&quot;, &quot;Adult&quot;))) %&gt;% ggplot(mapping = aes(x = total_body_length_cm, y = wingspan_cm, color = age_class)) + geom_point() + labs(x = &quot;Total body length (cm)&quot;, y = &quot;Wingspan (cm)&quot;, color = &quot;Age class&quot;) + scale_color_discrete(labels = c(&quot;Juvenile (&lt; 1 year)&quot;, &quot;Subadult (2-3 years)&quot;, &quot;Adult (&gt; 3 years)&quot;)) We can also change the position of the legend: morphometrics %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% mutate(age_class = factor(age_class, levels = c(&quot;Juvenile&quot;, &quot;Subadult&quot;, &quot;Adult&quot;))) %&gt;% ggplot(mapping = aes(x = total_body_length_cm, y = wingspan_cm, color = age_class)) + geom_point() + labs(x = &quot;Total body length (cm)&quot;, y = &quot;Wingspan (cm)&quot;, color = &quot;Age class&quot;) + scale_color_discrete(labels = c(&quot;Juvenile (&lt; 1 year)&quot;, &quot;Subadult (2-3 years)&quot;, &quot;Adult (&gt; 3 years)&quot;)) + theme(legend.position = &quot;bottom&quot;) 14.3.4 Themes The theme function that we just used to move the legend to the bottom can do so much more than just that! It has arguments that allow you to customize the appearance of your plot in pretty much any way you want. Things like the plot title and subtitle, the labels that appear on the axes (and you can have two y axis, one on the right and one on the left, or two x axis, one on the top and one on the bottom), the numbers or words that appear on axis ticks as well as their size and orientation, the length of the ticks themselves, legend size, spacing, alignment, the look of the background of the plot… You can create your own theme by saving it as an object and then adding it to a plot as a new layer: # This theme adds a gray box around the legend and # alternates the size of the lines in the background grid my_theme &lt;- theme(legend.background = element_rect(fill = &quot;gray90&quot;, size = 0.5, linetype = &quot;solid&quot;, color = &quot;black&quot;), panel.grid.major = element_line(color = &quot;white&quot;, size = 1.5)) morphometrics %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% mutate(age_class = factor(age_class, levels = c(&quot;Juvenile&quot;, &quot;Subadult&quot;, &quot;Adult&quot;))) %&gt;% ggplot(mapping = aes(x = total_body_length_cm, y = wingspan_cm, color = age_class)) + geom_point() + labs(x = &quot;Total body length (cm)&quot;, y = &quot;Wingspan (cm)&quot;, color = &quot;Age class&quot;) + scale_color_discrete(labels = c(&quot;Juvenile (&lt; 1 year)&quot;, &quot;Subadult (2-3 years)&quot;, &quot;Adult (&gt; 3 years)&quot;)) + theme(legend.position = &quot;bottom&quot;) + my_theme Ugly. I know. If you’re not a graphic designer and your plots look as ugly as mine when you manipulate the theme yourself, ggplot2 also offers a variety of pre-set themes. For example, here is the “minimal” theme: morphometrics %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% mutate(age_class = factor(age_class, levels = c(&quot;Juvenile&quot;, &quot;Subadult&quot;, &quot;Adult&quot;))) %&gt;% ggplot(mapping = aes(x = total_body_length_cm, y = wingspan_cm, color = age_class)) + geom_point() + labs(x = &quot;Total body length (cm)&quot;, y = &quot;Wingspan (cm)&quot;, color = &quot;Age class&quot;) + scale_color_discrete(labels = c(&quot;Juvenile (&lt; 1 year)&quot;, &quot;Subadult (2-3 years)&quot;, &quot;Adult (&gt; 3 years)&quot;)) + theme_minimal() + theme(legend.position = &quot;bottom&quot;) Here is the “black and white” theme: morphometrics %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% mutate(age_class = factor(age_class, levels = c(&quot;Juvenile&quot;, &quot;Subadult&quot;, &quot;Adult&quot;))) %&gt;% ggplot(mapping = aes(x = total_body_length_cm, y = wingspan_cm, color = age_class)) + geom_point() + labs(x = &quot;Total body length (cm)&quot;, y = &quot;Wingspan (cm)&quot;, color = &quot;Age class&quot;) + scale_color_discrete(labels = c(&quot;Juvenile (&lt; 1 year)&quot;, &quot;Subadult (2-3 years)&quot;, &quot;Adult (&gt; 3 years)&quot;)) + theme_bw() + theme(legend.position = &quot;bottom&quot;) Here is the “void” theme: morphometrics %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% mutate(age_class = factor(age_class, levels = c(&quot;Juvenile&quot;, &quot;Subadult&quot;, &quot;Adult&quot;))) %&gt;% ggplot(mapping = aes(x = total_body_length_cm, y = wingspan_cm, color = age_class)) + geom_point() + labs(x = &quot;Total body length (cm)&quot;, y = &quot;Wingspan (cm)&quot;, color = &quot;Age class&quot;) + scale_color_discrete(labels = c(&quot;Juvenile (&lt; 1 year)&quot;, &quot;Subadult (2-3 years)&quot;, &quot;Adult (&gt; 3 years)&quot;)) + theme_void() + theme(legend.position = &quot;bottom&quot;) If you use a pre-set theme, make sure you add that layer before you add any other tweaks using theme, because if you add theme first, the pre-set theme will override whatever settings you specified in theme. For instance, if I put theme_void at the end in the previous example, the legend does not get moved to the bottom: morphometrics %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% mutate(age_class = factor(age_class, levels = c(&quot;Juvenile&quot;, &quot;Subadult&quot;, &quot;Adult&quot;))) %&gt;% ggplot(mapping = aes(x = total_body_length_cm, y = wingspan_cm, color = age_class)) + geom_point() + labs(x = &quot;Total body length (cm)&quot;, y = &quot;Wingspan (cm)&quot;, color = &quot;Age class&quot;) + scale_color_discrete(labels = c(&quot;Juvenile (&lt; 1 year)&quot;, &quot;Subadult (2-3 years)&quot;, &quot;Adult (&gt; 3 years)&quot;)) + theme(legend.position = &quot;bottom&quot;) + theme_void() 14.3.5 Adding transparency We could decide that we want to make the points transparent on this plot so that we can actually get a better feel for the amount of data points within very clumpy clusters. We can do that by adding the argument alpha in our geometry layer: morphometrics %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% mutate(age_class = factor(age_class, levels = c(&quot;Juvenile&quot;, &quot;Subadult&quot;, &quot;Adult&quot;))) %&gt;% ggplot(mapping = aes(x = total_body_length_cm, y = wingspan_cm, color = age_class)) + geom_point(alpha = 0.2) + labs(x = &quot;Total body length (cm)&quot;, y = &quot;Wingspan (cm)&quot;, color = &quot;Age class&quot;) + scale_color_discrete(labels = c(&quot;Juvenile (&lt; 1 year)&quot;, &quot;Subadult (2-3 years)&quot;, &quot;Adult (&gt; 3 years)&quot;)) + theme_bw() + theme(legend.position = &quot;bottom&quot;) 14.3.6 Overlaying plots with different aesthetics From the plot we made, it seems clear that there is a correlation between the total body length of a dragon and its wingspan. We could actually model that correlation using linear regression. And then we may want to overlay the regression line to the raw data on our existing plot. Let’s see how to do just that: # Fit linear regression (reg &lt;- lm(formula = wingspan_cm ~ total_body_length_cm, data = morphometrics)) ## ## Call: ## lm(formula = wingspan_cm ~ total_body_length_cm, data = morphometrics) ## ## Coefficients: ## (Intercept) total_body_length_cm ## 445.2124 0.8525 # Let&#39;s grab the value of the intercept and slope coefs &lt;- reg$coefficients # Now we can plot morphometrics %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% mutate(age_class = factor(age_class, levels = c(&quot;Juvenile&quot;, &quot;Subadult&quot;, &quot;Adult&quot;))) %&gt;% ggplot(mapping = aes(x = total_body_length_cm, y = wingspan_cm, color = age_class)) + geom_point() + geom_abline(aes(slope = coefs[2], intercept = coefs[1])) + labs(x = &quot;Total body length (cm)&quot;, y = &quot;Wingspan (cm)&quot;, color = &quot;Age class&quot;) + scale_color_discrete(labels = c(&quot;Juvenile (&lt; 1 year)&quot;, &quot;Subadult (2-3 years)&quot;, &quot;Adult (&gt; 3 years)&quot;)) + theme_bw() + theme(legend.position = &quot;bottom&quot;) I added a new layer to the plot with geom_abline. Instead of the global aesthetics (the ones I specify at the beginning in ggplot), I need to provide a slope and an intercept. This is what I meant when I said that sometimes a certain geometry layer can use different aesthetics than the global ones. By specifying different aesthetics in that geometry layer, the global aesthetics get overridden for that layer only. 14.3.7 Modifying symbol appearance We can now play around with size, color, and line type of our regression line: morphometrics %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% mutate(age_class = factor(age_class, levels = c(&quot;Juvenile&quot;, &quot;Subadult&quot;, &quot;Adult&quot;))) %&gt;% ggplot(mapping = aes(x = total_body_length_cm, y = wingspan_cm, color = age_class)) + geom_point() + geom_abline(aes(slope = coefs[2], intercept = coefs[1]), size = 2, color = &quot;gray70&quot;, linetype = &quot;dashed&quot;) + labs(x = &quot;Total body length (cm)&quot;, y = &quot;Wingspan (cm)&quot;, color = &quot;Age class&quot;) + scale_color_discrete(labels = c(&quot;Juvenile (&lt; 1 year)&quot;, &quot;Subadult (2-3 years)&quot;, &quot;Adult (&gt; 3 years)&quot;)) + theme_bw() + theme(legend.position = &quot;bottom&quot;) We can also change the symbols for the point data: morphometrics %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% mutate(age_class = factor(age_class, levels = c(&quot;Juvenile&quot;, &quot;Subadult&quot;, &quot;Adult&quot;))) %&gt;% ggplot(mapping = aes(x = total_body_length_cm, y = wingspan_cm, color = age_class)) + geom_point(size = 2, shape = 8) + geom_abline(aes(slope = coefs[2], intercept = coefs[1]), size = 2, color = &quot;gray70&quot;, linetype = &quot;dashed&quot;) + labs(x = &quot;Total body length (cm)&quot;, y = &quot;Wingspan (cm)&quot;, color = &quot;Age class&quot;) + scale_color_discrete(labels = c(&quot;Juvenile (&lt; 1 year)&quot;, &quot;Subadult (2-3 years)&quot;, &quot;Adult (&gt; 3 years)&quot;)) + theme_bw() + theme(legend.position = &quot;bottom&quot;) 14.3.8 Fill vs. color Shapes that are one-dimensional (points and lines) are colored using the argument color in ggplot2. Shapes that are two-dimensional (polygons, bars in a barplot, ecc.) are colored inside using the argument fill, and around the border with color. Let’s make an example with some boxplots, which are two-dimensional. This is what happens if we use color instead of fill: morphometrics %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% mutate(age_class = factor(age_class, levels = c(&quot;Juvenile&quot;, &quot;Subadult&quot;, &quot;Adult&quot;))) %&gt;% ggplot(mapping = aes(y = wingspan_cm, color = age_class)) + geom_boxplot() + labs(x = &quot; &quot;, y = &quot;Wingspan (cm)&quot;, color = &quot;Age class&quot;) + scale_color_discrete(labels = c(&quot;Juvenile (&lt; 1 year)&quot;, &quot;Subadult (2-3 years)&quot;, &quot;Adult (&gt; 3 years)&quot;)) + theme_minimal() + theme(legend.position = &quot;bottom&quot;) If we use fill, the border of the boxplots will be black and the inside will be colored (note that we need to change it in three places: the global aesthetics, the legend title in labs, and the name of the function to add legend labels becomes scale_fill_discrete): morphometrics %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% mutate(age_class = factor(age_class, levels = c(&quot;Juvenile&quot;, &quot;Subadult&quot;, &quot;Adult&quot;))) %&gt;% ggplot(mapping = aes(y = wingspan_cm, fill = age_class)) + geom_boxplot() + labs(x = &quot; &quot;, y = &quot;Wingspan (cm)&quot;, fill = &quot;Age class&quot;) + scale_fill_discrete(labels = c(&quot;Juvenile (&lt; 1 year)&quot;, &quot;Subadult (2-3 years)&quot;, &quot;Adult (&gt; 3 years)&quot;)) + theme_minimal() + theme(legend.position = &quot;bottom&quot;) 14.3.9 Modifying axis values The values on the x axis don’t mean anything in this case because this is a boxplot. Let’s get rid of them in theme: morphometrics %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% mutate(age_class = factor(age_class, levels = c(&quot;Juvenile&quot;, &quot;Subadult&quot;, &quot;Adult&quot;))) %&gt;% ggplot(mapping = aes(y = wingspan_cm, fill = age_class)) + geom_boxplot() + labs(x = &quot; &quot;, y = &quot;Wingspan (cm)&quot;, fill = &quot;Age class&quot;) + scale_fill_discrete(labels = c(&quot;Juvenile (&lt; 1 year)&quot;, &quot;Subadult (2-3 years)&quot;, &quot;Adult (&gt; 3 years)&quot;)) + theme_minimal() + theme(legend.position = &quot;bottom&quot;, axis.text.x = element_blank()) 14.3.10 Adding an extra dimension with facets Dragon size might also depend on species. What if we wanted to look at the correlation between wingspan and total body length broken down by species as well as age class? That means we need to add another dimension to our scatterplot which is already showing 3: the x axis, the y axis, and the different colors. Facets expand the amount of information we can convey in a plot. Let’s see how they work: morphometrics %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% mutate(age_class = factor(age_class, levels = c(&quot;Juvenile&quot;, &quot;Subadult&quot;, &quot;Adult&quot;))) %&gt;% ggplot(mapping = aes(x = total_body_length_cm, y = wingspan_cm, color = age_class)) + geom_point() + facet_wrap(~ species) + labs(x = &quot;Total body length (cm)&quot;, y = &quot;Wingspan (cm)&quot;, color = &quot;Age class&quot;) + scale_color_discrete(labels = c(&quot;Juvenile (&lt; 1 year)&quot;, &quot;Subadult (2-3 years)&quot;, &quot;Adult (&gt; 3 years)&quot;)) + theme_bw() + theme(legend.position = &quot;bottom&quot;) The function I used to break down the plot into facets is facet_wrap. This function takes as input a one-sided formula: ~ variable/s. What goes on the right hand side of the formula is the categorical variable based on which we want to break down the plot. These can also be multiple categorical variables, in which case there will be as many facets as the possible level combinations. The labels that appear on the facets are verbatim the factor levels that appear in the data frame. If we weren’t happy with them (say, they are too long, or they are all lowercase and we want title case) we could change them. Let’s try to replace the full species names with just the initials. We need to define a labeller, which is a vector associating each label the way it appears in the current plot with the label that we want instead: species_labels &lt;- c(&quot;Hebridean Black&quot; = &quot;HB&quot;, &quot;Romanian Longhorn&quot; = &quot;RL&quot;, &quot;Peruvian Vipertooth&quot; = &quot;PV&quot;, &quot;Ukrainian Ironbelly&quot; = &quot;UI&quot;, &quot;Norwegian Ridgeback&quot; = &quot;NR&quot;, &quot;Common Welsh Green&quot; = &quot;CWG&quot;, &quot;Swedish Short-Snout&quot; = &quot;SSS&quot;, &quot;Chinese Fireball&quot; = &quot;CF&quot;, &quot;Hungarian Horntail&quot; = &quot;HH&quot;, &quot;Antipodean Opaleye&quot; = &quot;AO&quot;) morphometrics %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% mutate(age_class = factor(age_class, levels = c(&quot;Juvenile&quot;, &quot;Subadult&quot;, &quot;Adult&quot;))) %&gt;% ggplot(mapping = aes(x = total_body_length_cm, y = wingspan_cm, color = age_class)) + geom_point() + facet_wrap(~ species, labeller = labeller(species_labels, species = species_labels)) + labs(x = &quot;Total body length (cm)&quot;, y = &quot;Wingspan (cm)&quot;, color = &quot;Age class&quot;) + scale_color_discrete(labels = c(&quot;Juvenile (&lt; 1 year)&quot;, &quot;Subadult (2-3 years)&quot;, &quot;Adult (&gt; 3 years)&quot;)) + theme_bw() + theme(legend.position = &quot;bottom&quot;) 14.3.11 Error bars Let’s look at the content of some dragon diet samples, for a change. What do dragons like to eat most? ggplot(diet, aes(x = item)) + geom_bar(fill = &quot;orange&quot;) + labs(x = &quot; &quot;, y = &quot;Count&quot;) + theme_bw() Looks like they really like to eat domestic goats, huh? Let’s look at that in terms of relative frequency rather than count: ggplot(diet, aes(x = item)) + geom_bar(aes(y = ..prop.., group = 1), fill = &quot;orange&quot;) + labs(x = &quot; &quot;, y = &quot;Relative frequency&quot;) + theme_bw() Do different species like to eat different things? diet %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% ggplot(aes(x = item)) + geom_bar(aes(y = ..prop.., group = 1), fill = &quot;orange&quot;) + facet_wrap(~ species) + labs(x = &quot; &quot;, y = &quot;Relative frequency&quot;) + theme_bw() For each diet item, we can summarize the mean relative frequency in diet samples across species, calculate a standard deviation, and plot it as an error bar. Because we are plotting values that we calculate manually instead of using geom_bar to count and plot, we need to use geom_col instead: # This is the count by item for each species item_count &lt;- diet %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% group_by(species, item) %&gt;% tally() # This is the total number of items per species tot_items &lt;- diet %&gt;% left_join(dragons, by = &quot;dragon_id&quot;) %&gt;% group_by(species) %&gt;% tally() # Divide to get relative frequency item_count &lt;- item_count %&gt;% left_join(tot_items, by = &quot;species&quot;) %&gt;% mutate(rel_freq = n.x/n.y) # Calculate mean and sd for each item across species rf &lt;- item_count %&gt;% group_by(item) %&gt;% summarize(mean_rf = mean(rel_freq), sd_rf = sd(rel_freq)) ggplot(rf, aes(x = item, y = mean_rf)) + geom_col(fill = &quot;orange&quot;) + geom_errorbar(aes(ymin = mean_rf - sd_rf, ymax = mean_rf + sd_rf), width = 0.3) + labs(x = &quot; &quot;, y = &quot;Relative frequency&quot;) + theme_bw() We can also change the color to match the bars so that only the top part of the error bar is visible: ggplot(rf, aes(x = item, y = mean_rf)) + geom_col(fill = &quot;orange&quot;) + geom_errorbar(aes(ymin = mean_rf - sd_rf, ymax = mean_rf + sd_rf), width = 0.3, color = &quot;orange&quot;) + labs(x = &quot; &quot;, y = &quot;Relative frequency&quot;) + theme_bw() We can also represent these as points with error bars: ggplot(rf, aes(x = item, y = mean_rf)) + geom_pointrange(aes(ymin = mean_rf - sd_rf, ymax = mean_rf + sd_rf), color = &quot;orange&quot;) + labs(x = &quot; &quot;, y = &quot;Relative frequency&quot;) + theme_bw() 14.3.12 Plot model predictions with uncertainty Oftentimes you’ll find yourself wanting to make a plot with predictions from some kind of linear model, showing the confidence intervals around the mean estimate. This can be done by combining the geom_line function with geom_ribbon. Let’s go back to the linear regression model that we ran to quantify the correlation between total body length and wingspan. We can get model predictions for that model, calculate 95% confidence intervals using the standard error, and make a plot where the model predictions are overlaid to the raw data points: # Get model predictions for the original values of x mod_pred &lt;- predict(reg, se.fit = TRUE) # Calculate 95% CIs from std error preds &lt;- data.frame(mean = mod_pred$fit, upr = mod_pred$fit + 1.96 * mod_pred$se.fit, lwr = mod_pred$fit - 1.96 * mod_pred$se.fit) # Plot morphometrics %&gt;% ggplot(mapping = aes(x = total_body_length_cm, y = wingspan_cm)) + geom_ribbon(aes(ymin = preds$lwr, ymax = preds$upr), fill = &quot;gray90&quot;) + geom_line(aes(y = preds$mean), color = &quot;darkmagenta&quot;, size = 0.8) + geom_point(color = &quot;darkmagenta&quot;, alpha = 0.5) + labs(x = &quot;Total body length (cm)&quot;, y = &quot;Wingspan (cm)&quot;) + theme_minimal() The global aesthetics that I’m using here are those for the raw data. Then in geom_line I override the y aesthetic by replacing it with the mean model prediction for wingspan. geom_ribbon does not take as input a y aesthetic because it’s a range, not a single line, so the required aesthetics here are ymin and ymax. Notice that the order in which I put the layers determines what goes on the background and what’s in the foreground: I wanted the ribbon to be in the back, the line to be on top of the ribbon (not hidden behind it), and the points on top (or the ribbon would cover them) with some transparency. 14.3.13 Plot paths of ordered observations In our last plot, we used geom_line to plot our prediction curve. The counterpart of geom_line is geom_path, which also plots lines but in the order in which they appear in the data, not based on consecutive values of x. This is helpful in some situations, for example to plot movement tracks from telemetry data. Let’s plot the dragon GPS data: telemetry %&gt;% ggplot(aes(x = utm_x, y = utm_y, color = dragon_id)) + geom_path() + labs(x = &quot;UTM Easting&quot;, y = &quot;UTM Northing&quot;) + theme_minimal() + theme(legend.position = &quot;none&quot;) 14.4 Colorblind-friendly plots with viridis Making plots accessible and readable to everyone is an important part of communicating science. The package viridis makes it easy to make your plots colorblind-friendly. It includes several different color palettes that have been carefully engineered so that colorblind people can tell apart all the colors and the variation in hue scales linearly with the variation in the underlying numerical values. ggplot2 integrates with viridis seamlessly so it’s easy to transform your plots using viridis color palettes. Let’s demonstrate it with the telemetry plot we just made: telemetry %&gt;% ggplot(aes(x = utm_x, y = utm_y, color = dragon_id)) + geom_path() + labs(x = &quot;UTM Easting&quot;, y = &quot;UTM Northing&quot;) + scale_color_viridis_d() + theme_minimal() + theme(legend.position = &quot;none&quot;) To change the color palette to viridis, I added another layer to my plot with the function scale_color_viridis_d. The “d” at the end stands for “discrete”, because in this case the colors are assigned based on a categorical variable (the dragon ID). If I were using a continuous variable, I would have used the function scale_color_viridis_c. If I wanted to apply the palette to a fill parameter rather than a color parameter, I would have used the function scale_fill_viridis_d. The one I plotted is the standard viridis palette, but there are others to choose from (check out the viridis vignette!) For instance, this one is called plasma: telemetry %&gt;% ggplot(aes(x = utm_x, y = utm_y, color = dragon_id)) + geom_path() + labs(x = &quot;UTM Easting&quot;, y = &quot;UTM Northing&quot;) + scale_color_viridis_d(option = &quot;plasma&quot;) + theme_minimal() + theme(legend.position = &quot;none&quot;) 14.5 Arranging multiple plots together with patchwork Figure 14.2: Artwork by Allison Horst The package patchwork allows you to combine and arrange multiple plots into a single plot with several panels. Let’s load in the package (after installing it): library(patchwork) The first step to combine different plots is to save each plot by assigning it its own name. Each will be stored in the environment as a ggplot2 object. For example, let’s take our diet barplot, our regression prediction plot, and our telemetry one. We’ll call these p1, p2, and p3: p1 &lt;- ggplot(rf, aes(x = item, y = mean_rf)) + geom_col(fill = &quot;orange&quot;) + geom_errorbar(aes(ymin = mean_rf - sd_rf, ymax = mean_rf + sd_rf), width = 0.3, color = &quot;orange&quot;) + labs(x = &quot; &quot;, y = &quot;Relative frequency&quot;) + theme_minimal() p2 &lt;- morphometrics %&gt;% ggplot(mapping = aes(x = total_body_length_cm, y = wingspan_cm)) + geom_ribbon(aes(ymin = preds$lwr, ymax = preds$upr), fill = &quot;gray90&quot;) + geom_line(aes(y = preds$mean), color = &quot;darkmagenta&quot;, size = 0.8) + geom_point(color = &quot;darkmagenta&quot;, alpha = 0.5) + labs(x = &quot;Total body length (cm)&quot;, y = &quot;Wingspan (cm)&quot;) + theme_minimal() p3 &lt;- telemetry %&gt;% ggplot(aes(x = utm_x, y = utm_y, color = dragon_id)) + geom_path() + labs(x = &quot;UTM Easting&quot;, y = &quot;UTM Northing&quot;) + scale_color_viridis_d(option = &quot;plasma&quot;) + theme_minimal() + theme(legend.position = &quot;none&quot;) Now we can decide on the arrangement for these plots. The syntax for arranging plots uses combinations of three symbols: +, /, and |. Using + is the simplest option and it can be combined with the plot_layout function to tweak how many rows and columns the plots are arranged on. If no layout is specified, plots are aligned in row order: p1 + p2 + p3 But we can specify that we want them in 2 rows, in which case patchwork will fill the first row before starting the next: p1 + p2 + p3 + plot_layout(nrow = 2) If we want the first plot to appear alone on the first row and the last two on the second row, we can enforce hierarchy with parentheses: p1 + (p2 + p3) + plot_layout(nrow = 2) The symbol | means “side by side” and the symbol / means “one on top of each other”. We can combine these to obtain any layout we want: p1 | p2 / p3 (p1 | p2) / p3 (p1 / p2) | p3 14.6 Saving plots Rule number 1: never, EVER, save a plot by clicking Export on the RStudio plot panel. You will have so little control over the resolution, scale, aspect ratio, and format of your plot that the result is guaranteed to be disappointing. Instead, use ggsave! ggsave is the ggplot2 function that allows you to save your plots controlling and fine-tuning every detail of how they will appear in the end. By default, if you don’t assign a name to a plot and specify its name in ggsave, it will assume you want to save the last plot you ran. You’ll need to give it a path to the folder where you want the file saved, including the name you want to give to the file: ggsave(filename = &quot;img/patchwork1.tiff&quot;, device = &quot;tiff&quot;, # tiff is the best format for saving publication-quality figures width = 14, # define the width of the plot in your units of choice height = 8, # define the height of the plot in your units of choice units = &quot;in&quot;, # define your units of choice (&quot;in&quot; stands for inches) dpi = 400) # you can control exactly how many dots per inches your plot has, which comes in handy when the journal guidelines have a specific requirement Saving plots always requires a bit of back and forth: first, you guesstimate the right width and height, then you save the file, then you open it and look at it, then you go back to the code with any tweaks until you’re happy with it. 14.7 References https://ggplot2.tidyverse.org/ https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html https://patchwork.data-imaginist.com/ "],
["lubridate.html", "Chapter 15 Dates and Times in R", " Chapter 15 Dates and Times in R "],
["geospatial.html", "Chapter 16 Introduction to Geospatial Data in R", " Chapter 16 Introduction to Geospatial Data in R "],
["problem-decomposition.html", "Chapter 17 Problem Decomposition", " Chapter 17 Problem Decomposition "]
]
